{"train_lr": 3.7470314011786434e-05, "train_min_lr": 3.7470314011786434e-05, "train_mlm_acc_1": 0.018500027924093224, "train_mlm_acc_2": 0.018680830842061583, "train_loss_1": 7.843849407441803, "train_loss_2": 7.836664873303922, "train_loss": 15.680514286669494, "train_loss_scale": 339.5321020228672, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 0, "n_parameters": 106143056}
{"train_lr": 0.00011247691089805615, "train_min_lr": 0.00011247691089805615, "train_mlm_acc_1": 0.04701556199272847, "train_mlm_acc_2": 0.046884517660880545, "train_loss_1": 6.512790008291615, "train_loss_2": 6.514690383233412, "train_loss": 13.02748039236379, "train_loss_scale": 198.36059806508356, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 1, "n_parameters": 106143056}
{"train_lr": 0.00018748350778432582, "train_min_lr": 0.00018748350778432582, "train_mlm_acc_1": 0.0572366758381576, "train_mlm_acc_2": 0.05694557945944349, "train_loss_1": 6.232661391730463, "train_loss_2": 6.239012651990775, "train_loss": 12.47167404377366, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 5.1012626550862326, "epoch": 2, "n_parameters": 106143056}
{"train_lr": 0.0002624901046705954, "train_min_lr": 0.0002624901046705954, "train_mlm_acc_1": 0.06351503093211716, "train_mlm_acc_2": 0.06305790457443687, "train_loss_1": 6.060785542639495, "train_loss_2": 6.0716800069536365, "train_loss": 12.13246554361694, "train_loss_scale": 216.48548812664907, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.686781865940245, "epoch": 3, "n_parameters": 106143056}
{"train_lr": 0.0003374967015568651, "train_min_lr": 0.0003374967015568651, "train_mlm_acc_1": 0.06810615176503713, "train_mlm_acc_2": 0.06749007280091955, "train_loss_1": 5.939039342583746, "train_loss_2": 5.95346357771044, "train_loss": 11.892502921866868, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.7617093001737234, "epoch": 4, "n_parameters": 106143056}
{"train_lr": 0.0004125032984431348, "train_min_lr": 0.0004125032984431348, "train_mlm_acc_1": 0.0715129950907812, "train_mlm_acc_2": 0.07078680589839344, "train_loss_1": 5.850255737204036, "train_loss_2": 5.866517728268314, "train_loss": 11.716773463427863, "train_loss_scale": 494.6631486367634, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.3909426463101133, "epoch": 5, "n_parameters": 106143056}
{"train_lr": 0.00048750989532940465, "train_min_lr": 0.00048750989532940465, "train_mlm_acc_1": 0.07385371042138641, "train_mlm_acc_2": 0.07311113350783051, "train_loss_1": 5.789321497908368, "train_loss_2": 5.8062455597003515, "train_loss": 11.595567051003455, "train_loss_scale": 600.7106420404573, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.9142211503697366, "epoch": 6, "n_parameters": 106143056}
{"train_lr": 0.0005625164922156739, "train_min_lr": 0.0005625164922156739, "train_mlm_acc_1": 0.07578690903525055, "train_mlm_acc_2": 0.07497483048434046, "train_loss_1": 5.74142596458487, "train_loss_2": 5.758973134224521, "train_loss": 11.500399102426561, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.619661956475089, "epoch": 7, "n_parameters": 106143056}
{"train_lr": 0.0006375230891019436, "train_min_lr": 0.0006375230891019436, "train_mlm_acc_1": 0.07725412914490126, "train_mlm_acc_2": 0.07638684080228891, "train_loss_1": 5.705719910804493, "train_loss_2": 5.7240184180130536, "train_loss": 11.429738321740478, "train_loss_scale": 1448.1899736147757, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.4343830391096253, "epoch": 8, "n_parameters": 106143056}
{"train_lr": 0.0007125296859882135, "train_min_lr": 0.0007125296859882135, "train_mlm_acc_1": 0.07847253325835146, "train_mlm_acc_2": 0.07754892446493883, "train_loss_1": 5.67517554581742, "train_loss_2": 5.694168275820129, "train_loss": 11.369343825569253, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.240024025857501, "epoch": 9, "n_parameters": 106143056}
{"train_lr": 0.0007499927726594455, "train_min_lr": 0.0007499927726594455, "train_mlm_acc_1": 0.08016310016507497, "train_mlm_acc_2": 0.0792283142540889, "train_loss_1": 5.637820218829806, "train_loss_2": 5.657407445297392, "train_loss": 11.29522765647348, "train_loss_scale": 3389.9173262972736, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7065917757800932, "epoch": 10, "n_parameters": 106143056}
{"train_lr": 0.0007499493714617194, "train_min_lr": 0.0007499493714617194, "train_mlm_acc_1": 0.08232340187640334, "train_mlm_acc_2": 0.08131207137638105, "train_loss_1": 5.5942868943684125, "train_loss_2": 5.614512300638117, "train_loss": 11.208799191913588, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6063796793460428, "epoch": 11, "n_parameters": 106143056}
{"train_lr": 0.0007498625550649799, "train_min_lr": 0.0007498625550649799, "train_mlm_acc_1": 0.08344094900671546, "train_mlm_acc_2": 0.08237909260078963, "train_loss_1": 5.57182724153985, "train_loss_2": 5.592717875329255, "train_loss": 11.164545116030341, "train_loss_scale": 6895.11345646438, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 12, "n_parameters": 106143056}
{"train_lr": 0.000749732333657516, "train_min_lr": 0.000749732333657516, "train_mlm_acc_1": 0.08529224360022586, "train_mlm_acc_2": 0.08417725026535432, "train_loss_1": 5.535226873011577, "train_loss_2": 5.556366928911251, "train_loss": 11.091593799196845, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3048720765029955, "epoch": 13, "n_parameters": 106143056}
{"train_lr": 0.0007495587225213875, "train_min_lr": 0.0007495587225213875, "train_mlm_acc_1": 0.08599430357131423, "train_mlm_acc_2": 0.08489237686991036, "train_loss_1": 5.519747785496523, "train_loss_2": 5.541153608913891, "train_loss": 11.060901402693206, "train_loss_scale": 5954.870712401055, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4914249598508145, "epoch": 14, "n_parameters": 106143056}
{"train_lr": 0.0007493417420306326, "train_min_lr": 0.0007493417420306326, "train_mlm_acc_1": 0.08754515697689778, "train_mlm_acc_2": 0.08639169665562971, "train_loss_1": 5.49102755135995, "train_loss_2": 5.512738753591804, "train_loss": 11.003766309407686, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.265923775909444, "epoch": 15, "n_parameters": 106143056}
{"train_lr": 0.0007490814176488726, "train_min_lr": 0.0007490814176488726, "train_mlm_acc_1": 0.08858902252745293, "train_mlm_acc_2": 0.08741605955298103, "train_loss_1": 5.469804792993406, "train_loss_2": 5.491770185811958, "train_loss": 10.961574977914177, "train_loss_scale": 12947.250659630607, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 16, "n_parameters": 106143056}
{"train_lr": 0.0007487777799263258, "train_min_lr": 0.0007487777799263258, "train_mlm_acc_1": 0.0894193210456399, "train_mlm_acc_2": 0.08820729560022986, "train_loss_1": 5.454738284111443, "train_loss_2": 5.476860978882252, "train_loss": 10.931599263255809, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2005417169241288, "epoch": 17, "n_parameters": 106143056}
{"train_lr": 0.0007484308644962306, "train_min_lr": 0.0007484308644962306, "train_mlm_acc_1": 0.09023382746685778, "train_mlm_acc_2": 0.08899217585417898, "train_loss_1": 5.4395364910862165, "train_loss_2": 5.461842179612937, "train_loss": 10.901378665771418, "train_loss_scale": 11102.78979771328, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1888864443505556, "epoch": 18, "n_parameters": 106143056}
{"train_lr": 0.000748040712070646, "train_min_lr": 0.000748040712070646, "train_mlm_acc_1": 0.09090800202724408, "train_mlm_acc_2": 0.08967593570281616, "train_loss_1": 5.426013102317548, "train_loss_2": 5.448466879501611, "train_loss": 10.874479981924004, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1522348527333772, "epoch": 19, "n_parameters": 106143056}
{"train_lr": 0.0007476073684356914, "train_min_lr": 0.0007476073684356914, "train_mlm_acc_1": 0.09156393367476047, "train_mlm_acc_2": 0.09030619215813245, "train_loss_1": 5.414170056764977, "train_loss_2": 5.436923402752285, "train_loss": 10.851093458311539, "train_loss_scale": 16600.147757255938, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 20, "n_parameters": 106143056}
{"train_lr": 0.0007471308844461622, "train_min_lr": 0.0007471308844461622, "train_mlm_acc_1": 0.09221152829460098, "train_mlm_acc_2": 0.09093037907856541, "train_loss_1": 5.402518077492189, "train_loss_2": 5.42537193305679, "train_loss": 10.827890010601402, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1164045560328502, "epoch": 21, "n_parameters": 106143056}
{"train_lr": 0.00074661131601957, "train_min_lr": 0.00074661131601957, "train_mlm_acc_1": 0.09278331125251746, "train_mlm_acc_2": 0.09149492438636858, "train_loss_1": 5.391500283042485, "train_loss_2": 5.414553677291333, "train_loss": 10.806053965680936, "train_loss_scale": 9409.63236587511, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 22, "n_parameters": 106143056}
{"train_lr": 0.0007460487241295682, "train_min_lr": 0.0007460487241295682, "train_mlm_acc_1": 0.09322230920208685, "train_mlm_acc_2": 0.09190221194246671, "train_loss_1": 5.383274901510858, "train_loss_2": 5.406324522371552, "train_loss": 10.789599431850665, "train_loss_scale": 8948.517150395779, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0809771473091112, "epoch": 23, "n_parameters": 106143056}
{"train_lr": 0.0007454431747988132, "train_min_lr": 0.0007454431747988132, "train_mlm_acc_1": 0.09369856022501474, "train_mlm_acc_2": 0.09237900123625942, "train_loss_1": 5.37491083076992, "train_loss_2": 5.398099773634707, "train_loss": 10.773010609122673, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0868551940800542, "epoch": 24, "n_parameters": 106143056}
{"train_lr": 0.0007447947390912042, "train_min_lr": 0.0007447947390912042, "train_mlm_acc_1": 0.09343142127503519, "train_mlm_acc_2": 0.09210989248702137, "train_loss_1": 5.38176884526418, "train_loss_2": 5.405035296027453, "train_loss": 10.786804138303538, "train_loss_scale": 8694.543535620052, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 25, "n_parameters": 106143056}
{"train_lr": 0.0007441034931035458, "train_min_lr": 0.0007441034931035458, "train_mlm_acc_1": 0.09449342657175495, "train_mlm_acc_2": 0.09322162206786813, "train_loss_1": 5.359512212565832, "train_loss_2": 5.382681767879711, "train_loss": 10.742193984377248, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0010257784273924, "epoch": 26, "n_parameters": 106143056}
{"train_lr": 0.0007433695179566179, "train_min_lr": 0.0007433695179566179, "train_mlm_acc_1": 0.09504412650888361, "train_mlm_acc_2": 0.09372035322732168, "train_loss_1": 5.351099906569526, "train_loss_2": 5.374295254967772, "train_loss": 10.725395162376062, "train_loss_scale": 1371.6376429199647, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0374815172025165, "epoch": 27, "n_parameters": 106143056}
{"train_lr": 0.0007425928997856612, "train_min_lr": 0.0007425928997856612, "train_mlm_acc_1": 0.09528268151404623, "train_mlm_acc_2": 0.09396689017807038, "train_loss_1": 5.345129246499943, "train_loss_2": 5.368443474448765, "train_loss": 10.713572708052716, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.043020561586479, "epoch": 28, "n_parameters": 106143056}
{"train_lr": 0.0007417737297302581, "train_min_lr": 0.0007417737297302581, "train_mlm_acc_1": 0.09567509297602593, "train_mlm_acc_2": 0.0943200674248743, "train_loss_1": 5.3391376246772735, "train_loss_2": 5.362497602677073, "train_loss": 10.701635229765792, "train_loss_scale": 3236.8126649076517, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0345758870178499, "epoch": 29, "n_parameters": 106143056}
{"train_lr": 0.0007409121039236501, "train_min_lr": 0.0007409121039236501, "train_mlm_acc_1": 0.09603743174784181, "train_mlm_acc_2": 0.09466534278788845, "train_loss_1": 5.3326044909348065, "train_loss_2": 5.356012865232604, "train_loss": 10.688617358316742, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0309064629943936, "epoch": 30, "n_parameters": 106143056}
{"train_lr": 0.000740008123481444, "train_min_lr": 0.000740008123481444, "train_mlm_acc_1": 0.09634374773904694, "train_mlm_acc_2": 0.09497895361175769, "train_loss_1": 5.327408263425399, "train_loss_2": 5.350879672177549, "train_loss": 10.678287933977844, "train_loss_scale": 7460.700087950748, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0095347519914832, "epoch": 31, "n_parameters": 106143056}
{"train_lr": 0.0007390618944897517, "train_min_lr": 0.0007390618944897517, "train_mlm_acc_1": 0.09667988451281292, "train_mlm_acc_2": 0.09528658655369712, "train_loss_1": 5.321699365986579, "train_loss_2": 5.345283315123019, "train_loss": 10.666982686299447, "train_loss_scale": 8703.549692172384, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0350098478867489, "epoch": 32, "n_parameters": 106143056}
{"train_lr": 0.0007380735279927422, "train_min_lr": 0.0007380735279927422, "train_mlm_acc_1": 0.09689894831831924, "train_mlm_acc_2": 0.09550453952891243, "train_loss_1": 5.317318681886349, "train_loss_2": 5.340845748480727, "train_loss": 10.658164424233616, "train_loss_scale": 14496.309586631487, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 33, "n_parameters": 106143056}
{"train_lr": 0.0007370431399796046, "train_min_lr": 0.0007370431399796046, "train_mlm_acc_1": 0.09720819590985119, "train_mlm_acc_2": 0.09581802441536227, "train_loss_1": 5.3119118647713774, "train_loss_2": 5.335521228185534, "train_loss": 10.64743309117454, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0227947462622073, "epoch": 34, "n_parameters": 106143056}
{"train_lr": 0.0007359708513709434, "train_min_lr": 0.0007359708513709434, "train_mlm_acc_1": 0.09741444502143794, "train_mlm_acc_2": 0.09600166743580275, "train_loss_1": 5.308165452935345, "train_loss_2": 5.331793235338038, "train_loss": 10.639958690003334, "train_loss_scale": 12053.839929639402, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0197231604954393, "epoch": 35, "n_parameters": 106143056}
{"train_lr": 0.000734856788004579, "train_min_lr": 0.000734856788004579, "train_mlm_acc_1": 0.09774369922308489, "train_mlm_acc_2": 0.09632424514399958, "train_loss_1": 5.303019389261147, "train_loss_2": 5.326641054560243, "train_loss": 10.629660448487012, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0221404684355306, "epoch": 36, "n_parameters": 106143056}
{"train_lr": 0.0007337010806207864, "train_min_lr": 0.0007337010806207864, "train_mlm_acc_1": 0.0974417006115289, "train_mlm_acc_2": 0.09606075931255269, "train_loss_1": 5.308238054485623, "train_loss_2": 5.331859083530037, "train_loss": 10.640097137701124, "train_loss_scale": 8732.369393139841, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 37, "n_parameters": 106143056}
{"train_lr": 0.0007325038648469556, "train_min_lr": 0.0007325038648469556, "train_mlm_acc_1": 0.09814792907761578, "train_mlm_acc_2": 0.09674992444929106, "train_loss_1": 5.294441521325023, "train_loss_2": 5.317985034869655, "train_loss": 10.61242655892066, "train_loss_scale": 9625.780123131046, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9779677172973686, "epoch": 38, "n_parameters": 106143056}
{"train_lr": 0.000731265281181661, "train_min_lr": 0.000731265281181661, "train_mlm_acc_1": 0.0981375879944747, "train_mlm_acc_2": 0.09671088486988501, "train_loss_1": 5.2953364447008235, "train_loss_2": 5.319129722781001, "train_loss": 10.614466170836879, "train_loss_scale": 14834.941072999121, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 39, "n_parameters": 106143056}
{"train_lr": 0.0007299854749781874, "train_min_lr": 0.0007299854749781874, "train_mlm_acc_1": 0.09864883611376808, "train_mlm_acc_2": 0.09722955379612161, "train_loss_1": 5.2878010896810235, "train_loss_2": 5.3115763349185, "train_loss": 10.599377429579683, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9502220652348763, "epoch": 40, "n_parameters": 106143056}
{"train_lr": 0.0007286645964274694, "train_min_lr": 0.0007286645964274694, "train_mlm_acc_1": 0.09869683110921028, "train_mlm_acc_2": 0.0973019986130828, "train_loss_1": 5.284608380461116, "train_loss_2": 5.308301197926832, "train_loss": 10.592909579017022, "train_loss_scale": 11715.208443271767, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.008054045228027, "epoch": 41, "n_parameters": 106143056}
{"train_lr": 0.0007273028005404614, "train_min_lr": 0.0007273028005404614, "train_mlm_acc_1": 0.09879643993539017, "train_mlm_acc_2": 0.09742180864583036, "train_loss_1": 5.283195708441755, "train_loss_2": 5.306908256984533, "train_loss": 10.590103963853606, "train_loss_scale": 13422.775725593667, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 42, "n_parameters": 106143056}
{"train_lr": 0.0007259002471299484, "train_min_lr": 0.0007259002471299484, "train_mlm_acc_1": 0.09912168589586895, "train_mlm_acc_2": 0.09765904665930343, "train_loss_1": 5.277900104052997, "train_loss_2": 5.301611366351655, "train_loss": 10.579511466944753, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9659524421054434, "epoch": 43, "n_parameters": 106143056}
{"train_lr": 0.0007244571007917912, "train_min_lr": 0.0007244571007917912, "train_mlm_acc_1": 0.09927357270619067, "train_mlm_acc_2": 0.09782604998175838, "train_loss_1": 5.27524321369676, "train_loss_2": 5.299141724275305, "train_loss": 10.574384934354898, "train_loss_scale": 13127.37379067722, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0308496383270256, "epoch": 44, "n_parameters": 106143056}
{"train_lr": 0.0007229735308856102, "train_min_lr": 0.0007229735308856102, "train_mlm_acc_1": 0.09949841975458065, "train_mlm_acc_2": 0.09806078001398105, "train_loss_1": 5.271934864231653, "train_loss_2": 5.295682557077919, "train_loss": 10.567617425293701, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0079991044239087, "epoch": 45, "n_parameters": 106143056}
{"train_lr": 0.0007214497115149132, "train_min_lr": 0.0007214497115149132, "train_mlm_acc_1": 0.09955924090977657, "train_mlm_acc_2": 0.09810796191812662, "train_loss_1": 5.269782959261587, "train_loss_2": 5.2935064009332615, "train_loss": 10.563289356944638, "train_loss_scale": 11852.102022867195, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 46, "n_parameters": 106143056}
{"train_lr": 0.0007198858215066601, "train_min_lr": 0.0007198858215066601, "train_mlm_acc_1": 0.09980247969753064, "train_mlm_acc_2": 0.0984087924054425, "train_loss_1": 5.266138968073493, "train_loss_2": 5.289877011677416, "train_loss": 10.556015987194938, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0061630892879416, "epoch": 47, "n_parameters": 106143056}
{"train_lr": 0.0007182820443902745, "train_min_lr": 0.0007182820443902745, "train_mlm_acc_1": 0.0999618102612077, "train_mlm_acc_2": 0.09851648622555306, "train_loss_1": 5.264095728399466, "train_loss_2": 5.287928875958385, "train_loss": 10.552024605615996, "train_loss_scale": 15663.507475813545, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9997311333028915, "epoch": 48, "n_parameters": 106143056}
{"train_lr": 0.0007166385683761166, "train_min_lr": 0.0007166385683761166, "train_mlm_acc_1": 0.09949306023070423, "train_mlm_acc_2": 0.09802551951878619, "train_loss_1": 5.271283153441252, "train_loss_2": 5.295096026980888, "train_loss": 10.566379183829618, "train_loss_scale": 7150.888302550572, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 49, "n_parameters": 106143056}
{"train_lr": 0.0007149555863333774, "train_min_lr": 0.0007149555863333774, "train_mlm_acc_1": 0.10023699989812669, "train_mlm_acc_2": 0.09880634585252931, "train_loss_1": 5.258085331323384, "train_loss_2": 5.28201732623965, "train_loss": 10.540102653683752, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9720342777859462, "epoch": 50, "n_parameters": 106143056}
{"train_lr": 0.0007132332957674665, "train_min_lr": 0.0007132332957674665, "train_mlm_acc_1": 0.10049116381230251, "train_mlm_acc_2": 0.09904169426574032, "train_loss_1": 5.254969316977834, "train_loss_2": 5.278813825171562, "train_loss": 10.533783148964352, "train_loss_scale": 8155.975373790678, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9954311482300334, "epoch": 51, "n_parameters": 106143056}
{"train_lr": 0.0007114718987968146, "train_min_lr": 0.0007114718987968146, "train_mlm_acc_1": 0.10051368977940046, "train_mlm_acc_2": 0.09912410227658855, "train_loss_1": 5.253025066936446, "train_loss_2": 5.27679439558727, "train_loss": 10.529819466507844, "train_loss_scale": 10094.100263852242, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0031049664647513, "epoch": 52, "n_parameters": 106143056}
{"train_lr": 0.0007096716021291684, "train_min_lr": 0.0007096716021291684, "train_mlm_acc_1": 0.1006613508237095, "train_mlm_acc_2": 0.09922112296060999, "train_loss_1": 5.251476772385097, "train_loss_2": 5.27535338850533, "train_loss": 10.526830156119958, "train_loss_scale": 11808.872471416007, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 53, "n_parameters": 106143056}
{"train_lr": 0.0007078326170373227, "train_min_lr": 0.0007078326170373227, "train_mlm_acc_1": 0.10090093642781205, "train_mlm_acc_2": 0.09943560598190405, "train_loss_1": 5.247923237143008, "train_loss_2": 5.271688585545583, "train_loss": 10.5196118247855, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9947925948111133, "epoch": 54, "n_parameters": 106143056}
{"train_lr": 0.000705955159334333, "train_min_lr": 0.000705955159334333, "train_mlm_acc_1": 0.10089925297993836, "train_mlm_acc_2": 0.09942083299920133, "train_loss_1": 5.2476819462176465, "train_loss_2": 5.271489513685752, "train_loss": 10.51917146147608, "train_loss_scale": 8458.582233948988, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 55, "n_parameters": 106143056}
{"train_lr": 0.0007040394493481837, "train_min_lr": 0.0007040394493481837, "train_mlm_acc_1": 0.10110614345168978, "train_mlm_acc_2": 0.09963123913094231, "train_loss_1": 5.24424898294157, "train_loss_2": 5.268173541850759, "train_loss": 10.512422525683515, "train_loss_scale": 8256.844327176781, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0103721137935904, "epoch": 56, "n_parameters": 106143056}
{"train_lr": 0.0007020857118959358, "train_min_lr": 0.0007020857118959358, "train_mlm_acc_1": 0.1011917007105751, "train_mlm_acc_2": 0.09972306063665747, "train_loss_1": 5.241641807681967, "train_loss_2": 5.265508161423599, "train_loss": 10.507149965173861, "train_loss_scale": 10439.936675461742, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 57, "n_parameters": 106143056}
{"train_lr": 0.0007000941762573423, "train_min_lr": 0.0007000941762573423, "train_mlm_acc_1": 0.10132332907607919, "train_mlm_acc_2": 0.09986178913680392, "train_loss_1": 5.2399922416937805, "train_loss_2": 5.263882054397697, "train_loss": 10.503874297192354, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0224333198424904, "epoch": 58, "n_parameters": 106143056}
{"train_lr": 0.0006980650761479382, "train_min_lr": 0.0006980650761479382, "train_mlm_acc_1": 0.10149321834521537, "train_mlm_acc_2": 0.10002868945350774, "train_loss_1": 5.237133134690522, "train_loss_2": 5.26100644733996, "train_loss": 10.49813957872785, "train_loss_scale": 12154.708883025505, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 59, "n_parameters": 106143056}
{"train_lr": 0.0006959986496916213, "train_min_lr": 0.0006959986496916213, "train_mlm_acc_1": 0.10160687863384435, "train_mlm_acc_2": 0.10013843323009887, "train_loss_1": 5.235224348940971, "train_loss_2": 5.259090924483176, "train_loss": 10.494315270278783, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.025141568066472, "epoch": 60, "n_parameters": 106143056}
{"train_lr": 0.0006938951393926957, "train_min_lr": 0.0006938951393926957, "train_mlm_acc_1": 0.10116376946848164, "train_mlm_acc_2": 0.09971807905609606, "train_loss_1": 5.242108017756631, "train_loss_2": 5.265975743663238, "train_loss": 10.508083761315023, "train_loss_scale": 11790.860158311345, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 61, "n_parameters": 106143056}
{"train_lr": 0.0006917547921074234, "train_min_lr": 0.0006917547921074234, "train_mlm_acc_1": 0.10177509589882514, "train_mlm_acc_2": 0.10030560839262675, "train_loss_1": 5.23221329203172, "train_loss_2": 5.25618490574123, "train_loss": 10.48839820563636, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9907257795438708, "epoch": 62, "n_parameters": 106143056}
{"train_lr": 0.0006895778590150455, "train_min_lr": 0.0006895778590150455, "train_mlm_acc_1": 0.10197806972830098, "train_mlm_acc_2": 0.10052014863087404, "train_loss_1": 5.228926774903988, "train_loss_2": 5.252762377681497, "train_loss": 10.481689153686363, "train_loss_scale": 2692.8408091468777, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9981648985398057, "epoch": 63, "n_parameters": 106143056}
{"train_lr": 0.0006873645955883147, "train_min_lr": 0.0006873645955883147, "train_mlm_acc_1": 0.10204765157611909, "train_mlm_acc_2": 0.10055854695577997, "train_loss_1": 5.227100807056159, "train_loss_2": 5.250976124927467, "train_loss": 10.478076924434752, "train_loss_scale": 4065.3790677220754, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 64, "n_parameters": 106143056}
{"train_lr": 0.0006851152615635071, "train_min_lr": 0.0006851152615635071, "train_mlm_acc_1": 0.10215455531687356, "train_mlm_acc_2": 0.10064820400394152, "train_loss_1": 5.225389410187093, "train_loss_2": 5.249332466404377, "train_loss": 10.474721879107761, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.043787799546251, "epoch": 65, "n_parameters": 106143056}
{"train_lr": 0.0006828301209099406, "train_min_lr": 0.0006828301209099406, "train_mlm_acc_1": 0.1022340087252837, "train_mlm_acc_2": 0.10076897596185183, "train_loss_1": 5.224042438842166, "train_loss_2": 5.247802091777167, "train_loss": 10.47184453130083, "train_loss_scale": 2572.1583113456463, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0257880063358902, "epoch": 66, "n_parameters": 106143056}
{"train_lr": 0.0006805094417990081, "train_min_lr": 0.0006805094417990081, "train_mlm_acc_1": 0.10232184494934851, "train_mlm_acc_2": 0.10087295943132307, "train_loss_1": 5.222117405977811, "train_loss_2": 5.245960078484779, "train_loss": 10.468077487660377, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0271197011204487, "epoch": 67, "n_parameters": 106143056}
{"train_lr": 0.0006781534965726882, "train_min_lr": 0.0006781534965726882, "train_mlm_acc_1": 0.10250365559958584, "train_mlm_acc_2": 0.1010348094003103, "train_loss_1": 5.21942947989718, "train_loss_2": 5.243286422081128, "train_loss": 10.462715899619285, "train_loss_scale": 5832.386983289358, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 68, "n_parameters": 106143056}
{"train_lr": 0.0006757625617116008, "train_min_lr": 0.0006757625617116008, "train_mlm_acc_1": 0.10253789686665869, "train_mlm_acc_2": 0.10103621800481723, "train_loss_1": 5.218867560070444, "train_loss_2": 5.2428145241401864, "train_loss": 10.461682087722952, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0377604771100752, "epoch": 69, "n_parameters": 106143056}
{"train_lr": 0.0006733369178025507, "train_min_lr": 0.0006733369178025507, "train_mlm_acc_1": 0.10271900897663784, "train_mlm_acc_2": 0.10122483112114558, "train_loss_1": 5.216769401347731, "train_loss_2": 5.240632237262021, "train_loss": 10.45740164007759, "train_loss_scale": 5382.079155672824, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0338381966584171, "epoch": 70, "n_parameters": 106143056}
{"train_lr": 0.000670876849505609, "train_min_lr": 0.000670876849505609, "train_mlm_acc_1": 0.10278520108140815, "train_mlm_acc_2": 0.10133030331180011, "train_loss_1": 5.214665576828711, "train_loss_2": 5.238554228631257, "train_loss": 10.453219810597396, "train_loss_scale": 7017.597185576077, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 71, "n_parameters": 106143056}
{"train_lr": 0.000668382645520696, "train_min_lr": 0.000668382645520696, "train_mlm_acc_1": 0.10295040651962567, "train_mlm_acc_2": 0.1014860494393223, "train_loss_1": 5.212553420607836, "train_loss_2": 5.236303566470939, "train_loss": 10.448856985663362, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0398900210071051, "epoch": 72, "n_parameters": 106143056}
{"train_lr": 0.0006658545985537059, "train_min_lr": 0.0006658545985537059, "train_mlm_acc_1": 0.10305124066406395, "train_mlm_acc_2": 0.10154810741628957, "train_loss_1": 5.2103119425429725, "train_loss_2": 5.234215997716473, "train_loss": 10.444527940469136, "train_loss_scale": 6257.477572559366, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0168954085234287, "epoch": 73, "n_parameters": 106143056}
{"train_lr": 0.0006632930052821623, "train_min_lr": 0.0006632930052821623, "train_mlm_acc_1": 0.1030599326927382, "train_mlm_acc_2": 0.10157266028697226, "train_loss_1": 5.209305087410785, "train_loss_2": 5.2331811731178295, "train_loss": 10.442486255862992, "train_loss_scale": 4845.3122251539135, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 74, "n_parameters": 106143056}
{"train_lr": 0.0006606981663203897, "train_min_lr": 0.0006606981663203897, "train_mlm_acc_1": 0.10325917321533332, "train_mlm_acc_2": 0.10177706565262329, "train_loss_1": 5.207306000100172, "train_loss_2": 5.231210908453614, "train_loss": 10.438516910493426, "train_loss_scale": 4333.76253298153, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.06411406080662, "epoch": 75, "n_parameters": 106143056}
{"train_lr": 0.0006580703861842497, "train_min_lr": 0.0006580703861842497, "train_mlm_acc_1": 0.10330885160868379, "train_mlm_acc_2": 0.10182482014568285, "train_loss_1": 5.205703958095745, "train_loss_2": 5.22967546690737, "train_loss": 10.435379420652028, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0471384079181634, "epoch": 76, "n_parameters": 106143056}
{"train_lr": 0.0006554099732553881, "train_min_lr": 0.0006554099732553881, "train_mlm_acc_1": 0.10346274250887315, "train_mlm_acc_2": 0.10191955044210324, "train_loss_1": 5.204693941296248, "train_loss_2": 5.228548929213219, "train_loss": 10.433242868412558, "train_loss_scale": 10641.674582233949, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0894966114479507, "epoch": 77, "n_parameters": 106143056}
{"train_lr": 0.0006527172397450622, "train_min_lr": 0.0006527172397450622, "train_mlm_acc_1": 0.10356456156584157, "train_mlm_acc_2": 0.10204347161938196, "train_loss_1": 5.201481482546479, "train_loss_2": 5.225335499489632, "train_loss": 10.426816980777966, "train_loss_scale": 12111.479331574319, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 78, "n_parameters": 106143056}
{"train_lr": 0.0006499925016574828, "train_min_lr": 0.0006499925016574828, "train_mlm_acc_1": 0.10365109226650827, "train_mlm_acc_2": 0.10212918927462193, "train_loss_1": 5.201145683031074, "train_loss_2": 5.2249807094730825, "train_loss": 10.426126387209461, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.057272601253439, "epoch": 79, "n_parameters": 106143056}
{"train_lr": 0.0006472360787527486, "train_min_lr": 0.0006472360787527486, "train_mlm_acc_1": 0.10371923122453448, "train_mlm_acc_2": 0.10220342063367131, "train_loss_1": 5.199251589328444, "train_loss_2": 5.223065158255602, "train_loss": 10.422316743180536, "train_loss_scale": 10050.870712401056, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 80, "n_parameters": 106143056}
{"train_lr": 0.000644448294509309, "train_min_lr": 0.000644448294509309, "train_mlm_acc_1": 0.10385032134128959, "train_mlm_acc_2": 0.1023462489558582, "train_loss_1": 5.197541212710562, "train_loss_2": 5.221476486144406, "train_loss": 10.41901769675806, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.072711478804116, "epoch": 81, "n_parameters": 106143056}
{"train_lr": 0.0006416294760860044, "train_min_lr": 0.0006416294760860044, "train_mlm_acc_1": 0.10377610147182839, "train_mlm_acc_2": 0.10226993339517945, "train_loss_1": 5.197420451288802, "train_loss_2": 5.221241697420021, "train_loss": 10.418662152902641, "train_loss_scale": 10980.306068601583, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 82, "n_parameters": 106143056}
{"train_lr": 0.0006387799542836763, "train_min_lr": 0.0006387799542836763, "train_mlm_acc_1": 0.10402511198830479, "train_mlm_acc_2": 0.10248508061738579, "train_loss_1": 5.194151974238108, "train_loss_2": 5.218024302074127, "train_loss": 10.412176279824559, "train_loss_scale": 6851.883905013193, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 83, "n_parameters": 106143056}
{"train_lr": 0.0006359000635063394, "train_min_lr": 0.0006359000635063394, "train_mlm_acc_1": 0.10391696006806671, "train_mlm_acc_2": 0.1024192778431305, "train_loss_1": 5.196557613926807, "train_loss_2": 5.220460214212261, "train_loss": 10.41701783469191, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1761726652621805, "epoch": 84, "n_parameters": 106143056}
{"train_lr": 0.0006329901417219492, "train_min_lr": 0.0006329901417219492, "train_mlm_acc_1": 0.1042926976073897, "train_mlm_acc_2": 0.1027315488935382, "train_loss_1": 5.190279436090481, "train_loss_2": 5.214221466604617, "train_loss": 10.404500906469535, "train_loss_scale": 6423.190853122252, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.065873403400314, "epoch": 85, "n_parameters": 106143056}
{"train_lr": 0.0006300505304227264, "train_min_lr": 0.0006300505304227264, "train_mlm_acc_1": 0.10426769801149294, "train_mlm_acc_2": 0.10273689688523296, "train_loss_1": 5.189953909700338, "train_loss_2": 5.213768078867762, "train_loss": 10.403721985213046, "train_loss_scale": 7208.527704485488, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 86, "n_parameters": 106143056}
{"train_lr": 0.0006270815745850904, "train_min_lr": 0.0006270815745850904, "train_mlm_acc_1": 0.10439763147475668, "train_mlm_acc_2": 0.10283087133925503, "train_loss_1": 5.188900306860186, "train_loss_2": 5.212864008406956, "train_loss": 10.401764313799305, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0968861382785553, "epoch": 87, "n_parameters": 106143056}
{"train_lr": 0.0006240836226291734, "train_min_lr": 0.0006240836226291734, "train_mlm_acc_1": 0.10446064001507893, "train_mlm_acc_2": 0.10295631571712993, "train_loss_1": 5.186148798455244, "train_loss_2": 5.209966974134705, "train_loss": 10.396115777045882, "train_loss_scale": 6066.547053649956, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.070714321174219, "epoch": 88, "n_parameters": 106143056}
{"train_lr": 0.0006210570263779273, "train_min_lr": 0.0006210570263779273, "train_mlm_acc_1": 0.10433718827352413, "train_mlm_acc_2": 0.10281853763289953, "train_loss_1": 5.1887871689091885, "train_loss_2": 5.212756253117098, "train_loss": 10.401543420977832, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2123415471695973, "epoch": 89, "n_parameters": 106143056}
{"train_lr": 0.0006180021410158472, "train_min_lr": 0.0006180021410158472, "train_mlm_acc_1": 0.10477141072857296, "train_mlm_acc_2": 0.10322787511435222, "train_loss_1": 5.18238069755316, "train_loss_2": 5.206358187745932, "train_loss": 10.388738887815384, "train_loss_scale": 10238.198768689534, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 90, "n_parameters": 106143056}
{"train_lr": 0.0006149193250472682, "train_min_lr": 0.0006149193250472682, "train_mlm_acc_1": 0.10479521926200851, "train_mlm_acc_2": 0.10324690817538305, "train_loss_1": 5.181639308979769, "train_loss_2": 5.205534796706395, "train_loss": 10.3871741083073, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1026396621919663, "epoch": 91, "n_parameters": 106143056}
{"train_lr": 0.0006118089402543174, "train_min_lr": 0.0006118089402543174, "train_mlm_acc_1": 0.10491425052806146, "train_mlm_acc_2": 0.10335375458778602, "train_loss_1": 5.180115116670033, "train_loss_2": 5.204020057263454, "train_loss": 10.384135167433069, "train_loss_scale": 13422.775725593667, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 92, "n_parameters": 106143056}
{"train_lr": 0.0006086713516544388, "train_min_lr": 0.0006086713516544388, "train_mlm_acc_1": 0.10494692287126862, "train_mlm_acc_2": 0.10340010052876139, "train_loss_1": 5.178857017947376, "train_loss_2": 5.202813188864038, "train_loss": 10.381670204504813, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0862347151799063, "epoch": 93, "n_parameters": 106143056}
{"train_lr": 0.000605506927457566, "train_min_lr": 0.000605506927457566, "train_mlm_acc_1": 0.10511209393082319, "train_mlm_acc_2": 0.10360953329162133, "train_loss_1": 5.175849413179785, "train_loss_2": 5.199704697075494, "train_loss": 10.375554107948679, "train_loss_scale": 5799.964819700967, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 94, "n_parameters": 106143056}
{"train_lr": 0.0006023160390229106, "train_min_lr": 0.0006023160390229106, "train_mlm_acc_1": 0.10520506062091917, "train_mlm_acc_2": 0.10362418027710998, "train_loss_1": 5.175144905412837, "train_loss_2": 5.199141400942387, "train_loss": 10.37428630069357, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1156510472192822, "epoch": 95, "n_parameters": 106143056}
{"train_lr": 0.0005990990608153761, "train_min_lr": 0.0005990990608153761, "train_mlm_acc_1": 0.10531001749776939, "train_mlm_acc_2": 0.10376625275689856, "train_loss_1": 5.173373917319215, "train_loss_2": 5.197293014933168, "train_loss": 10.370666932933878, "train_loss_scale": 7475.109938434477, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0992679283507791, "epoch": 96, "n_parameters": 106143056}
{"train_lr": 0.000595856370361619, "train_min_lr": 0.000595856370361619, "train_mlm_acc_1": 0.10541535222783305, "train_mlm_acc_2": 0.10387212582663187, "train_loss_1": 5.172197617085859, "train_loss_2": 5.196210559985044, "train_loss": 10.368408179639617, "train_loss_scale": 7918.212840809147, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 97, "n_parameters": 106143056}
{"train_lr": 0.0005925883482057425, "train_min_lr": 0.0005925883482057425, "train_mlm_acc_1": 0.10556398673112469, "train_mlm_acc_2": 0.10404013691792754, "train_loss_1": 5.1704207487345375, "train_loss_2": 5.1943615114049315, "train_loss": 10.3647822611355, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.089622452527468, "epoch": 98, "n_parameters": 106143056}
{"train_lr": 0.0005892953778646349, "train_min_lr": 0.0005892953778646349, "train_mlm_acc_1": 0.10558296256291573, "train_mlm_acc_2": 0.10407034708506435, "train_loss_1": 5.16926368460282, "train_loss_2": 5.193167718492691, "train_loss": 10.362431404143965, "train_loss_scale": 5356.861917326297, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1234458516120072, "epoch": 99, "n_parameters": 106143056}
{"train_lr": 0.0005859778457829658, "train_min_lr": 0.0005859778457829658, "train_mlm_acc_1": 0.1057298906514439, "train_mlm_acc_2": 0.10415896204060227, "train_loss_1": 5.166566757277217, "train_loss_2": 5.1906351951412075, "train_loss": 10.357201951474817, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1237730736153735, "epoch": 100, "n_parameters": 106143056}
{"train_lr": 0.0005826361412878357, "train_min_lr": 0.0005826361412878357, "train_mlm_acc_1": 0.10578646315974344, "train_mlm_acc_2": 0.10427057242844985, "train_loss_1": 5.1654361698747, "train_loss_2": 5.189378314251006, "train_loss": 10.354814483916016, "train_loss_scale": 8307.278803869833, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 101, "n_parameters": 106143056}
{"train_lr": 0.0005792706565430835, "train_min_lr": 0.0005792706565430835, "train_mlm_acc_1": 0.10581303162954046, "train_mlm_acc_2": 0.10427624114241087, "train_loss_1": 5.164826567013639, "train_loss_2": 5.188771604023802, "train_loss": 10.353598174444919, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.11541898038792, "epoch": 102, "n_parameters": 106143056}
{"train_lr": 0.0005758817865032646, "train_min_lr": 0.0005758817865032646, "train_mlm_acc_1": 0.10600238915437811, "train_mlm_acc_2": 0.10447319129296793, "train_loss_1": 5.162380867813802, "train_loss_2": 5.186249355422685, "train_loss": 10.348630220720196, "train_loss_scale": 7864.175901495163, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 103, "n_parameters": 106143056}
{"train_lr": 0.0005724699288673034, "train_min_lr": 0.0005724699288673034, "train_mlm_acc_1": 0.10600843581001593, "train_mlm_acc_2": 0.10443309812889276, "train_loss_1": 5.161346414630206, "train_loss_2": 5.185348168474179, "train_loss": 10.34669458415284, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1315135897097088, "epoch": 104, "n_parameters": 106143056}
{"train_lr": 0.0005690354840318202, "train_min_lr": 0.0005690354840318202, "train_mlm_acc_1": 0.10615031359096368, "train_mlm_acc_2": 0.10460155585202452, "train_loss_1": 5.160021353575255, "train_loss_2": 5.1838764893767495, "train_loss": 10.343897838810609, "train_loss_scale": 7053.6218117854005, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1263415088963906, "epoch": 105, "n_parameters": 106143056}
{"train_lr": 0.0005655788550441483, "train_min_lr": 0.0005655788550441483, "train_mlm_acc_1": 0.10621368852276077, "train_mlm_acc_2": 0.10466373980490912, "train_loss_1": 5.158118737981104, "train_loss_2": 5.18212989761626, "train_loss": 10.340248634653754, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1049479197910614, "epoch": 106, "n_parameters": 106143056}
{"train_lr": 0.0005621004475550199, "train_min_lr": 0.0005621004475550199, "train_mlm_acc_1": 0.10616415893215041, "train_mlm_acc_2": 0.10459847531298613, "train_loss_1": 5.1596420567708785, "train_loss_2": 5.1837046479801385, "train_loss": 10.343346702811376, "train_loss_scale": 8638.705364995603, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 107, "n_parameters": 106143056}
{"train_lr": 0.0005586006697709787, "train_min_lr": 0.0005586006697709787, "train_mlm_acc_1": 0.10647402507750188, "train_mlm_acc_2": 0.10493942190341736, "train_loss_1": 5.153815278906307, "train_loss_2": 5.177859573324416, "train_loss": 10.331674850605618, "train_loss_scale": 9416.837291116975, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0950736037554611, "epoch": 108, "n_parameters": 106143056}
{"train_lr": 0.0005550799324064666, "train_min_lr": 0.0005550799324064666, "train_mlm_acc_1": 0.10654256478191182, "train_mlm_acc_2": 0.10499881154783038, "train_loss_1": 5.152685402356016, "train_loss_2": 5.176706556227507, "train_loss": 10.329391957797181, "train_loss_scale": 8264.049252418645, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 109, "n_parameters": 106143056}
{"train_lr": 0.0005515386486356223, "train_min_lr": 0.0005515386486356223, "train_mlm_acc_1": 0.10649962007766794, "train_mlm_acc_2": 0.10493689102326292, "train_loss_1": 5.152797435812501, "train_loss_2": 5.176861274473061, "train_loss": 10.32965871117675, "train_loss_scale": 8073.1187335092345, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 110, "n_parameters": 106143056}
{"train_lr": 0.0005479772340437942, "train_min_lr": 0.0005479772340437942, "train_mlm_acc_1": 0.1067099116976875, "train_mlm_acc_2": 0.10516030650189442, "train_loss_1": 5.150106651225212, "train_loss_2": 5.1740580299703725, "train_loss": 10.324164680251975, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1170858188270998, "epoch": 111, "n_parameters": 106143056}
{"train_lr": 0.0005443961065787804, "train_min_lr": 0.0005443961065787804, "train_mlm_acc_1": 0.10677448905539177, "train_mlm_acc_2": 0.1052496200755055, "train_loss_1": 5.1495430360997885, "train_loss_2": 5.173478387905614, "train_loss": 10.323021421017307, "train_loss_scale": 5482.948109058927, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.137728293474662, "epoch": 112, "n_parameters": 106143056}
{"train_lr": 0.0005407956865017628, "train_min_lr": 0.0005407956865017628, "train_mlm_acc_1": 0.10685023207876015, "train_mlm_acc_2": 0.10527936068896725, "train_loss_1": 5.148607203125849, "train_loss_2": 5.172669359436136, "train_loss": 10.321276559364199, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2013785508817607, "epoch": 113, "n_parameters": 106143056}
{"train_lr": 0.0005371763963380031, "train_min_lr": 0.0005371763963380031, "train_mlm_acc_1": 0.10701042155201958, "train_mlm_acc_2": 0.10544440578489106, "train_loss_1": 5.145309589521447, "train_loss_2": 5.169339471934863, "train_loss": 10.31464905841579, "train_loss_scale": 4949.78364116095, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 114, "n_parameters": 106143056}
{"train_lr": 0.0005335386608272497, "train_min_lr": 0.0005335386608272497, "train_mlm_acc_1": 0.10719180851601386, "train_mlm_acc_2": 0.10561682589732195, "train_loss_1": 5.143413092760842, "train_loss_2": 5.167338868349188, "train_loss": 10.310751962577866, "train_loss_scale": 4229.291116974494, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1668831767381653, "epoch": 115, "n_parameters": 106143056}
{"train_lr": 0.0005298829068738921, "train_min_lr": 0.0005298829068738921, "train_mlm_acc_1": 0.10725153028709436, "train_mlm_acc_2": 0.10567174930037011, "train_loss_1": 5.142274583287688, "train_loss_2": 5.1663730971731425, "train_loss": 10.308647679045416, "train_loss_scale": 6895.11345646438, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 116, "n_parameters": 106143056}
{"train_lr": 0.0005262095634968652, "train_min_lr": 0.0005262095634968652, "train_mlm_acc_1": 0.10727422799351531, "train_mlm_acc_2": 0.10570758235335298, "train_loss_1": 5.141776240857526, "train_loss_2": 5.165809046205136, "train_loss": 10.307585285018176, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1648764110177676, "epoch": 117, "n_parameters": 106143056}
{"train_lr": 0.0005225190617793022, "train_min_lr": 0.0005225190617793022, "train_mlm_acc_1": 0.1074114219918716, "train_mlm_acc_2": 0.10584463896729518, "train_loss_1": 5.139251406033415, "train_loss_2": 5.163204422621949, "train_loss": 10.302455824199432, "train_loss_scale": 6379.961301671065, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1827717848587371, "epoch": 118, "n_parameters": 106143056}
{"train_lr": 0.0005188118348179412, "train_min_lr": 0.0005188118348179412, "train_mlm_acc_1": 0.10758710595907721, "train_mlm_acc_2": 0.10601540995973081, "train_loss_1": 5.137058917849129, "train_loss_2": 5.161149908233968, "train_loss": 10.298208831377792, "train_loss_scale": 4290.532981530343, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 119, "n_parameters": 106143056}
{"train_lr": 0.0005150883176723058, "train_min_lr": 0.0005150883176723058, "train_mlm_acc_1": 0.1076058298103649, "train_mlm_acc_2": 0.10601472283124583, "train_loss_1": 5.135902999101654, "train_loss_2": 5.160038959487237, "train_loss": 10.295941961996368, "train_loss_scale": 4888.541776605101, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.187072675114886, "epoch": 120, "n_parameters": 106143056}
{"train_lr": 0.0005113489473136387, "train_min_lr": 0.0005113489473136387, "train_mlm_acc_1": 0.10776002994241322, "train_mlm_acc_2": 0.10617545055816885, "train_loss_1": 5.134685672996541, "train_loss_2": 5.158748256552083, "train_loss": 10.293433929705893, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1664452265518845, "epoch": 121, "n_parameters": 106143056}
{"train_lr": 0.0005075941625736347, "train_min_lr": 0.0005075941625736347, "train_mlm_acc_1": 0.10788003457652809, "train_mlm_acc_2": 0.10632845966543482, "train_loss_1": 5.1325012675061386, "train_loss_2": 5.156540781390594, "train_loss": 10.289042050416992, "train_loss_scale": 9049.386103781882, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 122, "n_parameters": 106143056}
{"train_lr": 0.0005038244040929274, "train_min_lr": 0.0005038244040929274, "train_mlm_acc_1": 0.10799064867037923, "train_mlm_acc_2": 0.106409917229241, "train_loss_1": 5.1314061134660465, "train_loss_2": 5.155551295796296, "train_loss": 10.286957408004197, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1713103096843709, "epoch": 123, "n_parameters": 106143056}
{"train_lr": 0.0005000401142693911, "train_min_lr": 0.0005000401142693911, "train_mlm_acc_1": 0.10803197868489443, "train_mlm_acc_2": 0.10639902638974243, "train_loss_1": 5.129908337546946, "train_loss_2": 5.154088083703789, "train_loss": 10.283996423295221, "train_loss_scale": 8357.713280562884, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 124, "n_parameters": 106143056}
{"train_lr": 0.0004962417372062153, "train_min_lr": 0.0004962417372062153, "train_mlm_acc_1": 0.10809976258048937, "train_mlm_acc_2": 0.1065365296191386, "train_loss_1": 5.128229703049756, "train_loss_2": 5.152355836270248, "train_loss": 10.280585542517791, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1679501077430543, "epoch": 125, "n_parameters": 106143056}
{"train_lr": 0.0004924297186597878, "train_min_lr": 0.0004924297186597878, "train_mlm_acc_1": 0.10828813518132939, "train_mlm_acc_2": 0.10672546342251168, "train_loss_1": 5.125724028524014, "train_loss_2": 5.14981144037599, "train_loss": 10.275535469948458, "train_loss_scale": 14474.694810905892, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 126, "n_parameters": 106143056}
{"train_lr": 0.0004886045059873886, "train_min_lr": 0.0004886045059873886, "train_mlm_acc_1": 0.1083538349121547, "train_mlm_acc_2": 0.1067957782039948, "train_loss_1": 5.124217269183673, "train_loss_2": 5.148303303104172, "train_loss": 10.27252057349357, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2035960767912885, "epoch": 127, "n_parameters": 106143056}
{"train_lr": 0.00048476654809468197, "train_min_lr": 0.00048476654809468197, "train_mlm_acc_1": 0.10836907738628047, "train_mlm_acc_2": 0.10678701748188484, "train_loss_1": 5.123703796452562, "train_loss_2": 5.1478825951209695, "train_loss": 10.271586394142245, "train_loss_scale": 5623.444151275286, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 128, "n_parameters": 106143056}
{"train_lr": 0.0004809162953830467, "train_min_lr": 0.0004809162953830467, "train_mlm_acc_1": 0.10848079087981002, "train_mlm_acc_2": 0.10689157354518469, "train_loss_1": 5.12272735352881, "train_loss_2": 5.146957239983054, "train_loss": 10.269684595294239, "train_loss_scale": 3224.2040457343887, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 129, "n_parameters": 106143056}
{"train_lr": 0.0004770541996967091, "train_min_lr": 0.0004770541996967091, "train_mlm_acc_1": 0.10865378361965285, "train_mlm_acc_2": 0.10703842149082515, "train_loss_1": 5.1198846285240425, "train_loss_2": 5.143949883437093, "train_loss": 10.263834506876131, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2115577774920165, "epoch": 130, "n_parameters": 106143056}
{"train_lr": 0.00047318071426971875, "train_min_lr": 0.00047318071426971875, "train_mlm_acc_1": 0.108742432916994, "train_mlm_acc_2": 0.10715670835082612, "train_loss_1": 5.119028331212234, "train_loss_2": 5.1431245098223055, "train_loss": 10.262152840720002, "train_loss_scale": 3413.3333333333335, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2108515739545764, "epoch": 131, "n_parameters": 106143056}
{"train_lr": 0.00046929629367276803, "train_min_lr": 0.00046929629367276803, "train_mlm_acc_1": 0.10884231660619915, "train_mlm_acc_2": 0.10723511968790934, "train_loss_1": 5.117336985408579, "train_loss_2": 5.141454354649379, "train_loss": 10.258791344671158, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2229674288129848, "epoch": 132, "n_parameters": 106143056}
{"train_lr": 0.00046540139375983523, "train_min_lr": 0.00046540139375983523, "train_mlm_acc_1": 0.10896711962309026, "train_mlm_acc_2": 0.10737208465463174, "train_loss_1": 5.114494798523141, "train_loss_2": 5.138638099349164, "train_loss": 10.253132892472763, "train_loss_scale": 4384.197009674583, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 133, "n_parameters": 106143056}
{"train_lr": 0.00046149647161469406, "train_min_lr": 0.00046149647161469406, "train_mlm_acc_1": 0.10913446647251843, "train_mlm_acc_2": 0.10752060464620197, "train_loss_1": 5.1133941042916025, "train_loss_2": 5.137540578684895, "train_loss": 10.250934676843038, "train_loss_scale": 4416.619173262973, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1980532062819051, "epoch": 134, "n_parameters": 106143056}
{"train_lr": 0.000457581985497272, "train_min_lr": 0.000457581985497272, "train_mlm_acc_1": 0.10917772042090786, "train_mlm_acc_2": 0.10755441065061848, "train_loss_1": 5.112341808559817, "train_loss_2": 5.136559968258901, "train_loss": 10.248901773883045, "train_loss_scale": 5011.025505716799, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 135, "n_parameters": 106143056}
{"train_lr": 0.00045365839478986964, "train_min_lr": 0.00045365839478986964, "train_mlm_acc_1": 0.10933882599285326, "train_mlm_acc_2": 0.1076967236958608, "train_loss_1": 5.109823370619416, "train_loss_2": 5.13402814663809, "train_loss": 10.243851511019201, "train_loss_scale": 4168.049252418646, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2089449363312599, "epoch": 136, "n_parameters": 106143056}
{"train_lr": 0.00044972615994325554, "train_min_lr": 0.00044972615994325554, "train_mlm_acc_1": 0.10940514412760184, "train_mlm_acc_2": 0.10779929856164422, "train_loss_1": 5.108765539728767, "train_loss_2": 5.132846774505541, "train_loss": 10.24161231255678, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2271478993387315, "epoch": 137, "n_parameters": 106143056}
{"train_lr": 0.00044578574242262216, "train_min_lr": 0.00044578574242262216, "train_mlm_acc_1": 0.10951647968846476, "train_mlm_acc_2": 0.10791485985739381, "train_loss_1": 5.106748408356988, "train_loss_2": 5.130863740398051, "train_loss": 10.237612149855916, "train_loss_scale": 10310.24802110818, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2297320524746636, "epoch": 138, "n_parameters": 106143056}
{"train_lr": 0.0004418376046534354, "train_min_lr": 0.0004418376046534354, "train_mlm_acc_1": 0.10953152750552408, "train_mlm_acc_2": 0.10794586024149637, "train_loss_1": 5.104969935870107, "train_loss_2": 5.129073497697567, "train_loss": 10.234043434301594, "train_loss_scale": 8905.287598944591, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 139, "n_parameters": 106143056}
{"train_lr": 0.00043788220996717, "train_min_lr": 0.00043788220996717, "train_mlm_acc_1": 0.10969035420321066, "train_mlm_acc_2": 0.10805247757066182, "train_loss_1": 5.103840122646476, "train_loss_2": 5.128027779707913, "train_loss": 10.231867899471139, "train_loss_scale": 8256.844327176781, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 140, "n_parameters": 106143056}
{"train_lr": 0.0004339200225469267, "train_min_lr": 0.0004339200225469267, "train_mlm_acc_1": 0.10985636126607158, "train_mlm_acc_2": 0.10824358726302022, "train_loss_1": 5.101879773584498, "train_loss_2": 5.1259892383687, "train_loss": 10.227869014102529, "train_loss_scale": 5742.325417766051, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 141, "n_parameters": 106143056}
{"train_lr": 0.0004299515073729694, "train_min_lr": 0.0004299515073729694, "train_mlm_acc_1": 0.10987896729168943, "train_mlm_acc_2": 0.1082981670940444, "train_loss_1": 5.099924348851727, "train_loss_2": 5.1240906999000035, "train_loss": 10.224015044662757, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.253036912953319, "epoch": 142, "n_parameters": 106143056}
{"train_lr": 0.0004259771301681481, "train_min_lr": 0.0004259771301681481, "train_mlm_acc_1": 0.11011807197703273, "train_mlm_acc_2": 0.10846656760022293, "train_loss_1": 5.09814717304109, "train_loss_2": 5.122358056779692, "train_loss": 10.220505236006664, "train_loss_scale": 7532.749340369393, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2541715827235655, "epoch": 143, "n_parameters": 106143056}
{"train_lr": 0.00042199735734324876, "train_min_lr": 0.00042199735734324876, "train_mlm_acc_1": 0.11001608114551979, "train_mlm_acc_2": 0.1084104417262168, "train_loss_1": 5.097843534032189, "train_loss_2": 5.121912350860099, "train_loss": 10.219755886098012, "train_loss_scale": 8847.648197009674, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2384772287614532, "epoch": 144, "n_parameters": 106143056}
{"train_lr": 0.0004180126559422584, "train_min_lr": 0.0004180126559422584, "train_mlm_acc_1": 0.11027592522884239, "train_mlm_acc_2": 0.10866095251653576, "train_loss_1": 5.095530468482351, "train_loss_2": 5.119559578604099, "train_loss": 10.21509004729614, "train_loss_scale": 7230.142480211081, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 145, "n_parameters": 106143056}
{"train_lr": 0.00041402349358755474, "train_min_lr": 0.00041402349358755474, "train_mlm_acc_1": 0.11038464982973423, "train_mlm_acc_2": 0.10874898339766705, "train_loss_1": 5.093549687241711, "train_loss_2": 5.117803285912452, "train_loss": 10.211352976247104, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2719550187271105, "epoch": 146, "n_parameters": 106143056}
{"train_lr": 0.00041003033842502425, "train_min_lr": 0.00041003033842502425, "train_mlm_acc_1": 0.1104773530825029, "train_mlm_acc_2": 0.10888764324942858, "train_loss_1": 5.091883396200685, "train_loss_2": 5.116032822517942, "train_loss": 10.207916217722595, "train_loss_scale": 5796.3623570800355, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 147, "n_parameters": 106143056}
{"train_lr": 0.00040603365906913383, "train_min_lr": 0.00040603365906913383, "train_mlm_acc_1": 0.11058646695411509, "train_mlm_acc_2": 0.10894249796149834, "train_loss_1": 5.090651628314768, "train_loss_2": 5.114788003678687, "train_loss": 10.205439630053814, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2858844990256384, "epoch": 148, "n_parameters": 106143056}
{"train_lr": 0.000402033924547923, "train_min_lr": 0.000402033924547923, "train_mlm_acc_1": 0.11072692475564247, "train_mlm_acc_2": 0.10906814846718846, "train_loss_1": 5.088345426735169, "train_loss_2": 5.112672371988037, "train_loss": 10.201017800086197, "train_loss_scale": 4337.364995602463, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 149, "n_parameters": 106143056}
{"train_lr": 0.0003980316042479732, "train_min_lr": 0.0003980316042479732, "train_mlm_acc_1": 0.1108211511590419, "train_mlm_acc_2": 0.10923901111175853, "train_loss_1": 5.086613702113522, "train_loss_2": 5.11077199531629, "train_loss": 10.197385694441715, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.32830270975435, "epoch": 150, "n_parameters": 106143056}
{"train_lr": 0.000394027167859318, "train_min_lr": 0.000394027167859318, "train_mlm_acc_1": 0.11093373499931923, "train_mlm_acc_2": 0.10929380854789951, "train_loss_1": 5.085173379829712, "train_loss_2": 5.10940300123463, "train_loss": 10.194576386516307, "train_loss_scale": 5554.997361477573, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 151, "n_parameters": 106143056}
{"train_lr": 0.00039002108532032085, "train_min_lr": 0.00039002108532032085, "train_mlm_acc_1": 0.11103037778589557, "train_mlm_acc_2": 0.10938890528330283, "train_loss_1": 5.083703348693244, "train_loss_2": 5.107911823712217, "train_loss": 10.19161517680897, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3403840972964136, "epoch": 152, "n_parameters": 106143056}
{"train_lr": 0.00038601382676252893, "train_min_lr": 0.00038601382676252893, "train_mlm_acc_1": 0.11116513249643717, "train_mlm_acc_2": 0.10949961101290628, "train_loss_1": 5.081948596233848, "train_loss_2": 5.10621401612551, "train_loss": 10.18816261335539, "train_loss_scale": 4564.320140721196, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 153, "n_parameters": 106143056}
{"train_lr": 0.0003820058624555032, "train_min_lr": 0.0003820058624555032, "train_mlm_acc_1": 0.11126570325105622, "train_mlm_acc_2": 0.10967641718040172, "train_loss_1": 5.0796618280750465, "train_loss_2": 5.103785217856774, "train_loss": 10.183447045617283, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.329302929636671, "epoch": 154, "n_parameters": 106143056}
{"train_lr": 0.000377997662751625, "train_min_lr": 0.000377997662751625, "train_mlm_acc_1": 0.11140965390049426, "train_mlm_acc_2": 0.10978210703678684, "train_loss_1": 5.078278613488928, "train_loss_2": 5.102494668677489, "train_loss": 10.180773272677902, "train_loss_scale": 2545.1398416886545, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3280217573112212, "epoch": 155, "n_parameters": 106143056}
{"train_lr": 0.0003739896980309009, "train_min_lr": 0.0003739896980309009, "train_mlm_acc_1": 0.11148829430361379, "train_mlm_acc_2": 0.10988502534763296, "train_loss_1": 5.076131277054994, "train_loss_2": 5.100387721755784, "train_loss": 10.1765189965566, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3566641425394446, "epoch": 156, "n_parameters": 106143056}
{"train_lr": 0.0003699824386457607, "train_min_lr": 0.0003699824386457607, "train_mlm_acc_1": 0.11164181867635685, "train_mlm_acc_2": 0.11000003697958398, "train_loss_1": 5.0744732008655555, "train_loss_2": 5.098665008758807, "train_loss": 10.173138210305858, "train_loss_scale": 4409.4142480211085, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 157, "n_parameters": 106143056}
{"train_lr": 0.00036597635486586153, "train_min_lr": 0.00036597635486586153, "train_mlm_acc_1": 0.11167232661443315, "train_mlm_acc_2": 0.11002670854031908, "train_loss_1": 5.0730368598260265, "train_loss_2": 5.097333783681915, "train_loss": 10.170370641358609, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.318765284885098, "epoch": 158, "n_parameters": 106143056}
{"train_lr": 0.0003619719168228958, "train_min_lr": 0.0003619719168228958, "train_mlm_acc_1": 0.11186862399141413, "train_mlm_acc_2": 0.1102555522673887, "train_loss_1": 5.0706866743172485, "train_loss_2": 5.094728130463874, "train_loss": 10.165414809237054, "train_loss_scale": 4762.455584872471, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 159, "n_parameters": 106143056}
{"train_lr": 0.00035796959445542426, "train_min_lr": 0.00035796959445542426, "train_mlm_acc_1": 0.11203850178570604, "train_mlm_acc_2": 0.11037035777562001, "train_loss_1": 5.068351894957829, "train_loss_2": 5.0925527100198185, "train_loss": 10.160904608594816, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3030078647004584, "epoch": 160, "n_parameters": 106143056}
{"train_lr": 0.0003539698574537211, "train_min_lr": 0.0003539698574537211, "train_mlm_acc_1": 0.1121725693890594, "train_mlm_acc_2": 0.11054674027735005, "train_loss_1": 5.06710887123014, "train_loss_2": 5.09129025779907, "train_loss": 10.158399129186478, "train_loss_scale": 5882.82145998241, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 161, "n_parameters": 106143056}
{"train_lr": 0.0003499731752046559, "train_min_lr": 0.0003499731752046559, "train_mlm_acc_1": 0.11224550666597163, "train_mlm_acc_2": 0.11057254141188418, "train_loss_1": 5.065514165052952, "train_loss_2": 5.089758562852965, "train_loss": 10.15527273157551, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3611018095712653, "epoch": 162, "n_parameters": 106143056}
{"train_lr": 0.0003459800167366142, "train_min_lr": 0.0003459800167366142, "train_mlm_acc_1": 0.1123738712250282, "train_mlm_acc_2": 0.11068759888259853, "train_loss_1": 5.064233376357046, "train_loss_2": 5.088527732337894, "train_loss": 10.152761109690973, "train_loss_scale": 4434.631486367634, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 163, "n_parameters": 106143056}
{"train_lr": 0.0003419908506644451, "train_min_lr": 0.0003419908506644451, "train_mlm_acc_1": 0.11243173778188155, "train_mlm_acc_2": 0.11075637909430575, "train_loss_1": 5.062287394845287, "train_loss_2": 5.0865036812705124, "train_loss": 10.148791080204772, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4053591254938036, "epoch": 164, "n_parameters": 106143056}
{"train_lr": 0.00033800614513447493, "train_min_lr": 0.00033800614513447493, "train_mlm_acc_1": 0.11261475099645483, "train_mlm_acc_2": 0.11095776111985128, "train_loss_1": 5.060352098239338, "train_loss_2": 5.084553655869309, "train_loss": 10.144905754842565, "train_loss_scale": 3355.6939313984167, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 165, "n_parameters": 106143056}
{"train_lr": 0.00033402636776956357, "train_min_lr": 0.00033402636776956357, "train_mlm_acc_1": 0.11264910673429385, "train_mlm_acc_2": 0.11100426740475858, "train_loss_1": 5.059497576799955, "train_loss_2": 5.08367572327717, "train_loss": 10.143173299867433, "train_loss_scale": 1611.2014072119614, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 166, "n_parameters": 106143056}
{"train_lr": 0.000330051985614231, "train_min_lr": 0.000330051985614231, "train_mlm_acc_1": 0.11282869572640644, "train_mlm_acc_2": 0.1111353002627861, "train_loss_1": 5.056710700561, "train_loss_2": 5.081001529330838, "train_loss": 10.137712231516943, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3697709669223876, "epoch": 167, "n_parameters": 106143056}
{"train_lr": 0.0003260834650798454, "train_min_lr": 0.0003260834650798454, "train_mlm_acc_1": 0.11294338669015214, "train_mlm_acc_2": 0.11132649006854445, "train_loss_1": 5.054623082476744, "train_loss_2": 5.078799114378272, "train_loss": 10.133422195649294, "train_loss_scale": 1707.5672823218997, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3603773965265211, "epoch": 168, "n_parameters": 106143056}
{"train_lr": 0.00032212127188988656, "train_min_lr": 0.00032212127188988656, "train_mlm_acc_1": 0.11308111897002161, "train_mlm_acc_2": 0.11144321950573537, "train_loss_1": 5.052783678945157, "train_loss_2": 5.077141009775714, "train_loss": 10.129924687986952, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3814668692615646, "epoch": 169, "n_parameters": 106143056}
{"train_lr": 0.0003181658710252925, "train_min_lr": 0.0003181658710252925, "train_mlm_acc_1": 0.11322879147197373, "train_mlm_acc_2": 0.11160929524892632, "train_loss_1": 5.051188532993683, "train_loss_2": 5.075521435408395, "train_loss": 10.126709971809555, "train_loss_scale": 3908.6719437115216, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3974391665496424, "epoch": 170, "n_parameters": 106143056}
{"train_lr": 0.0003142177266698921, "train_min_lr": 0.0003142177266698921, "train_mlm_acc_1": 0.11329114719858376, "train_mlm_acc_2": 0.1116524002799009, "train_loss_1": 5.0495171114972734, "train_loss_2": 5.073657632922539, "train_loss": 10.123174750081468, "train_loss_scale": 4708.418645558488, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3931278170151153, "epoch": 171, "n_parameters": 106143056}
{"train_lr": 0.00031027730215593045, "train_min_lr": 0.00031027730215593045, "train_mlm_acc_1": 0.11347680570674026, "train_mlm_acc_2": 0.11181686133172497, "train_loss_1": 5.047201516131298, "train_loss_2": 5.0715038745468295, "train_loss": 10.118705397545504, "train_loss_scale": 4665.1890941073, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 172, "n_parameters": 106143056}
{"train_lr": 0.0003063450599096958, "train_min_lr": 0.0003063450599096958, "train_mlm_acc_1": 0.11362624180518753, "train_mlm_acc_2": 0.1119411604523187, "train_loss_1": 5.045201772645365, "train_loss_2": 5.069541312826235, "train_loss": 10.11474308374165, "train_loss_scale": 3099.919085312225, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 173, "n_parameters": 106143056}
{"train_lr": 0.0003024214613972495, "train_min_lr": 0.0003024214613972495, "train_mlm_acc_1": 0.11376489019684867, "train_mlm_acc_2": 0.11211817280005208, "train_loss_1": 5.04285202816902, "train_loss_2": 5.066968032007376, "train_loss": 10.109820070241561, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.407207769055899, "epoch": 174, "n_parameters": 106143056}
{"train_lr": 0.0002985069670702745, "train_min_lr": 0.0002985069670702745, "train_mlm_acc_1": 0.11381698501433132, "train_mlm_acc_2": 0.11214647047949027, "train_loss_1": 5.042401673454093, "train_loss_2": 5.066687412081628, "train_loss": 10.109089079611953, "train_loss_scale": 3537.618293755497, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4524246473635303, "epoch": 175, "n_parameters": 106143056}
{"train_lr": 0.0002946020363120353, "train_min_lr": 0.0002946020363120353, "train_mlm_acc_1": 0.1138892695831959, "train_mlm_acc_2": 0.11224248341596771, "train_loss_1": 5.040744092711883, "train_loss_2": 5.064959428660578, "train_loss": 10.105703522578183, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.465998529287001, "epoch": 176, "n_parameters": 106143056}
{"train_lr": 0.0002907071273834704, "train_min_lr": 0.0002907071273834704, "train_mlm_acc_1": 0.11404538211120308, "train_mlm_acc_2": 0.11241024251693078, "train_loss_1": 5.038546249807772, "train_loss_2": 5.0626591901141715, "train_loss": 10.101205436514466, "train_loss_scale": 4225.688654353562, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 177, "n_parameters": 106143056}
{"train_lr": 0.0002868226973694113, "train_min_lr": 0.0002868226973694113, "train_mlm_acc_1": 0.1142108852916914, "train_mlm_acc_2": 0.11252032989339547, "train_loss_1": 5.037369290882805, "train_loss_2": 5.061620180975898, "train_loss": 10.09898947180628, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4430419924286446, "epoch": 178, "n_parameters": 106143056}
{"train_lr": 0.00028294920212494217, "train_min_lr": 0.00028294920212494217, "train_mlm_acc_1": 0.11430429853253204, "train_mlm_acc_2": 0.11263768919542917, "train_loss_1": 5.034913330981893, "train_loss_2": 5.0591250697876555, "train_loss": 10.094038399983207, "train_loss_scale": 3269.234828496042, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.449792965001565, "epoch": 179, "n_parameters": 106143056}
{"train_lr": 0.00027908709622190573, "train_min_lr": 0.00027908709622190573, "train_mlm_acc_1": 0.11450679142850476, "train_mlm_acc_2": 0.11282984089686247, "train_loss_1": 5.032280182513419, "train_loss_2": 5.056527848818266, "train_loss": 10.088808032642254, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4612145453245888, "epoch": 180, "n_parameters": 106143056}
{"train_lr": 0.00027523683289555303, "train_min_lr": 0.00027523683289555303, "train_mlm_acc_1": 0.11470212684018684, "train_mlm_acc_2": 0.11301649579648895, "train_loss_1": 5.0301249469700045, "train_loss_2": 5.054418861708729, "train_loss": 10.084543808049661, "train_loss_scale": 5093.882145998241, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 181, "n_parameters": 106143056}
{"train_lr": 0.0002713988639913556, "train_min_lr": 0.0002713988639913556, "train_mlm_acc_1": 0.11474723594628516, "train_mlm_acc_2": 0.11308330627979027, "train_loss_1": 5.0289093533312945, "train_loss_2": 5.05316200005767, "train_loss": 10.08207134888061, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4244149867232263, "epoch": 182, "n_parameters": 106143056}
{"train_lr": 0.00026757363991198143, "train_min_lr": 0.00026757363991198143, "train_mlm_acc_1": 0.1150068624318629, "train_mlm_acc_2": 0.11334222272651151, "train_loss_1": 5.025762732131709, "train_loss_2": 5.050126565897161, "train_loss": 10.07588930012578, "train_loss_scale": 4247.303430079156, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 183, "n_parameters": 106143056}
{"train_lr": 0.00026376160956443706, "train_min_lr": 0.00026376160956443706, "train_mlm_acc_1": 0.11510892200841517, "train_mlm_acc_2": 0.11344310271462775, "train_loss_1": 5.023915387657303, "train_loss_2": 5.048256996543971, "train_loss": 10.072172386350607, "train_loss_scale": 4254.508355321021, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.472190075205834, "epoch": 184, "n_parameters": 106143056}
{"train_lr": 0.00025996322030738496, "train_min_lr": 0.00025996322030738496, "train_mlm_acc_1": 0.11515631000105891, "train_mlm_acc_2": 0.11346908713786771, "train_loss_1": 5.022799834622138, "train_loss_2": 5.047102869133626, "train_loss": 10.069902694529363, "train_loss_scale": 4193.2664907651715, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 185, "n_parameters": 106143056}
{"train_lr": 0.00025617891789864574, "train_min_lr": 0.00025617891789864574, "train_mlm_acc_1": 0.11525749914731466, "train_mlm_acc_2": 0.11357605949506203, "train_loss_1": 5.021750893735424, "train_loss_2": 5.045961801850597, "train_loss": 10.067712693960916, "train_loss_scale": 4211.278803869833, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 186, "n_parameters": 106143056}
{"train_lr": 0.0002524091464428861, "train_min_lr": 0.0002524091464428861, "train_mlm_acc_1": 0.1155227828802002, "train_mlm_acc_2": 0.1138050292177075, "train_loss_1": 5.018430596867883, "train_loss_2": 5.0427172351218985, "train_loss": 10.061147832618854, "train_loss_scale": 2428.0598065083555, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 187, "n_parameters": 106143056}
{"train_lr": 0.00024865434833949967, "train_min_lr": 0.00024865434833949967, "train_mlm_acc_1": 0.11562167025902681, "train_mlm_acc_2": 0.11391994921062977, "train_loss_1": 5.017334752682541, "train_loss_2": 5.041690128407357, "train_loss": 10.05902488554583, "train_loss_scale": 2161.4775725593668, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5098316447191733, "epoch": 188, "n_parameters": 106143056}
{"train_lr": 0.0002449149642306928, "train_min_lr": 0.0002449149642306928, "train_mlm_acc_1": 0.11575861231865413, "train_mlm_acc_2": 0.1140435497868698, "train_loss_1": 5.014531538060808, "train_loss_2": 5.038881619404362, "train_loss": 10.053413160348422, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5213264295063003, "epoch": 189, "n_parameters": 106143056}
{"train_lr": 0.0002411914329497703, "train_min_lr": 0.0002411914329497703, "train_mlm_acc_1": 0.11597425193282576, "train_mlm_acc_2": 0.11430931454090272, "train_loss_1": 5.011557969537448, "train_loss_2": 5.035940300768263, "train_loss": 10.04749826663612, "train_loss_scale": 5310.029903254178, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.531151345505878, "epoch": 190, "n_parameters": 106143056}
{"train_lr": 0.000237484191469636, "train_min_lr": 0.000237484191469636, "train_mlm_acc_1": 0.11604535690670147, "train_mlm_acc_2": 0.11431977012265955, "train_loss_1": 5.0105739532590645, "train_loss_2": 5.034775761207574, "train_loss": 10.04534971084947, "train_loss_scale": 3434.948109058927, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 191, "n_parameters": 106143056}
{"train_lr": 0.00023379367485151643, "train_min_lr": 0.00023379367485151643, "train_mlm_acc_1": 0.11615027944011026, "train_mlm_acc_2": 0.11444015270500406, "train_loss_1": 5.009038735243346, "train_loss_2": 5.033221049589763, "train_loss": 10.042259780796558, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5074531745260602, "epoch": 192, "n_parameters": 106143056}
{"train_lr": 0.00023012031619389827, "train_min_lr": 0.00023012031619389827, "train_mlm_acc_1": 0.11626994050875399, "train_mlm_acc_2": 0.11455942446524858, "train_loss_1": 5.006784979407999, "train_loss_2": 5.031193568922494, "train_loss": 10.037978548068379, "train_loss_scale": 3505.1961301671063, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5451012938402153, "epoch": 193, "n_parameters": 106143056}
{"train_lr": 0.00022646454658170753, "train_min_lr": 0.00022646454658170753, "train_mlm_acc_1": 0.1164370584297555, "train_mlm_acc_2": 0.11473831490809286, "train_loss_1": 5.004817671857597, "train_loss_2": 5.0291681587433965, "train_loss": 10.03398583033888, "train_loss_scale": 2968.429199648197, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 194, "n_parameters": 106143056}
{"train_lr": 0.00022282679503571708, "train_min_lr": 0.00022282679503571708, "train_mlm_acc_1": 0.1165881550771724, "train_mlm_acc_2": 0.11487957439651564, "train_loss_1": 5.003258700368692, "train_loss_2": 5.027514192129083, "train_loss": 10.03077289317927, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5327348964405143, "epoch": 195, "n_parameters": 106143056}
{"train_lr": 0.00021920748846219963, "train_min_lr": 0.00021920748846219963, "train_mlm_acc_1": 0.11676070114176658, "train_mlm_acc_2": 0.11506925252894482, "train_loss_1": 5.000265790740963, "train_loss_2": 5.024618465908809, "train_loss": 10.024884259375755, "train_loss_scale": 3669.108179419525, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.587439967386536, "epoch": 196, "n_parameters": 106143056}
{"train_lr": 0.00021560705160282874, "train_min_lr": 0.00021560705160282874, "train_mlm_acc_1": 0.11690310575723281, "train_mlm_acc_2": 0.11519681545434783, "train_loss_1": 4.998299007103332, "train_loss_2": 5.022711228150071, "train_loss": 10.021010234571909, "train_loss_scale": 4229.291116974494, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5804639319211848, "epoch": 197, "n_parameters": 106143056}
{"train_lr": 0.0002120259069848334, "train_min_lr": 0.0002120259069848334, "train_mlm_acc_1": 0.1169905183114367, "train_mlm_acc_2": 0.11529523322871488, "train_loss_1": 4.996636335904282, "train_loss_2": 5.020897794734415, "train_loss": 10.017534126602145, "train_loss_scale": 5338.849604221636, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 198, "n_parameters": 106143056}
{"train_lr": 0.00020846447487141197, "train_min_lr": 0.00020846447487141197, "train_mlm_acc_1": 0.11714264560775896, "train_mlm_acc_2": 0.11544171475912644, "train_loss_1": 4.994871928436041, "train_loss_2": 5.019279810767899, "train_loss": 10.014151738941827, "train_loss_scale": 2732.467897977133, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 199, "n_parameters": 106143056}
{"train_lr": 0.0002049231732124145, "train_min_lr": 0.0002049231732124145, "train_mlm_acc_1": 0.11730371685182592, "train_mlm_acc_2": 0.11561048170920254, "train_loss_1": 4.9929454989252955, "train_loss_2": 5.017203783716354, "train_loss": 10.01014927939144, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6374111796746469, "epoch": 200, "n_parameters": 106143056}
{"train_lr": 0.00020140241759529154, "train_min_lr": 0.00020140241759529154, "train_mlm_acc_1": 0.11743481840001273, "train_mlm_acc_2": 0.11573833098885723, "train_loss_1": 4.99109853766105, "train_loss_2": 5.015453548733351, "train_loss": 10.006552086341978, "train_loss_scale": 2602.779243623571, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 201, "n_parameters": 106143056}
{"train_lr": 0.00019790262119632546, "train_min_lr": 0.00019790262119632546, "train_mlm_acc_1": 0.1175449400945266, "train_mlm_acc_2": 0.11585033072032552, "train_loss_1": 4.989267004773401, "train_loss_2": 5.013569454352061, "train_loss": 10.002836454617107, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5865485693869512, "epoch": 202, "n_parameters": 106143056}
{"train_lr": 0.0001944241947321401, "train_min_lr": 0.0001944241947321401, "train_mlm_acc_1": 0.11772798762714905, "train_mlm_acc_2": 0.11602966775814613, "train_loss_1": 4.986476212975846, "train_loss_2": 5.010808572815297, "train_loss": 9.997284782907894, "train_loss_scale": 3843.8276165347406, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6164532846385382, "epoch": 203, "n_parameters": 106143056}
{"train_lr": 0.00019096754641150413, "train_min_lr": 0.00019096754641150413, "train_mlm_acc_1": 0.11787627848797366, "train_mlm_acc_2": 0.11612640218866585, "train_loss_1": 4.984434852656714, "train_loss_2": 5.008894337932583, "train_loss": 9.993329195988839, "train_loss_scale": 4283.328056288478, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 204, "n_parameters": 106143056}
{"train_lr": 0.00018753308188742345, "train_min_lr": 0.00018753308188742345, "train_mlm_acc_1": 0.11796916500733233, "train_mlm_acc_2": 0.11622938927321998, "train_loss_1": 4.982450799765876, "train_loss_2": 5.006871679055659, "train_loss": 9.98932247562375, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.668589837737742, "epoch": 205, "n_parameters": 106143056}
{"train_lr": 0.00018412120420953888, "train_min_lr": 0.00018412120420953888, "train_mlm_acc_1": 0.1181756202647546, "train_mlm_acc_2": 0.11645886287496163, "train_loss_1": 4.9798449597132235, "train_loss_2": 5.004144930011259, "train_loss": 9.983989895700674, "train_loss_scale": 1308.5945470536499, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 206, "n_parameters": 106143056}
{"train_lr": 0.00018073231377682198, "train_min_lr": 0.00018073231377682198, "train_mlm_acc_1": 0.11831762403472537, "train_mlm_acc_2": 0.11657443563818355, "train_loss_1": 4.979021143577763, "train_loss_2": 5.003422326913714, "train_loss": 9.982443472011738, "train_loss_scale": 1043.8135444151276, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.648312351215064, "epoch": 207, "n_parameters": 106143056}
{"train_lr": 0.0001773668082905917, "train_min_lr": 0.0001773668082905917, "train_mlm_acc_1": 0.11836572211045729, "train_mlm_acc_2": 0.11669265381212075, "train_loss_1": 4.976777925183088, "train_loss_2": 5.001092179784045, "train_loss": 9.977870107745536, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6512305949378034, "epoch": 208, "n_parameters": 106143056}
{"train_lr": 0.00017402508270783777, "train_min_lr": 0.00017402508270783777, "train_mlm_acc_1": 0.11864546963596093, "train_mlm_acc_2": 0.11688900849206099, "train_loss_1": 4.97329792629341, "train_loss_2": 4.997603066730835, "train_loss": 9.970900990298261, "train_loss_scale": 2581.164467897977, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6765598349646718, "epoch": 209, "n_parameters": 106143056}
{"train_lr": 0.0001707075291948745, "train_min_lr": 0.0001707075291948745, "train_mlm_acc_1": 0.11881289674458974, "train_mlm_acc_2": 0.11708732135266249, "train_loss_1": 4.971557109997581, "train_loss_2": 4.995825553370235, "train_loss": 9.967382661899979, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6332177485723505, "epoch": 210, "n_parameters": 106143056}
{"train_lr": 0.0001674145370813154, "train_min_lr": 0.0001674145370813154, "train_mlm_acc_1": 0.11901866475475678, "train_mlm_acc_2": 0.11730131194676971, "train_loss_1": 4.969947915645472, "train_loss_2": 4.994238436798726, "train_loss": 9.964186354698375, "train_loss_scale": 2653.2137203166226, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 211, "n_parameters": 106143056}
{"train_lr": 0.0001641464928143861, "train_min_lr": 0.0001641464928143861, "train_mlm_acc_1": 0.11907946304217466, "train_mlm_acc_2": 0.11736752693651928, "train_loss_1": 4.967936789192646, "train_loss_2": 4.9922839158338315, "train_loss": 9.960220699784204, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6866705563368247, "epoch": 212, "n_parameters": 106143056}
{"train_lr": 0.0001609037799135703, "train_min_lr": 0.0001609037799135703, "train_mlm_acc_1": 0.11920480435286553, "train_mlm_acc_2": 0.11749730005421288, "train_loss_1": 4.965986462203473, "train_loss_2": 4.99027869621703, "train_loss": 9.956265159206843, "train_loss_scale": 3146.751099384345, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 213, "n_parameters": 106143056}
{"train_lr": 0.00015768677892560474, "train_min_lr": 0.00015768677892560474, "train_mlm_acc_1": 0.11934415127249826, "train_mlm_acc_2": 0.11758607542985951, "train_loss_1": 4.963792244436034, "train_loss_2": 4.988218845666871, "train_loss": 9.952011086590582, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6469317637416703, "epoch": 214, "n_parameters": 106143056}
{"train_lr": 0.0001544958673798188, "train_min_lr": 0.0001544958673798188, "train_mlm_acc_1": 0.11946468274031251, "train_mlm_acc_2": 0.1177052555215875, "train_loss_1": 4.962042856342245, "train_loss_2": 4.986440646721799, "train_loss": 9.948483505790026, "train_loss_scale": 3379.1099384344766, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.715402681993201, "epoch": 215, "n_parameters": 106143056}
{"train_lr": 0.00015133141974383045, "train_min_lr": 0.00015133141974383045, "train_mlm_acc_1": 0.11966245741769344, "train_mlm_acc_2": 0.11791535245013819, "train_loss_1": 4.959292986462173, "train_loss_2": 4.983760378186705, "train_loss": 9.943053365802177, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7147300557389842, "epoch": 216, "n_parameters": 106143056}
{"train_lr": 0.00014819380737959978, "train_min_lr": 0.00014819380737959978, "train_mlm_acc_1": 0.11982814378040395, "train_mlm_acc_2": 0.11815812169486557, "train_loss_1": 4.956964132077042, "train_loss_2": 4.981196407592391, "train_loss": 9.938160537729791, "train_loss_scale": 2233.5268249780124, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 217, "n_parameters": 106143056}
{"train_lr": 0.0001450833984998489, "train_min_lr": 0.0001450833984998489, "train_mlm_acc_1": 0.119943327190995, "train_mlm_acc_2": 0.11821722506775653, "train_loss_1": 4.955355033763375, "train_loss_2": 4.97976712705592, "train_loss": 9.935122167948787, "train_loss_scale": 2356.01055408971, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8079385501623364, "epoch": 218, "n_parameters": 106143056}
{"train_lr": 0.0001420005581248513, "train_min_lr": 0.0001420005581248513, "train_mlm_acc_1": 0.12016796809354946, "train_mlm_acc_2": 0.11843072321419927, "train_loss_1": 4.9529728787765235, "train_loss_2": 4.97745384971825, "train_loss": 9.930426731168332, "train_loss_scale": 2067.8135444151276, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 219, "n_parameters": 106143056}
{"train_lr": 0.00013894564803959363, "train_min_lr": 0.00013894564803959363, "train_mlm_acc_1": 0.12021816187032819, "train_mlm_acc_2": 0.11848508550563504, "train_loss_1": 4.952258304429872, "train_loss_2": 4.976682656830408, "train_loss": 9.928940960893321, "train_loss_scale": 2057.0061565523306, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 220, "n_parameters": 106143056}
{"train_lr": 0.00013591902675131893, "train_min_lr": 0.00013591902675131893, "train_mlm_acc_1": 0.12039590708128355, "train_mlm_acc_2": 0.11867169453209575, "train_loss_1": 4.949829340924688, "train_loss_2": 4.974157148479052, "train_loss": 9.923986492811219, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7926033521390528, "epoch": 221, "n_parameters": 106143056}
{"train_lr": 0.00013292104944745455, "train_min_lr": 0.00013292104944745455, "train_mlm_acc_1": 0.12054185031216162, "train_mlm_acc_2": 0.11877753313797917, "train_loss_1": 4.947448465996073, "train_loss_2": 4.971875579134875, "train_loss": 9.919324042614658, "train_loss_scale": 1401.357959542656, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 222, "n_parameters": 106143056}
{"train_lr": 0.00012995206795392967, "train_min_lr": 0.00012995206795392967, "train_mlm_acc_1": 0.12076494522251864, "train_mlm_acc_2": 0.11900874745451313, "train_loss_1": 4.944639372217519, "train_loss_2": 4.969050727607707, "train_loss": 9.913690100978526, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.689444828106839, "epoch": 223, "n_parameters": 106143056}
{"train_lr": 0.00012701243069388645, "train_min_lr": 0.00012701243069388645, "train_mlm_acc_1": 0.12083948575854694, "train_mlm_acc_2": 0.11909336563881254, "train_loss_1": 4.943277521728945, "train_loss_2": 4.967570393412598, "train_loss": 9.91084791393582, "train_loss_scale": 1917.410729991205, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8140818643905452, "epoch": 224, "n_parameters": 106143056}
{"train_lr": 0.0001241024826467912, "train_min_lr": 0.0001241024826467912, "train_mlm_acc_1": 0.12100648917274168, "train_mlm_acc_2": 0.1192648581359388, "train_loss_1": 4.940679580576083, "train_loss_2": 4.9649780626452165, "train_loss": 9.905657641386503, "train_loss_scale": 2280.358839050132, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7886133407854468, "epoch": 225, "n_parameters": 106143056}
{"train_lr": 0.00012122256530794866, "train_min_lr": 0.00012122256530794866, "train_mlm_acc_1": 0.12120484785981994, "train_mlm_acc_2": 0.11944562681314184, "train_loss_1": 4.938933556239229, "train_loss_2": 4.963222356092123, "train_loss": 9.902155911387743, "train_loss_scale": 1301.3896218117854, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 226, "n_parameters": 106143056}
{"train_lr": 0.00011837301664842798, "train_min_lr": 0.00011837301664842798, "train_mlm_acc_1": 0.12131784391968709, "train_mlm_acc_2": 0.1195674522639815, "train_loss_1": 4.936882134110863, "train_loss_2": 4.961253944623858, "train_loss": 9.898136079258949, "train_loss_scale": 1153.688654353562, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8663866289267963, "epoch": 227, "n_parameters": 106143056}
{"train_lr": 0.00011555417107539845, "train_min_lr": 0.00011555417107539845, "train_mlm_acc_1": 0.12145117865080832, "train_mlm_acc_2": 0.11969556490970135, "train_loss_1": 4.935150442148576, "train_loss_2": 4.959396782105915, "train_loss": 9.894547223730264, "train_loss_scale": 1317.6007036059807, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 228, "n_parameters": 106143056}
{"train_lr": 0.00011276635939288607, "train_min_lr": 0.00011276635939288607, "train_mlm_acc_1": 0.12167707919458495, "train_mlm_acc_2": 0.11995143518376057, "train_loss_1": 4.932668384796921, "train_loss_2": 4.956877023951464, "train_loss": 9.889545405131217, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.788747507380936, "epoch": 229, "n_parameters": 106143056}
{"train_lr": 0.00011000990876295262, "train_min_lr": 0.00011000990876295262, "train_mlm_acc_1": 0.12181505193096719, "train_mlm_acc_2": 0.12004844437655562, "train_loss_1": 4.930721367936231, "train_loss_2": 4.954923677046045, "train_loss": 9.88564504199418, "train_loss_scale": 1704.8654353562006, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 230, "n_parameters": 106143056}
{"train_lr": 0.00010728514266730062, "train_min_lr": 0.00010728514266730062, "train_mlm_acc_1": 0.12196312525793714, "train_mlm_acc_2": 0.12018387479152245, "train_loss_1": 4.92820054276952, "train_loss_2": 4.952541732117075, "train_loss": 9.880742270797622, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.77830202147535, "epoch": 231, "n_parameters": 106143056}
{"train_lr": 0.00010459238086931266, "train_min_lr": 0.00010459238086931266, "train_mlm_acc_1": 0.12210018181372287, "train_mlm_acc_2": 0.1203157436479417, "train_loss_1": 4.926703892680984, "train_loss_2": 4.951010031456893, "train_loss": 9.877713920992512, "train_loss_scale": 1567.071240105541, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7869456809869229, "epoch": 232, "n_parameters": 106143056}
{"train_lr": 0.0001019319393765248, "train_min_lr": 0.0001019319393765248, "train_mlm_acc_1": 0.12217802058155063, "train_mlm_acc_2": 0.12040643140480328, "train_loss_1": 4.925296779777675, "train_loss_2": 4.949588682479574, "train_loss": 9.87488546325328, "train_loss_scale": 1366.2339489885665, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 233, "n_parameters": 106143056}
{"train_lr": 9.930413040354184e-05, "train_min_lr": 9.930413040354184e-05, "train_mlm_acc_1": 0.12232071147263443, "train_mlm_acc_2": 0.12054613338522908, "train_loss_1": 4.9233610368445975, "train_loss_2": 4.947622564243662, "train_loss": 9.870983599882537, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.846086461290311, "epoch": 234, "n_parameters": 106143056}
{"train_lr": 9.670926233539824e-05, "train_min_lr": 9.670926233539824e-05, "train_mlm_acc_1": 0.12255444516990541, "train_mlm_acc_2": 0.12082815979809722, "train_loss_1": 4.920677922646414, "train_loss_2": 4.944957588991787, "train_loss": 9.865635513630266, "train_loss_scale": 1952.5347405452947, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8946940390919003, "epoch": 235, "n_parameters": 106143056}
{"train_lr": 9.414763969136625e-05, "train_min_lr": 9.414763969136625e-05, "train_mlm_acc_1": 0.12277950973331063, "train_mlm_acc_2": 0.1210234608376692, "train_loss_1": 4.9182280284224005, "train_loss_2": 4.942377573005337, "train_loss": 9.860605601794697, "train_loss_scale": 2325.389621811785, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 236, "n_parameters": 106143056}
{"train_lr": 9.16195630892216e-05, "train_min_lr": 9.16195630892216e-05, "train_mlm_acc_1": 0.12283373456415553, "train_mlm_acc_2": 0.12102263637965016, "train_loss_1": 4.916445134549992, "train_loss_2": 4.940699918865633, "train_loss": 9.857145053415625, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8732112959066607, "epoch": 237, "n_parameters": 106143056}
{"train_lr": 8.91253292099618e-05, "train_min_lr": 8.91253292099618e-05, "train_mlm_acc_1": 0.12297415807056868, "train_mlm_acc_2": 0.12119152927124117, "train_loss_1": 4.915122724617377, "train_loss_2": 4.939452995463433, "train_loss": 9.8545757168306, "train_loss_scale": 1257.259454705365, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 238, "n_parameters": 106143056}
{"train_lr": 8.66652307629916e-05, "train_min_lr": 8.66652307629916e-05, "train_mlm_acc_1": 0.12320469669250668, "train_mlm_acc_2": 0.12141823145604333, "train_loss_1": 4.9119929056893135, "train_loss_2": 4.93629106278994, "train_loss": 9.848283967011417, "train_loss_scale": 1037.5092348284961, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8412005563734284, "epoch": 239, "n_parameters": 106143056}
{"train_lr": 8.423955645177132e-05, "train_min_lr": 8.423955645177132e-05, "train_mlm_acc_1": 0.12332610989508785, "train_mlm_acc_2": 0.12154485534781569, "train_loss_1": 4.91006103847356, "train_loss_2": 4.9343065260372985, "train_loss": 9.844367566712613, "train_loss_scale": 1221.2348284960422, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 240, "n_parameters": 106143056}
{"train_lr": 8.184859093993656e-05, "train_min_lr": 8.184859093993656e-05, "train_mlm_acc_1": 0.12342583324527573, "train_mlm_acc_2": 0.12168921823732116, "train_loss_1": 4.908972498556974, "train_loss_2": 4.933102137862115, "train_loss": 9.842074637991772, "train_loss_scale": 1073.5338610378187, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9332247090738073, "epoch": 241, "n_parameters": 106143056}
{"train_lr": 7.949261481789082e-05, "train_min_lr": 7.949261481789082e-05, "train_mlm_acc_1": 0.12357520062735233, "train_mlm_acc_2": 0.12180868465217484, "train_loss_1": 4.906901843419909, "train_loss_2": 4.931211845855914, "train_loss": 9.83811369168727, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8677059595482122, "epoch": 242, "n_parameters": 106143056}
{"train_lr": 7.717190456987782e-05, "train_min_lr": 7.717190456987782e-05, "train_mlm_acc_1": 0.12377310129785181, "train_mlm_acc_2": 0.12204757173403953, "train_loss_1": 4.904769927184626, "train_loss_2": 4.92895141865144, "train_loss": 9.833721344997302, "train_loss_scale": 1105.0554089709763, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 243, "n_parameters": 106143056}
{"train_lr": 7.488673254153478e-05, "train_min_lr": 7.488673254153478e-05, "train_mlm_acc_1": 0.12386958371510397, "train_mlm_acc_2": 0.12207309807025768, "train_loss_1": 4.90316276112039, "train_loss_2": 4.927441601807755, "train_loss": 9.830604364605671, "train_loss_scale": 1189.7132805628848, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9522891152607524, "epoch": 244, "n_parameters": 106143056}
{"train_lr": 7.263736690793118e-05, "train_min_lr": 7.263736690793118e-05, "train_mlm_acc_1": 0.12396203507910906, "train_mlm_acc_2": 0.12217376044834247, "train_loss_1": 4.9014503645498495, "train_loss_2": 4.925617644843451, "train_loss": 9.827068012958048, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.906565671336158, "epoch": 245, "n_parameters": 106143056}
{"train_lr": 7.04240716420974e-05, "train_min_lr": 7.04240716420974e-05, "train_mlm_acc_1": 0.12413135168970732, "train_mlm_acc_2": 0.12234164552522288, "train_loss_1": 4.899626508132344, "train_loss_2": 4.923919244512929, "train_loss": 9.82354575180651, "train_loss_scale": 2755.883905013193, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 246, "n_parameters": 106143056}
{"train_lr": 6.824710648404599e-05, "train_min_lr": 6.824710648404599e-05, "train_mlm_acc_1": 0.12429641970009818, "train_mlm_acc_2": 0.12250443465807848, "train_loss_1": 4.8972787417753185, "train_loss_2": 4.921451549574065, "train_loss": 9.818730293813251, "train_loss_scale": 1169.8997361477573, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 247, "n_parameters": 106143056}
{"train_lr": 6.610672691029053e-05, "train_min_lr": 6.610672691029053e-05, "train_mlm_acc_1": 0.12450256574941551, "train_mlm_acc_2": 0.12270456839438033, "train_loss_1": 4.895447805982571, "train_loss_2": 4.91969976722932, "train_loss": 9.815147568913227, "train_loss_scale": 1124.8689533861038, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.92280015289102, "epoch": 248, "n_parameters": 106143056}
{"train_lr": 6.400318410386393e-05, "train_min_lr": 6.400318410386393e-05, "train_mlm_acc_1": 0.12453684124034045, "train_mlm_acc_2": 0.12273128569230975, "train_loss_1": 4.893916691146404, "train_loss_2": 4.918160396861527, "train_loss": 9.81207708549164, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8592648868929846, "epoch": 249, "n_parameters": 106143056}
{"train_lr": 6.19367249248409e-05, "train_min_lr": 6.19367249248409e-05, "train_mlm_acc_1": 0.1247243893610456, "train_mlm_acc_2": 0.12290628252857305, "train_loss_1": 4.892494545605692, "train_loss_2": 4.91670749453777, "train_loss": 9.809202036211756, "train_loss_scale": 1277.0729991204926, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 250, "n_parameters": 106143056}
{"train_lr": 5.990759188136876e-05, "train_min_lr": 5.990759188136876e-05, "train_mlm_acc_1": 0.12485034908630813, "train_mlm_acc_2": 0.12305606222853209, "train_loss_1": 4.890571553400974, "train_loss_2": 4.914671722009922, "train_loss": 9.805243276564196, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9509872424571055, "epoch": 251, "n_parameters": 106143056}
{"train_lr": 5.791602310120655e-05, "train_min_lr": 5.791602310120655e-05, "train_mlm_acc_1": 0.12502120017166607, "train_mlm_acc_2": 0.12327261802166202, "train_loss_1": 4.887909379934363, "train_loss_2": 4.912009971437479, "train_loss": 9.799919352053339, "train_loss_scale": 1846.2620932277925, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 252, "n_parameters": 106143056}
{"train_lr": 5.59622523037808e-05, "train_min_lr": 5.59622523037808e-05, "train_mlm_acc_1": 0.1251335664739932, "train_mlm_acc_2": 0.12333250008425171, "train_loss_1": 4.886804756094933, "train_loss_2": 4.910999327504855, "train_loss": 9.797804092878613, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.039971711348313, "epoch": 253, "n_parameters": 106143056}
{"train_lr": 5.4046508772757435e-05, "train_min_lr": 5.4046508772757435e-05, "train_mlm_acc_1": 0.12530556289117092, "train_mlm_acc_2": 0.12352344946789973, "train_loss_1": 4.884510171759412, "train_loss_2": 4.908706090905316, "train_loss": 9.793216263188954, "train_loss_scale": 1466.202286719437, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9601639190470848, "epoch": 254, "n_parameters": 106143056}
{"train_lr": 5.2169017329133505e-05, "train_min_lr": 5.2169017329133505e-05, "train_mlm_acc_1": 0.12539733858842964, "train_mlm_acc_2": 0.12362744426805274, "train_loss_1": 4.883058615022305, "train_loss_2": 4.907049793157015, "train_loss": 9.790108407602672, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0070226267963096, "epoch": 255, "n_parameters": 106143056}
{"train_lr": 5.03299983048543e-05, "train_min_lr": 5.03299983048543e-05, "train_mlm_acc_1": 0.12557806136707464, "train_mlm_acc_2": 0.12376934505930283, "train_loss_1": 4.881348071857409, "train_loss_2": 4.905449520943976, "train_loss": 9.78679758923664, "train_loss_scale": 2294.768689533861, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 256, "n_parameters": 106143056}
{"train_lr": 4.8529667516956426e-05, "train_min_lr": 4.8529667516956426e-05, "train_mlm_acc_1": 0.12567939945777573, "train_mlm_acc_2": 0.12386798043551027, "train_loss_1": 4.879759601311612, "train_loss_2": 4.90392764330749, "train_loss": 9.783687249651685, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.023535930072412, "epoch": 257, "n_parameters": 106143056}
{"train_lr": 4.676823624223976e-05, "train_min_lr": 4.676823624223976e-05, "train_mlm_acc_1": 0.12567955977303896, "train_mlm_acc_2": 0.12391094804766835, "train_loss_1": 4.878650941760685, "train_loss_2": 4.9028343923173665, "train_loss": 9.781485331509337, "train_loss_scale": 1906.603342128408, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 258, "n_parameters": 106143056}
{"train_lr": 4.5045911192474324e-05, "train_min_lr": 4.5045911192474324e-05, "train_mlm_acc_1": 0.12581844860728808, "train_mlm_acc_2": 0.12401036215452976, "train_loss_1": 4.877096466883925, "train_loss_2": 4.901201495971193, "train_loss": 9.778297966052905, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0365367751427668, "epoch": 259, "n_parameters": 106143056}
{"train_lr": 4.336289449014104e-05, "train_min_lr": 4.336289449014104e-05, "train_mlm_acc_1": 0.12606447024914708, "train_mlm_acc_2": 0.12425263898435689, "train_loss_1": 4.874641556590927, "train_loss_2": 4.898789855871897, "train_loss": 9.773431420640769, "train_loss_scale": 1396.8548812664908, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 260, "n_parameters": 106143056}
{"train_lr": 4.171938364471223e-05, "train_min_lr": 4.171938364471223e-05, "train_mlm_acc_1": 0.12608786648763515, "train_mlm_acc_2": 0.12428365080726309, "train_loss_1": 4.8730736210247665, "train_loss_2": 4.8972808657346745, "train_loss": 9.770354491110528, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0365523786637065, "epoch": 261, "n_parameters": 106143056}
{"train_lr": 4.011557152947225e-05, "train_min_lr": 4.011557152947225e-05, "train_mlm_acc_1": 0.12624934998978987, "train_mlm_acc_2": 0.12446561035771404, "train_loss_1": 4.8719630171147585, "train_loss_2": 4.8959836035626125, "train_loss": 9.767946616116593, "train_loss_scale": 1462.5998240985048, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.043279590057299, "epoch": 262, "n_parameters": 106143056}
{"train_lr": 3.8551646358884036e-05, "train_min_lr": 3.8551646358884036e-05, "train_mlm_acc_1": 0.12635991832105445, "train_mlm_acc_2": 0.12457712915895561, "train_loss_1": 4.870304148922704, "train_loss_2": 4.894297654102429, "train_loss": 9.764601798464357, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0358593255255237, "epoch": 263, "n_parameters": 106143056}
{"train_lr": 3.702779166650029e-05, "train_min_lr": 3.702779166650029e-05, "train_mlm_acc_1": 0.12648454961746197, "train_mlm_acc_2": 0.12470537922594929, "train_loss_1": 4.868702445831231, "train_loss_2": 4.8927404684462665, "train_loss": 9.761442913962963, "train_loss_scale": 2390.233948988566, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 264, "n_parameters": 106143056}
{"train_lr": 3.55441862834257e-05, "train_min_lr": 3.55441862834257e-05, "train_mlm_acc_1": 0.1265741150478915, "train_mlm_acc_2": 0.12483875969836035, "train_loss_1": 4.867655378323222, "train_loss_2": 4.891705166066857, "train_loss": 9.759360544914307, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0490860406410936, "epoch": 265, "n_parameters": 106143056}
{"train_lr": 3.4101004317329864e-05, "train_min_lr": 3.4101004317329864e-05, "train_mlm_acc_1": 0.1267618922207082, "train_mlm_acc_2": 0.12493029495876483, "train_loss_1": 4.8661494033842, "train_loss_2": 4.890152133444263, "train_loss": 9.7563015348364, "train_loss_scale": 2647.8100263852243, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 266, "n_parameters": 106143056}
{"train_lr": 3.269841513201525e-05, "train_min_lr": 3.269841513201525e-05, "train_mlm_acc_1": 0.12684801064444773, "train_mlm_acc_2": 0.12507723454097672, "train_loss_1": 4.864006226326985, "train_loss_2": 4.8879428930521645, "train_loss": 9.75194911382234, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.037783105434193, "epoch": 267, "n_parameters": 106143056}
{"train_lr": 3.1336583327541557e-05, "train_min_lr": 3.1336583327541557e-05, "train_mlm_acc_1": 0.12685591249055866, "train_mlm_acc_2": 0.1250728026749984, "train_loss_1": 4.863859754019698, "train_loss_2": 4.887851299690173, "train_loss": 9.751711058637607, "train_loss_scale": 1440.084432717678, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0611970193992084, "epoch": 268, "n_parameters": 106143056}
{"train_lr": 3.0015668720909095e-05, "train_min_lr": 3.0015668720909095e-05, "train_mlm_acc_1": 0.12704647241509212, "train_mlm_acc_2": 0.1252251017540562, "train_loss_1": 4.8623356001882465, "train_loss_2": 4.886249108805191, "train_loss": 9.748584705271423, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0987185661270624, "epoch": 269, "n_parameters": 106143056}
{"train_lr": 2.8735826327303497e-05, "train_min_lr": 2.8735826327303497e-05, "train_mlm_acc_1": 0.1270814351229654, "train_mlm_acc_2": 0.1253419113562507, "train_loss_1": 4.861484346205242, "train_loss_2": 4.885359893740534, "train_loss": 9.74684424597439, "train_loss_scale": 2190.297273526825, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 270, "n_parameters": 106143056}
{"train_lr": 2.7497206341904298e-05, "train_min_lr": 2.7497206341904298e-05, "train_mlm_acc_1": 0.12729507072262708, "train_mlm_acc_2": 0.1254754177447844, "train_loss_1": 4.859747205319485, "train_loss_2": 4.8837756296994925, "train_loss": 9.74352283066789, "train_loss_scale": 2022.7827616534742, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 271, "n_parameters": 106143056}
{"train_lr": 2.629995412225849e-05, "train_min_lr": 2.629995412225849e-05, "train_mlm_acc_1": 0.1273814410998395, "train_mlm_acc_2": 0.12559405964510081, "train_loss_1": 4.858027069371524, "train_loss_2": 4.882004943141418, "train_loss": 9.740032010992683, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0942811037011597, "epoch": 272, "n_parameters": 106143056}
{"train_lr": 2.514421017122239e-05, "train_min_lr": 2.514421017122239e-05, "train_mlm_acc_1": 0.12733948120409944, "train_mlm_acc_2": 0.1255742135329095, "train_loss_1": 4.857744617585876, "train_loss_2": 4.881714121542589, "train_loss": 9.73945873750336, "train_loss_scale": 1295.985927880387, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1059401450496864, "epoch": 273, "n_parameters": 106143056}
{"train_lr": 2.4030110120472967e-05, "train_min_lr": 2.4030110120472967e-05, "train_mlm_acc_1": 0.1275025450869438, "train_mlm_acc_2": 0.12570892243909018, "train_loss_1": 4.856038988422907, "train_loss_2": 4.879998232674578, "train_loss": 9.736037222670166, "train_loss_scale": 953.7519788918206, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 274, "n_parameters": 106143056}
{"train_lr": 2.29577847145909e-05, "train_min_lr": 2.29577847145909e-05, "train_mlm_acc_1": 0.12755951846531194, "train_mlm_acc_2": 0.1258104436915358, "train_loss_1": 4.855024441460716, "train_loss_2": 4.878962010118976, "train_loss": 9.73398644806737, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.16596078264577, "epoch": 275, "n_parameters": 106143056}
{"train_lr": 2.1927359795716904e-05, "train_min_lr": 2.1927359795716904e-05, "train_mlm_acc_1": 0.12759383993015258, "train_mlm_acc_2": 0.12584274956463404, "train_loss_1": 4.854956886489452, "train_loss_2": 4.878791371614343, "train_loss": 9.733748258994982, "train_loss_scale": 908.2708883025506, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.143607083599926, "epoch": 276, "n_parameters": 106143056}
{"train_lr": 2.093895628878402e-05, "train_min_lr": 2.093895628878402e-05, "train_mlm_acc_1": 0.12764269368200445, "train_mlm_acc_2": 0.12591915683478458, "train_loss_1": 4.853918886488744, "train_loss_2": 4.877728146686822, "train_loss": 9.731647038208148, "train_loss_scale": 1039.3104661389623, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.114236262354184, "epoch": 277, "n_parameters": 106143056}
{"train_lr": 1.9992690187326e-05, "train_min_lr": 1.9992690187326e-05, "train_mlm_acc_1": 0.12774027559558943, "train_mlm_acc_2": 0.12598903645108483, "train_loss_1": 4.852879466828067, "train_loss_2": 4.876661836734024, "train_loss": 9.729541303509668, "train_loss_scale": 1122.1671064204045, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 278, "n_parameters": 106143056}
{"train_lr": 1.9088672539865457e-05, "train_min_lr": 1.9088672539865457e-05, "train_mlm_acc_1": 0.12790426712240713, "train_mlm_acc_2": 0.1261454696882526, "train_loss_1": 4.851085203566253, "train_loss_2": 4.874936984732367, "train_loss": 9.72602219233517, "train_loss_scale": 1114.0615655233069, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 279, "n_parameters": 106143056}
{"train_lr": 1.8227009436881574e-05, "train_min_lr": 1.8227009436881574e-05, "train_mlm_acc_1": 0.127989927437009, "train_mlm_acc_2": 0.1262042638153598, "train_loss_1": 4.849941176181313, "train_loss_2": 4.873836145814092, "train_loss": 9.723777322152674, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.079625033556419, "epoch": 280, "n_parameters": 106143056}
{"train_lr": 1.7407801998359794e-05, "train_min_lr": 1.7407801998359794e-05, "train_mlm_acc_1": 0.12806714773128955, "train_mlm_acc_2": 0.12630015068172282, "train_loss_1": 4.8492784238008415, "train_loss_2": 4.873135490279084, "train_loss": 9.722413916386527, "train_loss_scale": 1329.3087071240107, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.050672616472135, "epoch": 281, "n_parameters": 106143056}
{"train_lr": 1.6631146361925272e-05, "train_min_lr": 1.6631146361925272e-05, "train_mlm_acc_1": 0.1281074012630507, "train_mlm_acc_2": 0.12636548391950425, "train_loss_1": 4.848170333980151, "train_loss_2": 4.871966004109529, "train_loss": 9.720136336621843, "train_loss_scale": 1913.8082673702727, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 282, "n_parameters": 106143056}
{"train_lr": 1.5897133671560495e-05, "train_min_lr": 1.5897133671560495e-05, "train_mlm_acc_1": 0.12819501992623036, "train_mlm_acc_2": 0.12637416450773664, "train_loss_1": 4.8482374619682735, "train_loss_2": 4.872059930335459, "train_loss": 9.720297390783472, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1892803719721035, "epoch": 283, "n_parameters": 106143056}
{"train_lr": 1.5205850066909038e-05, "train_min_lr": 1.5205850066909038e-05, "train_mlm_acc_1": 0.12835082330019357, "train_mlm_acc_2": 0.12653830493149154, "train_loss_1": 4.8464963200748645, "train_loss_2": 4.870352443625451, "train_loss": 9.716848760607375, "train_loss_scale": 1124.8689533861038, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 284, "n_parameters": 106143056}
{"train_lr": 1.4557376673166934e-05, "train_min_lr": 1.4557376673166934e-05, "train_mlm_acc_1": 0.12817847189348497, "train_mlm_acc_2": 0.12635892203033441, "train_loss_1": 4.84725228882507, "train_loss_2": 4.8711319864058344, "train_loss": 9.718384274916367, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.253772389186299, "epoch": 285, "n_parameters": 106143056}
{"train_lr": 1.3951789591562158e-05, "train_min_lr": 1.3951789591562158e-05, "train_mlm_acc_1": 0.12830367567723744, "train_mlm_acc_2": 0.12652009638090247, "train_loss_1": 4.846094752469394, "train_loss_2": 4.86991410142199, "train_loss": 9.716008844874676, "train_loss_scale": 1256.358839050132, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 286, "n_parameters": 106143056}
{"train_lr": 1.3389159890423752e-05, "train_min_lr": 1.3389159890423752e-05, "train_mlm_acc_1": 0.12832237670006413, "train_mlm_acc_2": 0.12658362013264088, "train_loss_1": 4.8451083764866345, "train_loss_2": 4.868886429485566, "train_loss": 9.713994807282768, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1574362102263627, "epoch": 287, "n_parameters": 106143056}
{"train_lr": 1.2869553596841708e-05, "train_min_lr": 1.2869553596841708e-05, "train_mlm_acc_1": 0.12845105045739635, "train_mlm_acc_2": 0.12669770420990104, "train_loss_1": 4.844717898857415, "train_loss_2": 4.868437744329766, "train_loss": 9.713155643816254, "train_loss_scale": 1068.1301671064205, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 288, "n_parameters": 106143056}
{"train_lr": 1.2393031688918403e-05, "train_min_lr": 1.2393031688918403e-05, "train_mlm_acc_1": 0.12849337677327996, "train_mlm_acc_2": 0.1267035560823302, "train_loss_1": 4.843926442120299, "train_loss_2": 4.867817183073509, "train_loss": 9.711743622677517, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2336892434768543, "epoch": 289, "n_parameters": 106143056}
{"train_lr": 1.1959650088612536e-05, "train_min_lr": 1.1959650088612536e-05, "train_mlm_acc_1": 0.12860987717146505, "train_mlm_acc_2": 0.12683640984718408, "train_loss_1": 4.842490470713445, "train_loss_2": 4.866330178400458, "train_loss": 9.708820645916116, "train_loss_scale": 1767.9085312225154, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2106562536226204, "epoch": 290, "n_parameters": 106143056}
{"train_lr": 1.1569459655176374e-05, "train_min_lr": 1.1569459655176374e-05, "train_mlm_acc_1": 0.12856113781747897, "train_mlm_acc_2": 0.1267487110787955, "train_loss_1": 4.8423273980669945, "train_loss_2": 4.866111052749234, "train_loss": 9.708438450134734, "train_loss_scale": 1033.9067722075638, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 291, "n_parameters": 106143056}
{"train_lr": 1.1222506179187317e-05, "train_min_lr": 1.1222506179187317e-05, "train_mlm_acc_1": 0.12858785513752422, "train_mlm_acc_2": 0.1268237096920164, "train_loss_1": 4.842476229711699, "train_loss_2": 4.86615806503472, "train_loss": 9.70863429610941, "train_loss_scale": 1168.098504837291, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 292, "n_parameters": 106143056}
{"train_lr": 1.0918830377174124e-05, "train_min_lr": 1.0918830377174124e-05, "train_mlm_acc_1": 0.12856544369033873, "train_mlm_acc_2": 0.1267776730156642, "train_loss_1": 4.842061790962856, "train_loss_2": 4.865913237357412, "train_loss": 9.707975027324236, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1903636730230995, "epoch": 293, "n_parameters": 106143056}
{"train_lr": 1.0658467886838543e-05, "train_min_lr": 1.0658467886838543e-05, "train_mlm_acc_1": 0.1286616742352094, "train_mlm_acc_2": 0.1269117405158103, "train_loss_1": 4.841364381076374, "train_loss_2": 4.865046126861371, "train_loss": 9.70641050363908, "train_loss_scale": 1363.532102022867, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.256768945129482, "epoch": 294, "n_parameters": 106143056}
{"train_lr": 1.0441449262873223e-05, "train_min_lr": 1.0441449262873223e-05, "train_mlm_acc_1": 0.1286416905305513, "train_mlm_acc_2": 0.12686363103813447, "train_loss_1": 4.841509200966767, "train_loss_2": 4.865306357595096, "train_loss": 9.706815559715164, "train_loss_scale": 1050.117854001759, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 295, "n_parameters": 106143056}
{"train_lr": 1.0267799973375903e-05, "train_min_lr": 1.0267799973375903e-05, "train_mlm_acc_1": 0.1287223694136689, "train_mlm_acc_2": 0.12695017324640967, "train_loss_1": 4.841429457815467, "train_loss_2": 4.8651166126826615, "train_loss": 9.706546076054938, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.265570206084373, "epoch": 296, "n_parameters": 106143056}
{"train_lr": 1.0137540396860598e-05, "train_min_lr": 1.0137540396860598e-05, "train_mlm_acc_1": 0.12862773077020204, "train_mlm_acc_2": 0.12682409903072248, "train_loss_1": 4.841074784282225, "train_loss_2": 4.864878711882871, "train_loss": 9.70595349359638, "train_loss_scale": 641.688654353562, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.320880698968993, "epoch": 297, "n_parameters": 106143056}
{"train_lr": 1.0050685819866211e-05, "train_min_lr": 1.0050685819866211e-05, "train_mlm_acc_1": 0.12872495754190255, "train_mlm_acc_2": 0.12692836874386618, "train_loss_1": 4.84067268809836, "train_loss_2": 4.864489221268824, "train_loss": 9.70516189757207, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.291053829427969, "epoch": 298, "n_parameters": 106143056}
{"train_lr": 1.0007246435162376e-05, "train_min_lr": 1.0007246435162376e-05, "train_mlm_acc_1": 0.12878199957111292, "train_mlm_acc_2": 0.12702029337164542, "train_loss_1": 4.839929207491057, "train_loss_2": 4.863678905454349, "train_loss": 9.703608110691228, "train_loss_scale": 570.990325417766, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 299, "n_parameters": 106143056}
