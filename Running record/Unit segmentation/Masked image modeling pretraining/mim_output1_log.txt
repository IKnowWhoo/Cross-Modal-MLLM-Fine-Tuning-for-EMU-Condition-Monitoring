{"train_lr": 3.0449161547253374e-05, "train_min_lr": 3.0449161547253374e-05, "train_mlm_acc_1": 0.018240509856288036, "train_mlm_acc_2": 0.018390761675621304, "train_loss_1": 7.853222715173449, "train_loss_2": 7.84588767260313, "train_loss": 15.69911039352417, "train_loss_scale": 316.7085714285714, "train_weight_decay": 0.04999999999999869, "train_grad_norm": NaN, "epoch": 0, "n_parameters": 106143056}
{"train_lr": 9.139101453675264e-05, "train_min_lr": 9.139101453675264e-05, "train_mlm_acc_1": 0.047331271102385865, "train_mlm_acc_2": 0.04720546983481784, "train_loss_1": 6.514878948373454, "train_loss_2": 6.5166804326006345, "train_loss": 13.031559377738407, "train_loss_scale": 307.5657142857143, "train_weight_decay": 0.04999999999999869, "train_grad_norm": Infinity, "epoch": 1, "n_parameters": 106143056}
{"train_lr": 0.00015233286752625188, "train_min_lr": 0.00015233286752625188, "train_mlm_acc_1": 0.05771007125299158, "train_mlm_acc_2": 0.0574098766917762, "train_loss_1": 6.231062296628952, "train_loss_2": 6.237194746775287, "train_loss": 12.468257044213159, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999869, "train_grad_norm": 5.307787807243211, "epoch": 2, "n_parameters": 106143056}
{"train_lr": 3.7470314011786434e-05, "train_min_lr": 3.7470314011786434e-05, "train_mlm_acc_1": 0.018773694459962912, "train_mlm_acc_2": 0.018912823846430504, "train_loss_1": 7.834030740965639, "train_loss_2": 7.82681306790341, "train_loss": 15.66084380504219, "train_loss_scale": 777.231310466139, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 0, "n_parameters": 106143056}
{"train_lr": 0.00011247691089805615, "train_min_lr": 0.00011247691089805615, "train_mlm_acc_1": 0.048123901764179924, "train_mlm_acc_2": 0.04798750941114944, "train_loss_1": 6.491597936566503, "train_loss_2": 6.493526000355877, "train_loss": 12.985123938285371, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.538106543617282, "epoch": 1, "n_parameters": 106143056}
{"train_lr": 0.00018748350778432582, "train_min_lr": 0.00018748350778432582, "train_mlm_acc_1": 0.05809673797314628, "train_mlm_acc_2": 0.057808951180667444, "train_loss_1": 6.219661619491292, "train_loss_2": 6.225588026860354, "train_loss": 12.445249651646341, "train_loss_scale": 936.1899736147757, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 5.235390392645682, "epoch": 2, "n_parameters": 106143056}
{"train_lr": 0.0002624901046705954, "train_min_lr": 0.0002624901046705954, "train_mlm_acc_1": 0.0639897359300834, "train_mlm_acc_2": 0.06351666853344601, "train_loss_1": 6.058377199877535, "train_loss_2": 6.068680111105859, "train_loss": 12.127057312660922, "train_loss_scale": 1095.1486367634125, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.539231849744222, "epoch": 3, "n_parameters": 106143056}
{"train_lr": 0.0003374967015568651, "train_min_lr": 0.0003374967015568651, "train_mlm_acc_1": 0.06821384566337224, "train_mlm_acc_2": 0.06764565859392954, "train_loss_1": 5.941672390295731, "train_loss_2": 5.955389009302084, "train_loss": 11.897061399964775, "train_loss_scale": 1604.8970976253297, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 4, "n_parameters": 106143056}
{"train_lr": 0.0004125032984431348, "train_min_lr": 0.0004125032984431348, "train_mlm_acc_1": 0.07178071810779545, "train_mlm_acc_2": 0.0710960306381199, "train_loss_1": 5.851476325313564, "train_loss_2": 5.867036315256184, "train_loss": 11.718512641723049, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.3778305971108726, "epoch": 5, "n_parameters": 106143056}
{"train_lr": 0.00048750989532940465, "train_min_lr": 0.00048750989532940465, "train_mlm_acc_1": 0.07426342572328834, "train_mlm_acc_2": 0.07350858383121504, "train_loss_1": 5.788048612725452, "train_loss_2": 5.804772939195524, "train_loss": 11.592821554961494, "train_loss_scale": 1713.8715919085312, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.877292839497354, "epoch": 6, "n_parameters": 106143056}
{"train_lr": 0.0005625164922156739, "train_min_lr": 0.0005625164922156739, "train_mlm_acc_1": 0.07598428292774981, "train_mlm_acc_2": 0.07515431645595802, "train_loss_1": 5.743505628987584, "train_loss_2": 5.76089491179457, "train_loss": 11.50440053207998, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.6118668336666984, "epoch": 7, "n_parameters": 106143056}
{"train_lr": 0.0006375230891019436, "train_min_lr": 0.0006375230891019436, "train_mlm_acc_1": 0.07775548277070571, "train_mlm_acc_2": 0.07690567006877146, "train_loss_1": 5.701497195211543, "train_loss_2": 5.719655993850795, "train_loss": 11.42115319142136, "train_loss_scale": 3921.2805628847846, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.320331538887326, "epoch": 8, "n_parameters": 106143056}
{"train_lr": 0.0007125296859882135, "train_min_lr": 0.0007125296859882135, "train_mlm_acc_1": 0.07864184997051876, "train_mlm_acc_2": 0.07772035971644319, "train_loss_1": 5.677792104326431, "train_loss_2": 5.696478920540688, "train_loss": 11.374271025338924, "train_loss_scale": 4733.6358839050135, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.186138670173987, "epoch": 9, "n_parameters": 106143056}
{"train_lr": 0.0007499927726594455, "train_min_lr": 0.0007499927726594455, "train_mlm_acc_1": 0.08044532127514574, "train_mlm_acc_2": 0.07949437673564873, "train_loss_1": 5.638960714023576, "train_loss_2": 5.658164105503414, "train_loss": 11.297124818635805, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.924965088369559, "epoch": 10, "n_parameters": 106143056}
{"train_lr": 0.0007499493714617194, "train_min_lr": 0.0007499493714617194, "train_mlm_acc_1": 0.08247361673499239, "train_mlm_acc_2": 0.081457797015248, "train_loss_1": 5.596759625925972, "train_loss_2": 5.616448523291602, "train_loss": 11.213208146334324, "train_loss_scale": 11441.421284080914, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5634473412835819, "epoch": 11, "n_parameters": 106143056}
{"train_lr": 0.0007498625550649799, "train_min_lr": 0.0007498625550649799, "train_mlm_acc_1": 0.08377173773308752, "train_mlm_acc_2": 0.08273956467042838, "train_loss_1": 5.571092266101217, "train_loss_2": 5.591254125379531, "train_loss": 11.162346391061366, "train_loss_scale": 5994.49780123131, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 12, "n_parameters": 106143056}
{"train_lr": 0.000749732333657516, "train_min_lr": 0.000749732333657516, "train_mlm_acc_1": 0.08549709554610933, "train_mlm_acc_2": 0.08444219042212033, "train_loss_1": 5.5354067728303455, "train_loss_2": 5.555986166577016, "train_loss": 11.091392939302517, "train_loss_scale": 4207.676341248901, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3790361319808657, "epoch": 13, "n_parameters": 106143056}
{"train_lr": 0.0007495587225213875, "train_min_lr": 0.0007495587225213875, "train_mlm_acc_1": 0.08668682407243743, "train_mlm_acc_2": 0.0855794806408523, "train_loss_1": 5.512026273061439, "train_loss_2": 5.533034655852808, "train_loss": 11.045060932688683, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3446702592815343, "epoch": 14, "n_parameters": 106143056}
{"train_lr": 0.0007493417420306326, "train_min_lr": 0.0007493417420306326, "train_mlm_acc_1": 0.0871268641383845, "train_mlm_acc_2": 0.08597522470264604, "train_loss_1": 5.503480986219388, "train_loss_2": 5.524633074656011, "train_loss": 11.028114055685549, "train_loss_scale": 5299.2225153913805, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 15, "n_parameters": 106143056}
{"train_lr": 0.0007490814176488726, "train_min_lr": 0.0007490814176488726, "train_mlm_acc_1": 0.08867688158079785, "train_mlm_acc_2": 0.0875099423745272, "train_loss_1": 5.473177488110206, "train_loss_2": 5.494511472308647, "train_loss": 10.96768896057612, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1902540673156947, "epoch": 16, "n_parameters": 106143056}
{"train_lr": 0.0007487777799263258, "train_min_lr": 0.0007487777799263258, "train_mlm_acc_1": 0.08961695832222465, "train_mlm_acc_2": 0.0884298751075001, "train_loss_1": 5.456129864002386, "train_loss_2": 5.477681866526709, "train_loss": 10.933811726020739, "train_loss_scale": 7975.852242744063, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2294619687314399, "epoch": 17, "n_parameters": 106143056}
{"train_lr": 0.0007484308644962306, "train_min_lr": 0.0007484308644962306, "train_mlm_acc_1": 0.08978829049016288, "train_mlm_acc_2": 0.0885891369826561, "train_loss_1": 5.454284456180918, "train_loss_2": 5.476079683033332, "train_loss": 10.930364134548627, "train_loss_scale": 6808.654353562005, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 18, "n_parameters": 106143056}
{"train_lr": 0.000748040712070646, "train_min_lr": 0.000748040712070646, "train_mlm_acc_1": 0.09118421086935014, "train_mlm_acc_2": 0.08997347948314227, "train_loss_1": 5.4266446389015455, "train_loss_2": 5.448591966427725, "train_loss": 10.875236601816948, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1011488456524772, "epoch": 19, "n_parameters": 106143056}
{"train_lr": 0.0007476073684356914, "train_min_lr": 0.0007476073684356914, "train_mlm_acc_1": 0.09153060855224349, "train_mlm_acc_2": 0.09029541588769267, "train_loss_1": 5.4191789381212585, "train_loss_2": 5.441227447388983, "train_loss": 10.860406383465756, "train_loss_scale": 6466.420404573439, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2165172752205908, "epoch": 20, "n_parameters": 106143056}
{"train_lr": 0.0007471308844461622, "train_min_lr": 0.0007471308844461622, "train_mlm_acc_1": 0.09239375131268615, "train_mlm_acc_2": 0.09110985355731838, "train_loss_1": 5.402987778186798, "train_loss_2": 5.425112010830834, "train_loss": 10.828099780996956, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0783065456828216, "epoch": 21, "n_parameters": 106143056}
{"train_lr": 0.00074661131601957, "train_min_lr": 0.00074661131601957, "train_mlm_acc_1": 0.09289650204480873, "train_mlm_acc_2": 0.09160871070907135, "train_loss_1": 5.394140074466967, "train_loss_2": 5.416464522363014, "train_loss": 10.810604596096063, "train_loss_scale": 14906.990325417766, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0945332090688988, "epoch": 22, "n_parameters": 106143056}
{"train_lr": 0.0007460487241295682, "train_min_lr": 0.0007460487241295682, "train_mlm_acc_1": 0.09351771146226134, "train_mlm_acc_2": 0.09219771736811784, "train_loss_1": 5.383910749287803, "train_loss_2": 5.406324088573456, "train_loss": 10.79023484022028, "train_loss_scale": 17378.27968337731, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.073562566292527, "epoch": 23, "n_parameters": 106143056}
{"train_lr": 0.0007454431747988132, "train_min_lr": 0.0007454431747988132, "train_mlm_acc_1": 0.09392217043607037, "train_mlm_acc_2": 0.09264494917415272, "train_loss_1": 5.375380673792242, "train_loss_2": 5.397995266142705, "train_loss": 10.773375945229644, "train_loss_scale": 18156.411609498682, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 24, "n_parameters": 106143056}
{"train_lr": 0.0007447947390912042, "train_min_lr": 0.0007447947390912042, "train_mlm_acc_1": 0.09433393565923133, "train_mlm_acc_2": 0.09303265395873245, "train_loss_1": 5.367582296580731, "train_loss_2": 5.390135444615531, "train_loss": 10.757717735953989, "train_loss_scale": 18559.887423043096, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.044953123246145, "epoch": 25, "n_parameters": 106143056}
{"train_lr": 0.0007441034931035458, "train_min_lr": 0.0007441034931035458, "train_mlm_acc_1": 0.09434436842809016, "train_mlm_acc_2": 0.09302876025713529, "train_loss_1": 5.368827264195696, "train_loss_2": 5.3914790763704, "train_loss": 10.760306343554193, "train_loss_scale": 9171.869832893579, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 26, "n_parameters": 106143056}
{"train_lr": 0.0007433695179566179, "train_min_lr": 0.0007433695179566179, "train_mlm_acc_1": 0.09500262475668361, "train_mlm_acc_2": 0.09369221588280527, "train_loss_1": 5.355496047302203, "train_loss_2": 5.378186189509738, "train_loss": 10.73368223392869, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0427742833197904, "epoch": 27, "n_parameters": 106143056}
{"train_lr": 0.0007425928997856612, "train_min_lr": 0.0007425928997856612, "train_mlm_acc_1": 0.09549859603219842, "train_mlm_acc_2": 0.09417113514900496, "train_loss_1": 5.345846615345098, "train_loss_2": 5.368675025388035, "train_loss": 10.714521638111997, "train_loss_scale": 5205.558487247142, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0095527224511354, "epoch": 28, "n_parameters": 106143056}
{"train_lr": 0.0007417737297302581, "train_min_lr": 0.0007417737297302581, "train_mlm_acc_1": 0.09577300690733742, "train_mlm_acc_2": 0.0944567116783406, "train_loss_1": 5.341450097063915, "train_loss_2": 5.364230525944457, "train_loss": 10.705680619024244, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0259527658409682, "epoch": 29, "n_parameters": 106143056}
{"train_lr": 0.0007409121039236501, "train_min_lr": 0.0007409121039236501, "train_mlm_acc_1": 0.09620056435279056, "train_mlm_acc_2": 0.09483081161101056, "train_loss_1": 5.334283423560066, "train_loss_2": 5.357098131611773, "train_loss": 10.691381553127352, "train_loss_scale": 12385.26649076517, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0080149881967664, "epoch": 30, "n_parameters": 106143056}
{"train_lr": 0.000740008123481444, "train_min_lr": 0.000740008123481444, "train_mlm_acc_1": 0.09647246732285596, "train_mlm_acc_2": 0.09513728788635295, "train_loss_1": 5.328703313987299, "train_loss_2": 5.351631204601747, "train_loss": 10.680334515705797, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0258002632945489, "epoch": 31, "n_parameters": 106143056}
{"train_lr": 0.0007390618944897517, "train_min_lr": 0.0007390618944897517, "train_mlm_acc_1": 0.0962701004052579, "train_mlm_acc_2": 0.09489296121308179, "train_loss_1": 5.3336279755531955, "train_loss_2": 5.3565919333733065, "train_loss": 10.690219913434856, "train_loss_scale": 6192.633245382585, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 32, "n_parameters": 106143056}
{"train_lr": 0.0007380735279927422, "train_min_lr": 0.0007380735279927422, "train_mlm_acc_1": 0.09716566352922348, "train_mlm_acc_2": 0.09578771118022233, "train_loss_1": 5.317542905438439, "train_loss_2": 5.3405220303602565, "train_loss": 10.6580649374238, "train_loss_scale": 4376.992084432718, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9825324770014016, "epoch": 33, "n_parameters": 106143056}
{"train_lr": 0.0007370431399796046, "train_min_lr": 0.0007370431399796046, "train_mlm_acc_1": 0.09734366069447083, "train_mlm_acc_2": 0.0960064428819961, "train_loss_1": 5.313256552687002, "train_loss_2": 5.336253891257519, "train_loss": 10.64951044032735, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9785997895368276, "epoch": 34, "n_parameters": 106143056}
{"train_lr": 0.0007359708513709434, "train_min_lr": 0.0007359708513709434, "train_mlm_acc_1": 0.09767578931143647, "train_mlm_acc_2": 0.09628347629188128, "train_loss_1": 5.308685935214621, "train_loss_2": 5.3317374545120835, "train_loss": 10.640423381653603, "train_loss_scale": 10728.133685136323, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0053128340628028, "epoch": 35, "n_parameters": 106143056}
{"train_lr": 0.000734856788004579, "train_min_lr": 0.000734856788004579, "train_mlm_acc_1": 0.09779329747190943, "train_mlm_acc_2": 0.09645741952791247, "train_loss_1": 5.304928165155225, "train_loss_2": 5.328087921455017, "train_loss": 10.633016086295706, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9832956264599856, "epoch": 36, "n_parameters": 106143056}
{"train_lr": 0.0007337010806207864, "train_min_lr": 0.0007337010806207864, "train_mlm_acc_1": 0.09810750382619016, "train_mlm_acc_2": 0.09673852982980805, "train_loss_1": 5.3007162510562384, "train_loss_2": 5.323743514723178, "train_loss": 10.624459763210703, "train_loss_scale": 10540.805628847846, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 37, "n_parameters": 106143056}
{"train_lr": 0.0007325038648469556, "train_min_lr": 0.0007325038648469556, "train_mlm_acc_1": 0.09825361887420624, "train_mlm_acc_2": 0.09686146611503424, "train_loss_1": 5.297300252562148, "train_loss_2": 5.320436969386346, "train_loss": 10.617737223626023, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0208627281738356, "epoch": 38, "n_parameters": 106143056}
{"train_lr": 0.000731265281181661, "train_min_lr": 0.000731265281181661, "train_mlm_acc_1": 0.09847967980041274, "train_mlm_acc_2": 0.09711092334279992, "train_loss_1": 5.292919480024772, "train_loss_2": 5.316100147594563, "train_loss": 10.609019625889385, "train_loss_scale": 16009.343887423043, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0063696895761247, "epoch": 39, "n_parameters": 106143056}
{"train_lr": 0.0007299854749781874, "train_min_lr": 0.0007299854749781874, "train_mlm_acc_1": 0.09823898329639524, "train_mlm_acc_2": 0.09686501622331069, "train_loss_1": 5.298905610251867, "train_loss_2": 5.3221633802303225, "train_loss": 10.62106899011523, "train_loss_scale": 5032.640281442392, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 40, "n_parameters": 106143056}
{"train_lr": 0.0007286645964274694, "train_min_lr": 0.0007286645964274694, "train_mlm_acc_1": 0.0989212772949036, "train_mlm_acc_2": 0.09753696913458243, "train_loss_1": 5.284839492255172, "train_loss_2": 5.308031408432396, "train_loss": 10.592870897017976, "train_loss_scale": 4744.44327176781, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9563702203353036, "epoch": 41, "n_parameters": 106143056}
{"train_lr": 0.0007273028005404614, "train_min_lr": 0.0007273028005404614, "train_mlm_acc_1": 0.099201127893325, "train_mlm_acc_2": 0.09778115848241506, "train_loss_1": 5.281915340857644, "train_loss_2": 5.305200904843675, "train_loss": 10.58711624072116, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0209716241823128, "epoch": 42, "n_parameters": 106143056}
{"train_lr": 0.0007259002471299484, "train_min_lr": 0.0007259002471299484, "train_mlm_acc_1": 0.09886657148222837, "train_mlm_acc_2": 0.09747398356114995, "train_loss_1": 5.286685248058725, "train_loss_2": 5.3099892415702605, "train_loss": 10.59667448664089, "train_loss_scale": 4395.004397537379, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 43, "n_parameters": 106143056}
{"train_lr": 0.0007244571007917912, "train_min_lr": 0.0007244571007917912, "train_mlm_acc_1": 0.09945039036573158, "train_mlm_acc_2": 0.09804519389820733, "train_loss_1": 5.276335203815366, "train_loss_2": 5.299634467800563, "train_loss": 10.575969673293457, "train_loss_scale": 4784.070360598065, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9817645638368585, "epoch": 44, "n_parameters": 106143056}
{"train_lr": 0.0007229735308856102, "train_min_lr": 0.0007229735308856102, "train_mlm_acc_1": 0.09968001291028035, "train_mlm_acc_2": 0.09827518286044229, "train_loss_1": 5.273057333135563, "train_loss_2": 5.296295554363214, "train_loss": 10.569352890591718, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0126681314189914, "epoch": 45, "n_parameters": 106143056}
{"train_lr": 0.0007214497115149132, "train_min_lr": 0.0007214497115149132, "train_mlm_acc_1": 0.09972015185414329, "train_mlm_acc_2": 0.09832535370473366, "train_loss_1": 5.271489518246529, "train_loss_2": 5.294663441736864, "train_loss": 10.566152956785606, "train_loss_scale": 11542.29023746702, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0060072122903487, "epoch": 46, "n_parameters": 106143056}
{"train_lr": 0.0007198858215066601, "train_min_lr": 0.0007198858215066601, "train_mlm_acc_1": 0.09994200989276354, "train_mlm_acc_2": 0.09849525443560844, "train_loss_1": 5.267951208190532, "train_loss_2": 5.29131945425099, "train_loss": 10.559270661340644, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0007608599482447, "epoch": 47, "n_parameters": 106143056}
{"train_lr": 0.0007182820443902745, "train_min_lr": 0.0007182820443902745, "train_mlm_acc_1": 0.09972096491840945, "train_mlm_acc_2": 0.09829246382849093, "train_loss_1": 5.2719289944584995, "train_loss_2": 5.295300314063657, "train_loss": 10.567229309518188, "train_loss_scale": 13451.595426561125, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 48, "n_parameters": 106143056}
{"train_lr": 0.0007166385683761166, "train_min_lr": 0.0007166385683761166, "train_mlm_acc_1": 0.10032863817329248, "train_mlm_acc_2": 0.09892346459074747, "train_loss_1": 5.260804164378184, "train_loss_2": 5.284103836159803, "train_loss": 10.544908003211546, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.958152964802929, "epoch": 49, "n_parameters": 106143056}
{"train_lr": 0.0007149555863333774, "train_min_lr": 0.0007149555863333774, "train_mlm_acc_1": 0.10042567026089605, "train_mlm_acc_2": 0.09898746939312106, "train_loss_1": 5.259031009024031, "train_loss_2": 5.282395858248809, "train_loss": 10.541426865909848, "train_loss_scale": 13862.276165347406, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0059469513129853, "epoch": 50, "n_parameters": 106143056}
{"train_lr": 0.0007132332957674665, "train_min_lr": 0.0007132332957674665, "train_mlm_acc_1": 0.10058797837342336, "train_mlm_acc_2": 0.0991350388524623, "train_loss_1": 5.256962356959505, "train_loss_2": 5.280265093845763, "train_loss": 10.537227453111868, "train_loss_scale": 14035.194371152154, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 51, "n_parameters": 106143056}
{"train_lr": 0.0007114718987968146, "train_min_lr": 0.0007114718987968146, "train_mlm_acc_1": 0.10041155008699093, "train_mlm_acc_2": 0.098966100114736, "train_loss_1": 5.260176748168395, "train_loss_2": 5.283633087429963, "train_loss": 10.543809835598358, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1761837914101156, "epoch": 52, "n_parameters": 106143056}
{"train_lr": 0.0007096716021291684, "train_min_lr": 0.0007096716021291684, "train_mlm_acc_1": 0.10086080893258201, "train_mlm_acc_2": 0.099437369576761, "train_loss_1": 5.251633618416866, "train_loss_2": 5.274962387592413, "train_loss": 10.52659600642866, "train_loss_scale": 9236.71416007036, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 53, "n_parameters": 106143056}
{"train_lr": 0.0007078326170373227, "train_min_lr": 0.0007078326170373227, "train_mlm_acc_1": 0.10101356607900315, "train_mlm_acc_2": 0.09959635661264575, "train_loss_1": 5.249301090508883, "train_loss_2": 5.272724737015961, "train_loss": 10.522025826423967, "train_loss_scale": 6401.576077396658, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 54, "n_parameters": 106143056}
{"train_lr": 0.000705955159334333, "train_min_lr": 0.000705955159334333, "train_mlm_acc_1": 0.10101348594430647, "train_mlm_acc_2": 0.09958886703527094, "train_loss_1": 5.249068709350827, "train_loss_2": 5.272498220703323, "train_loss": 10.521566932308328, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0222565904456267, "epoch": 55, "n_parameters": 106143056}
{"train_lr": 0.0007040394493481837, "train_min_lr": 0.0007040394493481837, "train_mlm_acc_1": 0.1012502085440444, "train_mlm_acc_2": 0.09980657947288209, "train_loss_1": 5.245862778751286, "train_loss_2": 5.269319602923113, "train_loss": 10.515182383142236, "train_loss_scale": 6873.498680738786, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0052220636852602, "epoch": 56, "n_parameters": 106143056}
{"train_lr": 0.0007020857118959358, "train_min_lr": 0.0007020857118959358, "train_mlm_acc_1": 0.10135340181784663, "train_mlm_acc_2": 0.09991766309010139, "train_loss_1": 5.243925381461675, "train_loss_2": 5.267407272033976, "train_loss": 10.5113326575322, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0206595053249214, "epoch": 57, "n_parameters": 106143056}
{"train_lr": 0.0007000941762573423, "train_min_lr": 0.0007000941762573423, "train_mlm_acc_1": 0.10148961096674387, "train_mlm_acc_2": 0.10003709517707664, "train_loss_1": 5.241345387912153, "train_loss_2": 5.264806188295678, "train_loss": 10.506151576994172, "train_loss_scale": 14208.112576956904, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 58, "n_parameters": 106143056}
{"train_lr": 0.0006980650761479382, "train_min_lr": 0.0006980650761479382, "train_mlm_acc_1": 0.10161445980765443, "train_mlm_acc_2": 0.10018073659547479, "train_loss_1": 5.238535291339183, "train_loss_2": 5.262120307068502, "train_loss": 10.500655596153507, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0245282218554823, "epoch": 59, "n_parameters": 106143056}
{"train_lr": 0.0006959986496916213, "train_min_lr": 0.0006959986496916213, "train_mlm_acc_1": 0.10175818144184068, "train_mlm_acc_2": 0.10028480019472807, "train_loss_1": 5.236408425824309, "train_loss_2": 5.259987156854561, "train_loss": 10.496395581420725, "train_loss_scale": 11679.183817062445, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.029853053174736, "epoch": 60, "n_parameters": 106143056}
{"train_lr": 0.0006938951393926957, "train_min_lr": 0.0006938951393926957, "train_mlm_acc_1": 0.10186099678379539, "train_mlm_acc_2": 0.10037109044543488, "train_loss_1": 5.234971182379894, "train_loss_2": 5.258565503301176, "train_loss": 10.493536685995608, "train_loss_scale": 8480.197009674583, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 61, "n_parameters": 106143056}
{"train_lr": 0.0006917547921074234, "train_min_lr": 0.0006917547921074234, "train_mlm_acc_1": 0.10210899958958752, "train_mlm_acc_2": 0.10064736801128353, "train_loss_1": 5.232027417751604, "train_loss_2": 5.255514589127681, "train_loss": 10.487542006145366, "train_loss_scale": 8264.049252418645, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 62, "n_parameters": 106143056}
{"train_lr": 0.0006895778590150455, "train_min_lr": 0.0006895778590150455, "train_mlm_acc_1": 0.10173858719465889, "train_mlm_acc_2": 0.10026107186643225, "train_loss_1": 5.236276425283628, "train_loss_2": 5.25985237513075, "train_loss": 10.496128798579582, "train_loss_scale": 7583.183817062445, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 63, "n_parameters": 106143056}
{"train_lr": 0.0006873645955883147, "train_min_lr": 0.0006873645955883147, "train_mlm_acc_1": 0.10226590231244462, "train_mlm_acc_2": 0.10076165819506218, "train_loss_1": 5.2277722911239195, "train_loss_2": 5.251265166355207, "train_loss": 10.47903745543464, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0058871756652623, "epoch": 64, "n_parameters": 106143056}
{"train_lr": 0.0006851152615635071, "train_min_lr": 0.0006851152615635071, "train_mlm_acc_1": 0.10231657706695817, "train_mlm_acc_2": 0.10084644822189183, "train_loss_1": 5.226793101563617, "train_loss_2": 5.250255225358978, "train_loss": 10.477048328180741, "train_loss_scale": 5691.890941072999, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0228817737092024, "epoch": 65, "n_parameters": 106143056}
{"train_lr": 0.0006828301209099406, "train_min_lr": 0.0006828301209099406, "train_mlm_acc_1": 0.10233527806275439, "train_mlm_acc_2": 0.10084909361131038, "train_loss_1": 5.226347316957505, "train_loss_2": 5.249908246853526, "train_loss": 10.476255564387682, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0449383269828354, "epoch": 66, "n_parameters": 106143056}
{"train_lr": 0.0006805094417990081, "train_min_lr": 0.0006805094417990081, "train_mlm_acc_1": 0.10252412019679183, "train_mlm_acc_2": 0.10100600785488163, "train_loss_1": 5.223171816285284, "train_loss_2": 5.246799348736396, "train_loss": 10.469971165283793, "train_loss_scale": 13357.931398416886, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0154163166421908, "epoch": 67, "n_parameters": 106143056}
{"train_lr": 0.0006781534965726882, "train_min_lr": 0.0006781534965726882, "train_mlm_acc_1": 0.10261186483916528, "train_mlm_acc_2": 0.10116693021429796, "train_loss_1": 5.221513377959622, "train_loss_2": 5.245097602682357, "train_loss": 10.466610980012906, "train_loss_scale": 10396.707124010554, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 68, "n_parameters": 106143056}
{"train_lr": 0.0006757625617116008, "train_min_lr": 0.0006757625617116008, "train_mlm_acc_1": 0.10270417880810791, "train_mlm_acc_2": 0.10126716886846088, "train_loss_1": 5.2197699545241285, "train_loss_2": 5.243506590472887, "train_loss": 10.463276547303614, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0426814875376256, "epoch": 69, "n_parameters": 106143056}
{"train_lr": 0.0006733369178025507, "train_min_lr": 0.0006733369178025507, "train_mlm_acc_1": 0.10287742341214115, "train_mlm_acc_2": 0.10135757031202605, "train_loss_1": 5.217557121182914, "train_loss_2": 5.241153052163522, "train_loss": 10.458710175495769, "train_loss_scale": 16153.442392260335, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0119209508677796, "epoch": 70, "n_parameters": 106143056}
{"train_lr": 0.000670876849505609, "train_min_lr": 0.000670876849505609, "train_mlm_acc_1": 0.1027506506750352, "train_mlm_acc_2": 0.10126805063189649, "train_loss_1": 5.219147453626836, "train_loss_2": 5.242894996386824, "train_loss": 10.462042445348036, "train_loss_scale": 9924.784520668425, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 71, "n_parameters": 106143056}
{"train_lr": 0.000668382645520696, "train_min_lr": 0.000668382645520696, "train_mlm_acc_1": 0.10311093947316931, "train_mlm_acc_2": 0.1016471436142384, "train_loss_1": 5.213682644180593, "train_loss_2": 5.237402348950335, "train_loss": 10.451084992082473, "train_loss_scale": 2629.7977132805627, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 72, "n_parameters": 106143056}
{"train_lr": 0.0006658545985537059, "train_min_lr": 0.0006658545985537059, "train_mlm_acc_1": 0.10310442339409415, "train_mlm_acc_2": 0.10165519429585367, "train_loss_1": 5.212594191652699, "train_loss_2": 5.236347278640683, "train_loss": 10.448941472023332, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0554357527008995, "epoch": 73, "n_parameters": 106143056}
{"train_lr": 0.0006632930052821623, "train_min_lr": 0.0006632930052821623, "train_mlm_acc_1": 0.1032131021152674, "train_mlm_acc_2": 0.10174224033244053, "train_loss_1": 5.211414652009124, "train_loss_2": 5.235084000552235, "train_loss": 10.446498653295277, "train_loss_scale": 4007.739665787159, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0255574123211462, "epoch": 74, "n_parameters": 106143056}
{"train_lr": 0.0006606981663203897, "train_min_lr": 0.0006606981663203897, "train_mlm_acc_1": 0.10335504867238048, "train_mlm_acc_2": 0.10188612224011565, "train_loss_1": 5.208731832059728, "train_loss_2": 5.232487895453091, "train_loss": 10.44121973233571, "train_loss_scale": 4906.554089709763, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0367148106519655, "epoch": 75, "n_parameters": 106143056}
{"train_lr": 0.0006580703861842497, "train_min_lr": 0.0006580703861842497, "train_mlm_acc_1": 0.10343011597821795, "train_mlm_acc_2": 0.10195952908872326, "train_loss_1": 5.207051055569762, "train_loss_2": 5.230903434197737, "train_loss": 10.437954494066163, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0463532941217681, "epoch": 76, "n_parameters": 106143056}
{"train_lr": 0.0006554099732553881, "train_min_lr": 0.0006554099732553881, "train_mlm_acc_1": 0.10353736327870985, "train_mlm_acc_2": 0.10202277803395464, "train_loss_1": 5.205625623805332, "train_loss_2": 5.229545657584409, "train_loss": 10.43517128616021, "train_loss_scale": 11787.257695690414, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.060200075675441, "epoch": 77, "n_parameters": 106143056}
{"train_lr": 0.0006527172397450622, "train_min_lr": 0.0006527172397450622, "train_mlm_acc_1": 0.10335230020922506, "train_mlm_acc_2": 0.10187052482642436, "train_loss_1": 5.2086334135727395, "train_loss_2": 5.2324111986390935, "train_loss": 10.441044614623278, "train_loss_scale": 10497.576077396658, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 78, "n_parameters": 106143056}
{"train_lr": 0.0006499925016574828, "train_min_lr": 0.0006499925016574828, "train_mlm_acc_1": 0.10374871983619614, "train_mlm_acc_2": 0.1021984733760737, "train_loss_1": 5.202313606112068, "train_loss_2": 5.226138275185487, "train_loss": 10.428451877890078, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0432849911712405, "epoch": 79, "n_parameters": 106143056}
{"train_lr": 0.0006472360787527486, "train_min_lr": 0.0006472360787527486, "train_mlm_acc_1": 0.10388983044815933, "train_mlm_acc_2": 0.1023915527509681, "train_loss_1": 5.200111245364606, "train_loss_2": 5.223906719852353, "train_loss": 10.42401796217644, "train_loss_scale": 6992.379947229551, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0548964340957299, "epoch": 80, "n_parameters": 106143056}
{"train_lr": 0.000644448294509309, "train_min_lr": 0.000644448294509309, "train_mlm_acc_1": 0.10392185002516238, "train_mlm_acc_2": 0.10243189791192873, "train_loss_1": 5.199253021307755, "train_loss_2": 5.223101666650965, "train_loss": 10.422354683188251, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0723806866030998, "epoch": 81, "n_parameters": 106143056}
{"train_lr": 0.0006416294760860044, "train_min_lr": 0.0006416294760860044, "train_mlm_acc_1": 0.10401339669324451, "train_mlm_acc_2": 0.10251131699491774, "train_loss_1": 5.197641278948821, "train_loss_2": 5.221536549645343, "train_loss": 10.419177827126328, "train_loss_scale": 8336.098504837291, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 82, "n_parameters": 106143056}
{"train_lr": 0.0006387799542836763, "train_min_lr": 0.0006387799542836763, "train_mlm_acc_1": 0.10398932472657717, "train_mlm_acc_2": 0.10248626016322834, "train_loss_1": 5.198232958897647, "train_loss_2": 5.221947370229736, "train_loss": 10.420180331853365, "train_loss_scale": 9596.96042216359, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1285250786111978, "epoch": 83, "n_parameters": 106143056}
{"train_lr": 0.0006359000635063394, "train_min_lr": 0.0006359000635063394, "train_mlm_acc_1": 0.10431870487301546, "train_mlm_acc_2": 0.10282520266543016, "train_loss_1": 5.192411893590459, "train_loss_2": 5.21628396843438, "train_loss": 10.408695857988288, "train_loss_scale": 10548.01055408971, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 84, "n_parameters": 106143056}
{"train_lr": 0.0006329901417219492, "train_min_lr": 0.0006329901417219492, "train_mlm_acc_1": 0.10438355711258443, "train_mlm_acc_2": 0.10281964846810518, "train_loss_1": 5.191814668417606, "train_loss_2": 5.215807907656818, "train_loss": 10.407622575340506, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.044142456251797, "epoch": 85, "n_parameters": 106143056}
{"train_lr": 0.0006300505304227264, "train_min_lr": 0.0006300505304227264, "train_mlm_acc_1": 0.10408829225730168, "train_mlm_acc_2": 0.10257107311025877, "train_loss_1": 5.197433792454376, "train_loss_2": 5.221443083586143, "train_loss": 10.418876873681498, "train_loss_scale": 2905.386103781882, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 86, "n_parameters": 106143056}
{"train_lr": 0.0006270815745850904, "train_min_lr": 0.0006270815745850904, "train_mlm_acc_1": 0.10461516074816596, "train_mlm_acc_2": 0.10311342458090791, "train_loss_1": 5.187882649657385, "train_loss_2": 5.211639576767659, "train_loss": 10.399522229360716, "train_loss_scale": 2357.8117854001757, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0416204855435756, "epoch": 87, "n_parameters": 106143056}
{"train_lr": 0.0006240836226291734, "train_min_lr": 0.0006240836226291734, "train_mlm_acc_1": 0.10459369983320946, "train_mlm_acc_2": 0.10306355148871661, "train_loss_1": 5.188250782726727, "train_loss_2": 5.212066711830065, "train_loss": 10.400317497807002, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0753416931723543, "epoch": 88, "n_parameters": 106143056}
{"train_lr": 0.0006210570263779273, "train_min_lr": 0.0006210570263779273, "train_mlm_acc_1": 0.10478692810094556, "train_mlm_acc_2": 0.10325542844343757, "train_loss_1": 5.185042698758678, "train_loss_2": 5.209000928473242, "train_loss": 10.394043627074652, "train_loss_scale": 5702.698328935796, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0826516800421628, "epoch": 89, "n_parameters": 106143056}
{"train_lr": 0.0006180021410158472, "train_min_lr": 0.0006180021410158472, "train_mlm_acc_1": 0.10482932312582786, "train_mlm_acc_2": 0.1033086683764962, "train_loss_1": 5.184334575133882, "train_loss_2": 5.208379874076357, "train_loss": 10.392714447375443, "train_loss_scale": 5972.883025505716, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 90, "n_parameters": 106143056}
{"train_lr": 0.0006149193250472682, "train_min_lr": 0.0006149193250472682, "train_mlm_acc_1": 0.10495777930343554, "train_mlm_acc_2": 0.10345921537567752, "train_loss_1": 5.182744021885418, "train_loss_2": 5.206625359039508, "train_loss": 10.389369379247398, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0896338086015003, "epoch": 91, "n_parameters": 106143056}
{"train_lr": 0.0006118089402543174, "train_min_lr": 0.0006118089402543174, "train_mlm_acc_1": 0.1051134567309692, "train_mlm_acc_2": 0.10358607972314353, "train_loss_1": 5.179869724609606, "train_loss_2": 5.203768839936772, "train_loss": 10.383638558937147, "train_loss_scale": 7302.191732629727, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0658910348945894, "epoch": 92, "n_parameters": 106143056}
{"train_lr": 0.0006086713516544388, "train_min_lr": 0.0006086713516544388, "train_mlm_acc_1": 0.10510612746803852, "train_mlm_acc_2": 0.10357718161170484, "train_loss_1": 5.180032828866963, "train_loss_2": 5.203992335179865, "train_loss": 10.384025166825234, "train_loss_scale": 8386.532981530343, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0837649323485248, "epoch": 93, "n_parameters": 106143056}
{"train_lr": 0.000605506927457566, "train_min_lr": 0.000605506927457566, "train_mlm_acc_1": 0.10523633580743323, "train_mlm_acc_2": 0.10371699806944965, "train_loss_1": 5.177511886483027, "train_loss_2": 5.201403374145611, "train_loss": 10.378915263878849, "train_loss_scale": 11167.63412489006, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 94, "n_parameters": 106143056}
{"train_lr": 0.0006023160390229106, "train_min_lr": 0.0006023160390229106, "train_mlm_acc_1": 0.1053292108814354, "train_mlm_acc_2": 0.10379100034362329, "train_loss_1": 5.1760227164890855, "train_loss_2": 5.199974616997684, "train_loss": 10.375997331966511, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.076976281095201, "epoch": 95, "n_parameters": 106143056}
{"train_lr": 0.0005990990608153761, "train_min_lr": 0.0005990990608153761, "train_mlm_acc_1": 0.10538029791860987, "train_mlm_acc_2": 0.10383878923254702, "train_loss_1": 5.174899547846567, "train_loss_2": 5.198942427742136, "train_loss": 10.373841974645092, "train_loss_scale": 10367.887423043096, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 96, "n_parameters": 106143056}
{"train_lr": 0.000595856370361619, "train_min_lr": 0.000595856370361619, "train_mlm_acc_1": 0.10553363915581973, "train_mlm_acc_2": 0.1039839080095016, "train_loss_1": 5.1733451130207735, "train_loss_2": 5.197351280124751, "train_loss": 10.370696396081199, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0971137516941014, "epoch": 97, "n_parameters": 106143056}
{"train_lr": 0.0005925883482057425, "train_min_lr": 0.0005925883482057425, "train_mlm_acc_1": 0.10555163006115584, "train_mlm_acc_2": 0.104029956136944, "train_loss_1": 5.172119583125269, "train_loss_2": 5.19610653892356, "train_loss": 10.368226115915371, "train_loss_scale": 5295.620052770449, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 98, "n_parameters": 106143056}
{"train_lr": 0.0005892953778646349, "train_min_lr": 0.0005892953778646349, "train_mlm_acc_1": 0.10564681846179927, "train_mlm_acc_2": 0.10409965253580057, "train_loss_1": 5.170688183766871, "train_loss_2": 5.194771213340675, "train_loss": 10.365459401458633, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.092405150307829, "epoch": 99, "n_parameters": 106143056}
{"train_lr": 0.0005859778457829658, "train_min_lr": 0.0005859778457829658, "train_mlm_acc_1": 0.10586999347572695, "train_mlm_acc_2": 0.10433579112420296, "train_loss_1": 5.1679575527668415, "train_loss_2": 5.192012210162774, "train_loss": 10.359969758630951, "train_loss_scale": 8094.7335092348285, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.109137155292531, "epoch": 100, "n_parameters": 106143056}
{"train_lr": 0.0005826361412878357, "train_min_lr": 0.0005826361412878357, "train_mlm_acc_1": 0.1059660751334897, "train_mlm_acc_2": 0.10440390717349586, "train_loss_1": 5.166141813956758, "train_loss_2": 5.190145500574388, "train_loss": 10.35628731940646, "train_loss_scale": 9971.616534740546, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.070672597765608, "epoch": 101, "n_parameters": 106143056}
{"train_lr": 0.0005792706565430835, "train_min_lr": 0.0005792706565430835, "train_mlm_acc_1": 0.10603665330806844, "train_mlm_acc_2": 0.10453546687013739, "train_loss_1": 5.16473160543878, "train_loss_2": 5.188693097157759, "train_loss": 10.35342470626613, "train_loss_scale": 8602.68073878628, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 102, "n_parameters": 106143056}
{"train_lr": 0.0005758817865032646, "train_min_lr": 0.0005758817865032646, "train_mlm_acc_1": 0.10586327122870043, "train_mlm_acc_2": 0.10436636774998122, "train_loss_1": 5.167663691960203, "train_loss_2": 5.191779390069195, "train_loss": 10.359443082763317, "train_loss_scale": 8386.532981530343, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 103, "n_parameters": 106143056}
{"train_lr": 0.0005724699288673034, "train_min_lr": 0.0005724699288673034, "train_mlm_acc_1": 0.10615734504773335, "train_mlm_acc_2": 0.1046168098501409, "train_loss_1": 5.16181291863912, "train_loss_2": 5.185950165111556, "train_loss": 10.347763078193866, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0974567159289526, "epoch": 104, "n_parameters": 106143056}
{"train_lr": 0.0005690354840318202, "train_min_lr": 0.0005690354840318202, "train_mlm_acc_1": 0.10633395662942448, "train_mlm_acc_2": 0.10478468350296154, "train_loss_1": 5.160042501114499, "train_loss_2": 5.184044034835426, "train_loss": 10.344086539462248, "train_loss_scale": 8696.344766930519, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 105, "n_parameters": 106143056}
{"train_lr": 0.0005655788550441483, "train_min_lr": 0.0005655788550441483, "train_mlm_acc_1": 0.1063683581847301, "train_mlm_acc_2": 0.10483270140304152, "train_loss_1": 5.159024334939405, "train_loss_2": 5.183046059275051, "train_loss": 10.342070397097705, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1593118906545345, "epoch": 106, "n_parameters": 106143056}
{"train_lr": 0.0005621004475550199, "train_min_lr": 0.0005621004475550199, "train_mlm_acc_1": 0.1064800143916825, "train_mlm_acc_2": 0.104902180264767, "train_loss_1": 5.157301314063731, "train_loss_2": 5.181468018074254, "train_loss": 10.33876932589968, "train_loss_scale": 9496.091468777484, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 107, "n_parameters": 106143056}
{"train_lr": 0.0005586006697709787, "train_min_lr": 0.0005586006697709787, "train_mlm_acc_1": 0.10650517424550514, "train_mlm_acc_2": 0.10500059801947552, "train_loss_1": 5.155967056384292, "train_loss_2": 5.179958211715115, "train_loss": 10.33592527428529, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1353323276669913, "epoch": 108, "n_parameters": 106143056}
{"train_lr": 0.0005550799324064666, "train_min_lr": 0.0005550799324064666, "train_mlm_acc_1": 0.10661549063230698, "train_mlm_acc_2": 0.10508420852749308, "train_loss_1": 5.155177785779891, "train_loss_2": 5.179372012615204, "train_loss": 10.334549796927258, "train_loss_scale": 12637.43887423043, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 109, "n_parameters": 106143056}
{"train_lr": 0.0005515386486356223, "train_min_lr": 0.0005515386486356223, "train_mlm_acc_1": 0.1067877045767865, "train_mlm_acc_2": 0.10521589413943816, "train_loss_1": 5.15308042954434, "train_loss_2": 5.177291585042378, "train_loss": 10.3303720103929, "train_loss_scale": 5454.128408091468, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 110, "n_parameters": 106143056}
{"train_lr": 0.0005479772340437942, "train_min_lr": 0.0005479772340437942, "train_mlm_acc_1": 0.10691798163582829, "train_mlm_acc_2": 0.10538592081674249, "train_loss_1": 5.151075052187541, "train_loss_2": 5.175219332794401, "train_loss": 10.32629438975241, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.146578671068294, "epoch": 111, "n_parameters": 106143056}
{"train_lr": 0.0005443961065787804, "train_min_lr": 0.0005443961065787804, "train_mlm_acc_1": 0.1068597829924436, "train_mlm_acc_2": 0.10530512753985462, "train_loss_1": 5.150891122371352, "train_loss_2": 5.174972766831766, "train_loss": 10.32586389114276, "train_loss_scale": 7820.946350043975, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.234501409499186, "epoch": 112, "n_parameters": 106143056}
{"train_lr": 0.0005407956865017628, "train_min_lr": 0.0005407956865017628, "train_mlm_acc_1": 0.1071427828397212, "train_mlm_acc_2": 0.10559992284637695, "train_loss_1": 5.1469977435147225, "train_loss_2": 5.171183599121442, "train_loss": 10.31818134405158, "train_loss_scale": 7539.954265611258, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 113, "n_parameters": 106143056}
{"train_lr": 0.0005371763963380031, "train_min_lr": 0.0005371763963380031, "train_mlm_acc_1": 0.10720621504826618, "train_mlm_acc_2": 0.10565790391986635, "train_loss_1": 5.145795944550631, "train_loss_2": 5.169827903480832, "train_loss": 10.31562385395523, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1531081851784766, "epoch": 114, "n_parameters": 106143056}
{"train_lr": 0.0005335386608272497, "train_min_lr": 0.0005335386608272497, "train_mlm_acc_1": 0.10726624598240082, "train_mlm_acc_2": 0.105720316882269, "train_loss_1": 5.145289178573991, "train_loss_2": 5.169428654794852, "train_loss": 10.31471783389307, "train_loss_scale": 2779.2999120492523, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 115, "n_parameters": 106143056}
{"train_lr": 0.0005298829068738921, "train_min_lr": 0.0005298829068738921, "train_mlm_acc_1": 0.10731317597402877, "train_mlm_acc_2": 0.1057175569901392, "train_loss_1": 5.143696610143338, "train_loss_2": 5.167934985672473, "train_loss": 10.311631594714934, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.138476911614417, "epoch": 116, "n_parameters": 106143056}
{"train_lr": 0.0005262095634968652, "train_min_lr": 0.0005262095634968652, "train_mlm_acc_1": 0.10750103325533075, "train_mlm_acc_2": 0.10591150671423871, "train_loss_1": 5.141782797211183, "train_loss_2": 5.165809158861585, "train_loss": 10.307591961052927, "train_loss_scale": 3858.2374670184695, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1636439994855627, "epoch": 117, "n_parameters": 106143056}
{"train_lr": 0.0005225190617793022, "train_min_lr": 0.0005225190617793022, "train_mlm_acc_1": 0.10761304452471442, "train_mlm_acc_2": 0.10601599400710698, "train_loss_1": 5.140171947925889, "train_loss_2": 5.16445936722617, "train_loss": 10.30463130996221, "train_loss_scale": 4607.549692172383, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.164996161100208, "epoch": 118, "n_parameters": 106143056}
{"train_lr": 0.0005188118348179412, "train_min_lr": 0.0005188118348179412, "train_mlm_acc_1": 0.10769492572561733, "train_mlm_acc_2": 0.10610443721267353, "train_loss_1": 5.138729284757465, "train_loss_2": 5.162888906090115, "train_loss": 10.301618193573562, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1826960421384376, "epoch": 119, "n_parameters": 106143056}
{"train_lr": 0.0005150883176723058, "train_min_lr": 0.0005150883176723058, "train_mlm_acc_1": 0.10782457292145455, "train_mlm_acc_2": 0.10627124585512708, "train_loss_1": 5.136946844603791, "train_loss_2": 5.161138898464495, "train_loss": 10.298085741338335, "train_loss_scale": 9265.533861037818, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 120, "n_parameters": 106143056}
{"train_lr": 0.0005113489473136387, "train_min_lr": 0.0005113489473136387, "train_mlm_acc_1": 0.10787666773402256, "train_mlm_acc_2": 0.10634870665342848, "train_loss_1": 5.135272915990288, "train_loss_2": 5.159497371135098, "train_loss": 10.294770294045186, "train_loss_scale": 4319.352682497802, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 121, "n_parameters": 106143056}
{"train_lr": 0.0005075941625736347, "train_min_lr": 0.0005075941625736347, "train_mlm_acc_1": 0.10799141597697345, "train_mlm_acc_2": 0.10641562023831624, "train_loss_1": 5.134132930397882, "train_loss_2": 5.158370570173993, "train_loss": 10.292503499418576, "train_loss_scale": 4859.722075637643, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1676745777499182, "epoch": 122, "n_parameters": 106143056}
{"train_lr": 0.0005038244040929274, "train_min_lr": 0.0005038244040929274, "train_mlm_acc_1": 0.10810834004829589, "train_mlm_acc_2": 0.10653705639795792, "train_loss_1": 5.131825936029329, "train_loss_2": 5.155981650505552, "train_loss": 10.287807586849418, "train_loss_scale": 4975.0008795074755, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 123, "n_parameters": 106143056}
{"train_lr": 0.0005000401142693911, "train_min_lr": 0.0005000401142693911, "train_mlm_acc_1": 0.10816336654883497, "train_mlm_acc_2": 0.10657684039652164, "train_loss_1": 5.131119767457849, "train_loss_2": 5.15539582612332, "train_loss": 10.286515592060912, "train_loss_scale": 4204.073878627968, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1826201766965256, "epoch": 124, "n_parameters": 106143056}
{"train_lr": 0.0004962417372062153, "train_min_lr": 0.0004962417372062153, "train_mlm_acc_1": 0.10829821289840531, "train_mlm_acc_2": 0.10669023731990455, "train_loss_1": 5.128721814042345, "train_loss_2": 5.152978327416912, "train_loss": 10.281700144657044, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2088187260908732, "epoch": 125, "n_parameters": 106143056}
{"train_lr": 0.0004924297186597878, "train_min_lr": 0.0004924297186597878, "train_mlm_acc_1": 0.10840021517363654, "train_mlm_acc_2": 0.10684990000287718, "train_loss_1": 5.1272696313254125, "train_loss_2": 5.151492249472894, "train_loss": 10.27876187796748, "train_loss_scale": 4715.623570800351, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 126, "n_parameters": 106143056}
{"train_lr": 0.0004886045059873886, "train_min_lr": 0.0004886045059873886, "train_mlm_acc_1": 0.10854374204591087, "train_mlm_acc_2": 0.10695359712137317, "train_loss_1": 5.125187189304315, "train_loss_2": 5.149422872035045, "train_loss": 10.274610063960496, "train_loss_scale": 4463.451187335092, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1637864090312229, "epoch": 127, "n_parameters": 106143056}
{"train_lr": 0.00048476654809468197, "train_min_lr": 0.00048476654809468197, "train_mlm_acc_1": 0.10864748508344252, "train_mlm_acc_2": 0.10702298436618575, "train_loss_1": 5.123788495334283, "train_loss_2": 5.148020657564111, "train_loss": 10.27180914996272, "train_loss_scale": 6156.608619173263, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 128, "n_parameters": 106143056}
{"train_lr": 0.0004809162953830467, "train_min_lr": 0.0004809162953830467, "train_mlm_acc_1": 0.10872243785298541, "train_mlm_acc_2": 0.10710731627241026, "train_loss_1": 5.122153784584978, "train_loss_2": 5.146431590133103, "train_loss": 10.268585377653755, "train_loss_scale": 2282.160070360598, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 129, "n_parameters": 106143056}
{"train_lr": 0.0004770541996967091, "train_min_lr": 0.0004770541996967091, "train_mlm_acc_1": 0.10885769647129188, "train_mlm_acc_2": 0.10726137891274172, "train_loss_1": 5.1205573361383365, "train_loss_2": 5.144803917187814, "train_loss": 10.26536125233012, "train_loss_scale": 2307.377308707124, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.207328527143574, "epoch": 130, "n_parameters": 106143056}
{"train_lr": 0.00047318071426971875, "train_min_lr": 0.00047318071426971875, "train_mlm_acc_1": 0.10882620366737443, "train_mlm_acc_2": 0.10733373214145868, "train_loss_1": 5.1199634107666885, "train_loss_2": 5.144192687596998, "train_loss": 10.264156097787037, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2034216669954116, "epoch": 131, "n_parameters": 106143056}
{"train_lr": 0.00046929629367276803, "train_min_lr": 0.00046929629367276803, "train_mlm_acc_1": 0.10903675873127415, "train_mlm_acc_2": 0.10743384485001116, "train_loss_1": 5.117196459464054, "train_loss_2": 5.141441213319253, "train_loss": 10.258637671944543, "train_loss_scale": 5601.8293755496925, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2322664327965354, "epoch": 132, "n_parameters": 106143056}
{"train_lr": 0.00046540139375983523, "train_min_lr": 0.00046540139375983523, "train_mlm_acc_1": 0.10917549871117951, "train_mlm_acc_2": 0.1075616024578729, "train_loss_1": 5.11534060143334, "train_loss_2": 5.139634947401448, "train_loss": 10.254975551351079, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.244902220648847, "epoch": 133, "n_parameters": 106143056}
{"train_lr": 0.00046149647161469406, "train_min_lr": 0.00046149647161469406, "train_mlm_acc_1": 0.1092070144131819, "train_mlm_acc_2": 0.10760333329331041, "train_loss_1": 5.114596531542121, "train_loss_2": 5.138951286686652, "train_loss": 10.253547818386041, "train_loss_scale": 4557.115215479332, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 134, "n_parameters": 106143056}
{"train_lr": 0.000457581985497272, "train_min_lr": 0.000457581985497272, "train_mlm_acc_1": 0.10926990838116894, "train_mlm_acc_2": 0.10769444474624429, "train_loss_1": 5.1131182399987125, "train_loss_2": 5.137441669154188, "train_loss": 10.250559908523828, "train_loss_scale": 4621.959542656113, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2176816478673052, "epoch": 135, "n_parameters": 106143056}
{"train_lr": 0.00045365839478986964, "train_min_lr": 0.00045365839478986964, "train_mlm_acc_1": 0.10946720201692486, "train_mlm_acc_2": 0.10784175079365046, "train_loss_1": 5.111415567372909, "train_loss_2": 5.13574280739879, "train_loss": 10.247158374928967, "train_loss_scale": 4931.771328056288, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 136, "n_parameters": 106143056}
{"train_lr": 0.00044972615994325554, "train_min_lr": 0.00044972615994325554, "train_mlm_acc_1": 0.10956903255692861, "train_mlm_acc_2": 0.10792917478174338, "train_loss_1": 5.108836869451175, "train_loss_2": 5.133122704798649, "train_loss": 10.241959575717662, "train_loss_scale": 4247.303430079156, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.264751601869219, "epoch": 137, "n_parameters": 106143056}
{"train_lr": 0.00044578574242262216, "train_min_lr": 0.00044578574242262216, "train_mlm_acc_1": 0.10960722464671654, "train_mlm_acc_2": 0.10801808747381837, "train_loss_1": 5.108552821865183, "train_loss_2": 5.132757670856298, "train_loss": 10.241310492039984, "train_loss_scale": 5490.153034300792, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 138, "n_parameters": 106143056}
{"train_lr": 0.0004418376046534354, "train_min_lr": 0.0004418376046534354, "train_mlm_acc_1": 0.10983073186594583, "train_mlm_acc_2": 0.10821383514686463, "train_loss_1": 5.105730366947992, "train_loss_2": 5.1300171158139705, "train_loss": 10.2357474830765, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.258674064747786, "epoch": 139, "n_parameters": 106143056}
{"train_lr": 0.00043788220996717, "train_min_lr": 0.00043788220996717, "train_mlm_acc_1": 0.1098102329089163, "train_mlm_acc_2": 0.10817211579118602, "train_loss_1": 5.105073335512542, "train_loss_2": 5.129444457190857, "train_loss": 10.234517796582681, "train_loss_scale": 6524.059806508355, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 140, "n_parameters": 106143056}
{"train_lr": 0.0004339200225469267, "train_min_lr": 0.0004339200225469267, "train_mlm_acc_1": 0.10999694500747567, "train_mlm_acc_2": 0.10839235917366091, "train_loss_1": 5.102154883514293, "train_loss_2": 5.126590808547162, "train_loss": 10.228745693162333, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2310854252116556, "epoch": 141, "n_parameters": 106143056}
{"train_lr": 0.0004299515073729694, "train_min_lr": 0.0004299515073729694, "train_mlm_acc_1": 0.11011827810566706, "train_mlm_acc_2": 0.10851043990666576, "train_loss_1": 5.101123292769061, "train_loss_2": 5.125399096817328, "train_loss": 10.226522386021644, "train_loss_scale": 4636.369393139842, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 142, "n_parameters": 106143056}
{"train_lr": 0.0004259771301681481, "train_min_lr": 0.0004259771301681481, "train_mlm_acc_1": 0.11018203094473851, "train_mlm_acc_2": 0.10856653137334026, "train_loss_1": 5.099794801589996, "train_loss_2": 5.124135118728158, "train_loss": 10.223929921890836, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.236985182646816, "epoch": 143, "n_parameters": 106143056}
{"train_lr": 0.00042199735734324876, "train_min_lr": 0.00042199735734324876, "train_mlm_acc_1": 0.11032643963041386, "train_mlm_acc_2": 0.10871716998042433, "train_loss_1": 5.097274188892613, "train_loss_2": 5.121627951307892, "train_loss": 10.21890214261195, "train_loss_scale": 5450.5259454705365, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 144, "n_parameters": 106143056}
{"train_lr": 0.0004180126559422584, "train_min_lr": 0.0004180126559422584, "train_mlm_acc_1": 0.11044363859506846, "train_mlm_acc_2": 0.10889247601332508, "train_loss_1": 5.095083356113316, "train_loss_2": 5.119456962681488, "train_loss": 10.214540320210217, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.266757081922147, "epoch": 145, "n_parameters": 106143056}
{"train_lr": 0.00041402349358755474, "train_min_lr": 0.00041402349358755474, "train_mlm_acc_1": 0.11052634436866512, "train_mlm_acc_2": 0.10891161214481636, "train_loss_1": 5.094064816164153, "train_loss_2": 5.118377980529581, "train_loss": 10.21244280277477, "train_loss_scale": 6423.190853122252, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2788229682200187, "epoch": 146, "n_parameters": 106143056}
{"train_lr": 0.00041003033842502425, "train_min_lr": 0.00041003033842502425, "train_mlm_acc_1": 0.11071296488471401, "train_mlm_acc_2": 0.10906237666884219, "train_loss_1": 5.09217013495998, "train_loss_2": 5.116533416451963, "train_loss": 10.208703550415912, "train_loss_scale": 4351.774846086192, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 147, "n_parameters": 106143056}
{"train_lr": 0.00040603365906913383, "train_min_lr": 0.00040603365906913383, "train_mlm_acc_1": 0.11085169340451899, "train_mlm_acc_2": 0.10921553459604948, "train_loss_1": 5.089814518665995, "train_loss_2": 5.1142867630578595, "train_loss": 10.20410128507891, "train_loss_scale": 4827.299912049252, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3048175059606237, "epoch": 148, "n_parameters": 106143056}
{"train_lr": 0.000402033924547923, "train_min_lr": 0.000402033924547923, "train_mlm_acc_1": 0.11083677158221641, "train_mlm_acc_2": 0.1092337661258149, "train_loss_1": 5.089412523081351, "train_loss_2": 5.113740291633204, "train_loss": 10.203152816339658, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3095343198394607, "epoch": 149, "n_parameters": 106143056}
{"train_lr": 0.0003980316042479732, "train_min_lr": 0.0003980316042479732, "train_mlm_acc_1": 0.11093171948457273, "train_mlm_acc_2": 0.1093273282857086, "train_loss_1": 5.088199810333806, "train_loss_2": 5.112530922197729, "train_loss": 10.200730731745194, "train_loss_scale": 3647.493403693931, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 150, "n_parameters": 106143056}
{"train_lr": 0.000394027167859318, "train_min_lr": 0.000394027167859318, "train_mlm_acc_1": 0.11109553918360406, "train_mlm_acc_2": 0.10945753667506872, "train_loss_1": 5.086369132251202, "train_loss_2": 5.110795619305331, "train_loss": 10.197164750036276, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3214800786112313, "epoch": 151, "n_parameters": 106143056}
{"train_lr": 0.00039002108532032085, "train_min_lr": 0.00039002108532032085, "train_mlm_acc_1": 0.11116758325909615, "train_mlm_acc_2": 0.10953876510567197, "train_loss_1": 5.083834260938035, "train_loss_2": 5.108140469383753, "train_loss": 10.191974733729266, "train_loss_scale": 3955.503957783641, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3336823036928604, "epoch": 152, "n_parameters": 106143056}
{"train_lr": 0.00038601382676252893, "train_min_lr": 0.00038601382676252893, "train_mlm_acc_1": 0.11133381929297717, "train_mlm_acc_2": 0.10969683595195007, "train_loss_1": 5.0823156389628155, "train_loss_2": 5.106724582435588, "train_loss": 10.189040224491345, "train_loss_scale": 4802.082673702726, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3328877909202375, "epoch": 153, "n_parameters": 106143056}
{"train_lr": 0.0003820058624555032, "train_min_lr": 0.0003820058624555032, "train_mlm_acc_1": 0.11143315322254846, "train_mlm_acc_2": 0.1098069920112021, "train_loss_1": 5.080538626973212, "train_loss_2": 5.104834469243321, "train_loss": 10.18537309501081, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3494548985805026, "epoch": 154, "n_parameters": 106143056}
{"train_lr": 0.000377997662751625, "train_min_lr": 0.000377997662751625, "train_mlm_acc_1": 0.11158862454847825, "train_mlm_acc_2": 0.1099367766217603, "train_loss_1": 5.078091996693255, "train_loss_2": 5.102458464438809, "train_loss": 10.180550450490248, "train_loss_scale": 9078.205804749341, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 155, "n_parameters": 106143056}
{"train_lr": 0.0003739896980309009, "train_min_lr": 0.0003739896980309009, "train_mlm_acc_1": 0.11166678387229392, "train_mlm_acc_2": 0.1100141801580577, "train_loss_1": 5.07684182418263, "train_loss_2": 5.10128684246236, "train_loss": 10.178128668899166, "train_loss_scale": 4924.566402814424, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 156, "n_parameters": 106143056}
{"train_lr": 0.0003699824386457607, "train_min_lr": 0.0003699824386457607, "train_mlm_acc_1": 0.11174827577790332, "train_mlm_acc_2": 0.11009166383806193, "train_loss_1": 5.075518267030976, "train_loss_2": 5.099960897245634, "train_loss": 10.175479160344905, "train_loss_scale": 4254.508355321021, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3802244434151192, "epoch": 157, "n_parameters": 106143056}
{"train_lr": 0.00036597635486586153, "train_min_lr": 0.00036597635486586153, "train_mlm_acc_1": 0.11188892822421058, "train_mlm_acc_2": 0.11028399882328646, "train_loss_1": 5.072901211135096, "train_loss_2": 5.097375582474412, "train_loss": 10.170276788000276, "train_loss_scale": 7003.187335092348, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 158, "n_parameters": 106143056}
{"train_lr": 0.0003619719168228958, "train_min_lr": 0.0003619719168228958, "train_mlm_acc_1": 0.11200581802253463, "train_mlm_acc_2": 0.11036826205491469, "train_loss_1": 5.072146781673532, "train_loss_2": 5.096549857574906, "train_loss": 10.168696638776634, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3557102165415085, "epoch": 159, "n_parameters": 106143056}
{"train_lr": 0.00035796959445542426, "train_min_lr": 0.00035796959445542426, "train_mlm_acc_1": 0.11212551347967058, "train_mlm_acc_2": 0.1105221987815808, "train_loss_1": 5.0695737144248785, "train_loss_2": 5.09397476953483, "train_loss": 10.16354848306852, "train_loss_scale": 6271.887423043096, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3253572930237025, "epoch": 160, "n_parameters": 106143056}
{"train_lr": 0.0003539698574537211, "train_min_lr": 0.0003539698574537211, "train_mlm_acc_1": 0.11232163907964972, "train_mlm_acc_2": 0.11065939277092694, "train_loss_1": 5.067599777653224, "train_loss_2": 5.092082315248256, "train_loss": 10.159682098248599, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4001037805040573, "epoch": 161, "n_parameters": 106143056}
{"train_lr": 0.0003499731752046559, "train_min_lr": 0.0003499731752046559, "train_mlm_acc_1": 0.11237471870481706, "train_mlm_acc_2": 0.11071123566770093, "train_loss_1": 5.066607450170274, "train_loss_2": 5.090985686504327, "train_loss": 10.157593141969297, "train_loss_scale": 4733.6358839050135, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 162, "n_parameters": 106143056}
{"train_lr": 0.0003459800167366142, "train_min_lr": 0.0003459800167366142, "train_mlm_acc_1": 0.11254086315618761, "train_mlm_acc_2": 0.11092537514727789, "train_loss_1": 5.064543780571762, "train_loss_2": 5.088879879829437, "train_loss": 10.153423656050112, "train_loss_scale": 4182.459102902375, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 163, "n_parameters": 106143056}
{"train_lr": 0.0003419908506644451, "train_min_lr": 0.0003419908506644451, "train_mlm_acc_1": 0.1126659410197219, "train_mlm_acc_2": 0.11100749683418133, "train_loss_1": 5.062790506538216, "train_loss_2": 5.087234994981409, "train_loss": 10.150025497745188, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.367550450872725, "epoch": 164, "n_parameters": 106143056}
{"train_lr": 0.00033800614513447493, "train_min_lr": 0.00033800614513447493, "train_mlm_acc_1": 0.11276420994547892, "train_mlm_acc_2": 0.11110267376407601, "train_loss_1": 5.060511798741215, "train_loss_2": 5.0849975613826395, "train_loss": 10.145509364107982, "train_loss_scale": 4467.053649956025, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 165, "n_parameters": 106143056}
{"train_lr": 0.00033402636776956357, "train_min_lr": 0.00033402636776956357, "train_mlm_acc_1": 0.11286094430227916, "train_mlm_acc_2": 0.1111915749796685, "train_loss_1": 5.059240810684499, "train_loss_2": 5.0837475651696575, "train_loss": 10.142988375120238, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4022051257424535, "epoch": 166, "n_parameters": 106143056}
{"train_lr": 0.000330051985614231, "train_min_lr": 0.000330051985614231, "train_mlm_acc_1": 0.11303499061614275, "train_mlm_acc_2": 0.11139277377876018, "train_loss_1": 5.0574427432099665, "train_loss_2": 5.081878321938276, "train_loss": 10.139321064990973, "train_loss_scale": 5962.07563764292, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4104120982982866, "epoch": 167, "n_parameters": 106143056}
{"train_lr": 0.0003260834650798454, "train_min_lr": 0.0003260834650798454, "train_mlm_acc_1": 0.11309071569543794, "train_mlm_acc_2": 0.1114679670924601, "train_loss_1": 5.054932560329387, "train_loss_2": 5.079463927968091, "train_loss": 10.134396489398355, "train_loss_scale": 7496.72471416007, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 168, "n_parameters": 106143056}
{"train_lr": 0.00032212127188988656, "train_min_lr": 0.00032212127188988656, "train_mlm_acc_1": 0.1131759179746216, "train_mlm_acc_2": 0.11152531835434855, "train_loss_1": 5.053767465245021, "train_loss_2": 5.0781670534097, "train_loss": 10.131934515089975, "train_loss_scale": 2370.420404573439, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 169, "n_parameters": 106143056}
{"train_lr": 0.0003181658710252925, "train_min_lr": 0.0003181658710252925, "train_mlm_acc_1": 0.1133514758414059, "train_mlm_acc_2": 0.1116978758774049, "train_loss_1": 5.05164950677147, "train_loss_2": 5.076157293774731, "train_loss": 10.127806800336511, "train_loss_scale": 2219.116974494283, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4258881023607446, "epoch": 170, "n_parameters": 106143056}
{"train_lr": 0.0003142177266698921, "train_min_lr": 0.0003142177266698921, "train_mlm_acc_1": 0.11344086960377459, "train_mlm_acc_2": 0.1117522839093114, "train_loss_1": 5.051089385725892, "train_loss_2": 5.075561159623749, "train_loss": 10.126650540998554, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4434888990384607, "epoch": 171, "n_parameters": 106143056}
{"train_lr": 0.00031027730215593045, "train_min_lr": 0.00031027730215593045, "train_mlm_acc_1": 0.11370542042674915, "train_mlm_acc_2": 0.11204698764479071, "train_loss_1": 5.047496332080089, "train_loss_2": 5.071949670948055, "train_loss": 10.119446006907427, "train_loss_scale": 5385.6816182937555, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 172, "n_parameters": 106143056}
{"train_lr": 0.0003063450599096958, "train_min_lr": 0.0003063450599096958, "train_mlm_acc_1": 0.11364830969017828, "train_mlm_acc_2": 0.11200227935142364, "train_loss_1": 5.047190342750482, "train_loss_2": 5.071647875069943, "train_loss": 10.118838216509857, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.399462131103509, "epoch": 173, "n_parameters": 106143056}
{"train_lr": 0.0003024214613972495, "train_min_lr": 0.0003024214613972495, "train_mlm_acc_1": 0.11385547492338595, "train_mlm_acc_2": 0.11222923351017629, "train_loss_1": 5.044711938424391, "train_loss_2": 5.069062152921681, "train_loss": 10.113774089511278, "train_loss_scale": 4117.614775725594, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 174, "n_parameters": 106143056}
{"train_lr": 0.0002985069670702745, "train_min_lr": 0.0002985069670702745, "train_mlm_acc_1": 0.11391642202009679, "train_mlm_acc_2": 0.1122358412782456, "train_loss_1": 5.042703456278946, "train_loss_2": 5.06718447497778, "train_loss": 10.109887936394154, "train_loss_scale": 2519.9226033421282, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 175, "n_parameters": 106143056}
{"train_lr": 0.0002946020363120353, "train_min_lr": 0.0002946020363120353, "train_mlm_acc_1": 0.11414622774441041, "train_mlm_acc_2": 0.11247026206550362, "train_loss_1": 5.040390603355703, "train_loss_2": 5.064817470317361, "train_loss": 10.105208075455437, "train_loss_scale": 2069.6147757255935, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4852491637647625, "epoch": 176, "n_parameters": 106143056}
{"train_lr": 0.0002907071273834704, "train_min_lr": 0.0002907071273834704, "train_mlm_acc_1": 0.114265648345893, "train_mlm_acc_2": 0.11261649164326142, "train_loss_1": 5.03890389083453, "train_loss_2": 5.063343650957106, "train_loss": 10.102247550179273, "train_loss_scale": 3440.3518029903253, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 177, "n_parameters": 106143056}
{"train_lr": 0.0002868226973694113, "train_min_lr": 0.0002868226973694113, "train_mlm_acc_1": 0.11440460598251881, "train_mlm_acc_2": 0.11271843662618175, "train_loss_1": 5.036659167278411, "train_loss_2": 5.061029762213128, "train_loss": 10.097688928338238, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4764799868840341, "epoch": 178, "n_parameters": 106143056}
{"train_lr": 0.00028294920212494217, "train_min_lr": 0.00028294920212494217, "train_mlm_acc_1": 0.11446802672195325, "train_mlm_acc_2": 0.11282445852650476, "train_loss_1": 5.034804252699581, "train_loss_2": 5.059265407534577, "train_loss": 10.09406965934297, "train_loss_scale": 3197.1855760773965, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5166928549030945, "epoch": 179, "n_parameters": 106143056}
{"train_lr": 0.00027908709622190573, "train_min_lr": 0.00027908709622190573, "train_mlm_acc_1": 0.1146463330920291, "train_mlm_acc_2": 0.11295244517009591, "train_loss_1": 5.032984126211786, "train_loss_2": 5.057489013137163, "train_loss": 10.090473134788171, "train_loss_scale": 2950.416886543536, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 180, "n_parameters": 106143056}
{"train_lr": 0.00027523683289555303, "train_min_lr": 0.00027523683289555303, "train_mlm_acc_1": 0.1147873176871197, "train_mlm_acc_2": 0.1130618911847577, "train_loss_1": 5.03088881944289, "train_loss_2": 5.055334571273891, "train_loss": 10.086223394596063, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4961670642897238, "epoch": 181, "n_parameters": 106143056}
{"train_lr": 0.0002713988639913556, "train_min_lr": 0.0002713988639913556, "train_mlm_acc_1": 0.11494904170148632, "train_mlm_acc_2": 0.1132657124776403, "train_loss_1": 5.02905073109277, "train_loss_2": 5.053629463088019, "train_loss": 10.082680198636721, "train_loss_scale": 2224.520668425682, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 182, "n_parameters": 106143056}
{"train_lr": 0.00026757363991198143, "train_min_lr": 0.00026757363991198143, "train_mlm_acc_1": 0.11503311023918834, "train_mlm_acc_2": 0.11335676669723886, "train_loss_1": 5.0275298644286455, "train_loss_2": 5.052025954819816, "train_loss": 10.079555820139648, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4672633025241506, "epoch": 183, "n_parameters": 106143056}
{"train_lr": 0.00026376160956443706, "train_min_lr": 0.00026376160956443706, "train_mlm_acc_1": 0.11515774153477677, "train_mlm_acc_2": 0.1135065348879512, "train_loss_1": 5.025611021954864, "train_loss_2": 5.050209370798045, "train_loss": 10.0758203952692, "train_loss_scale": 4004.1372031662268, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5199121145585597, "epoch": 184, "n_parameters": 106143056}
{"train_lr": 0.00025996322030738496, "train_min_lr": 0.00025996322030738496, "train_mlm_acc_1": 0.11530392527950496, "train_mlm_acc_2": 0.11366756035304951, "train_loss_1": 5.022783519934434, "train_loss_2": 5.047314683439025, "train_loss": 10.070098203950108, "train_loss_scale": 4899.349164467898, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.500198632557348, "epoch": 185, "n_parameters": 106143056}
{"train_lr": 0.00025617891789864574, "train_min_lr": 0.00025617891789864574, "train_mlm_acc_1": 0.11543121335253106, "train_mlm_acc_2": 0.11376778759625834, "train_loss_1": 5.0218964336520235, "train_loss_2": 5.046364965623371, "train_loss": 10.068261397021217, "train_loss_scale": 4521.090589270008, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 186, "n_parameters": 106143056}
{"train_lr": 0.0002524091464428861, "train_min_lr": 0.0002524091464428861, "train_mlm_acc_1": 0.1155345783672945, "train_mlm_acc_2": 0.11382766966785819, "train_loss_1": 5.0196374184538, "train_loss_2": 5.0441720239300425, "train_loss": 10.063809447259157, "train_loss_scale": 4657.984168865435, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5178233854269498, "epoch": 187, "n_parameters": 106143056}
{"train_lr": 0.00024865434833949967, "train_min_lr": 0.00024865434833949967, "train_mlm_acc_1": 0.11571484309905385, "train_mlm_acc_2": 0.11401103778104171, "train_loss_1": 5.0176373851750125, "train_loss_2": 5.04195188417074, "train_loss": 10.059589273591994, "train_loss_scale": 4369.787159190853, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 188, "n_parameters": 106143056}
{"train_lr": 0.0002449149642306928, "train_min_lr": 0.0002449149642306928, "train_mlm_acc_1": 0.11582677414200106, "train_mlm_acc_2": 0.11414658270281532, "train_loss_1": 5.0160444158677375, "train_loss_2": 5.040566437791709, "train_loss": 10.056610854760324, "train_loss_scale": 4150.0369393139845, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 189, "n_parameters": 106143056}
{"train_lr": 0.0002411914329497703, "train_min_lr": 0.0002411914329497703, "train_mlm_acc_1": 0.11596146017303174, "train_mlm_acc_2": 0.11426441155279034, "train_loss_1": 5.014154829419068, "train_loss_2": 5.038680106689768, "train_loss": 10.05283493175775, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5977969204739928, "epoch": 190, "n_parameters": 106143056}
{"train_lr": 0.000237484191469636, "train_min_lr": 0.000237484191469636, "train_mlm_acc_1": 0.11613846107704684, "train_mlm_acc_2": 0.11445327661440052, "train_loss_1": 5.011791168490102, "train_loss_2": 5.036195698650447, "train_loss": 10.047986865882404, "train_loss_scale": 4567.922603342128, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 191, "n_parameters": 106143056}
{"train_lr": 0.00023379367485151643, "train_min_lr": 0.00023379367485151643, "train_mlm_acc_1": 0.1162895233458008, "train_mlm_acc_2": 0.11460333114543973, "train_loss_1": 5.009626369153394, "train_loss_2": 5.034087102299944, "train_loss": 10.04371346993308, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5306874576533376, "epoch": 192, "n_parameters": 106143056}
{"train_lr": 0.00023012031619389827, "train_min_lr": 0.00023012031619389827, "train_mlm_acc_1": 0.11640679098996633, "train_mlm_acc_2": 0.11471993456166255, "train_loss_1": 5.007324776527854, "train_loss_2": 5.031782359802209, "train_loss": 10.039107136906713, "train_loss_scale": 4142.83201407212, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 193, "n_parameters": 106143056}
{"train_lr": 0.00022646454658170753, "train_min_lr": 0.00022646454658170753, "train_mlm_acc_1": 0.11658465073393984, "train_mlm_acc_2": 0.11484823042728341, "train_loss_1": 5.0059934517429285, "train_loss_2": 5.030440058378976, "train_loss": 10.036433512428506, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.526770033643449, "epoch": 194, "n_parameters": 106143056}
{"train_lr": 0.00022282679503571708, "train_min_lr": 0.00022282679503571708, "train_mlm_acc_1": 0.1167072435814753, "train_mlm_acc_2": 0.11499392177595076, "train_loss_1": 5.004026632667531, "train_loss_2": 5.028593491176397, "train_loss": 10.032620124473002, "train_loss_scale": 2818.9270008795074, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 195, "n_parameters": 106143056}
{"train_lr": 0.00021920748846219963, "train_min_lr": 0.00021920748846219963, "train_mlm_acc_1": 0.11683318033165699, "train_mlm_acc_2": 0.11514745762108079, "train_loss_1": 5.000926309388881, "train_loss_2": 5.025566589024995, "train_loss": 10.02649289364341, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.590402799944345, "epoch": 196, "n_parameters": 106143056}
{"train_lr": 0.00021560705160282874, "train_min_lr": 0.00021560705160282874, "train_mlm_acc_1": 0.1170105476705595, "train_mlm_acc_2": 0.1153109910698868, "train_loss_1": 4.999610681856738, "train_loss_2": 5.024159758575359, "train_loss": 10.023770442214468, "train_loss_scale": 2739.6728232189976, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6433027573290266, "epoch": 197, "n_parameters": 106143056}
{"train_lr": 0.0002120259069848334, "train_min_lr": 0.0002120259069848334, "train_mlm_acc_1": 0.11709337943072186, "train_mlm_acc_2": 0.11538555453430695, "train_loss_1": 4.99742083331421, "train_loss_2": 5.022023482656102, "train_loss": 10.01944431497428, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6371192309871092, "epoch": 198, "n_parameters": 106143056}
{"train_lr": 0.00020846447487141197, "train_min_lr": 0.00020846447487141197, "train_mlm_acc_1": 0.11721744956555158, "train_mlm_acc_2": 0.11552609249264684, "train_loss_1": 4.996734767339684, "train_loss_2": 5.021211939782769, "train_loss": 10.017946705025544, "train_loss_scale": 3407.9296394019348, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 199, "n_parameters": 106143056}
{"train_lr": 0.0002049231732124145, "train_min_lr": 0.0002049231732124145, "train_mlm_acc_1": 0.11739550399444112, "train_mlm_acc_2": 0.11567595234122734, "train_loss_1": 4.993939872100464, "train_loss_2": 5.018543275176378, "train_loss": 10.01248314974071, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6599740570013002, "epoch": 200, "n_parameters": 106143056}
{"train_lr": 0.00020140241759529154, "train_min_lr": 0.00020140241759529154, "train_mlm_acc_1": 0.11760424960178562, "train_mlm_acc_2": 0.11589033231171947, "train_loss_1": 4.991191925767649, "train_loss_2": 5.0157910150819, "train_loss": 10.006982944361871, "train_loss_scale": 1093.3474054529463, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 201, "n_parameters": 106143056}
{"train_lr": 0.00019790262119632546, "train_min_lr": 0.00019790262119632546, "train_mlm_acc_1": 0.11763938409239447, "train_mlm_acc_2": 0.11596260537379466, "train_loss_1": 4.989912772241557, "train_loss_2": 5.014463872739697, "train_loss": 10.004376646291822, "train_loss_scale": 1201.4212840809146, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6947550241005662, "epoch": 202, "n_parameters": 106143056}
{"train_lr": 0.0001944241947321401, "train_min_lr": 0.0001944241947321401, "train_mlm_acc_1": 0.11786168875138332, "train_mlm_acc_2": 0.1161379800477084, "train_loss_1": 4.987723580765535, "train_loss_2": 5.012236000522774, "train_loss": 9.999959581969806, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7084837987848616, "epoch": 203, "n_parameters": 106143056}
{"train_lr": 0.00019096754641150413, "train_min_lr": 0.00019096754641150413, "train_mlm_acc_1": 0.11799385538201848, "train_mlm_acc_2": 0.11628067099858688, "train_loss_1": 4.985068200550901, "train_loss_2": 5.009660496036526, "train_loss": 9.994728690925772, "train_loss_scale": 2896.3799472295514, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.675529749118768, "epoch": 204, "n_parameters": 106143056}
{"train_lr": 0.00018753308188742345, "train_min_lr": 0.00018753308188742345, "train_mlm_acc_1": 0.11812404078810673, "train_mlm_acc_2": 0.11639410224083807, "train_loss_1": 4.9836674295922805, "train_loss_2": 5.008232933707476, "train_loss": 9.991900361307692, "train_loss_scale": 2190.297273526825, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 205, "n_parameters": 106143056}
{"train_lr": 0.00018412120420953888, "train_min_lr": 0.00018412120420953888, "train_mlm_acc_1": 0.11826441842708786, "train_mlm_acc_2": 0.116532075005889, "train_loss_1": 4.981568200344985, "train_loss_2": 5.005911436905018, "train_loss": 9.987479639556604, "train_loss_scale": 2399.2401055408973, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6494376395182748, "epoch": 206, "n_parameters": 106143056}
{"train_lr": 0.00018073231377682198, "train_min_lr": 0.00018073231377682198, "train_mlm_acc_1": 0.11844703073964742, "train_mlm_acc_2": 0.1167000288409144, "train_loss_1": 4.979968132685441, "train_loss_2": 5.004555395221962, "train_loss": 9.984523529847044, "train_loss_scale": 2964.8267370272647, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 207, "n_parameters": 106143056}
{"train_lr": 0.0001773668082905917, "train_min_lr": 0.0001773668082905917, "train_mlm_acc_1": 0.11857978139308559, "train_mlm_acc_2": 0.1168464874830703, "train_loss_1": 4.977328734798398, "train_loss_2": 5.001949128553127, "train_loss": 9.979277866392044, "train_loss_scale": 2002.0686015831134, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 208, "n_parameters": 106143056}
{"train_lr": 0.00017402508270783777, "train_min_lr": 0.00017402508270783777, "train_mlm_acc_1": 0.11868611247366394, "train_mlm_acc_2": 0.11695595639745525, "train_loss_1": 4.975756308439015, "train_loss_2": 5.000308036804199, "train_loss": 9.976064348074042, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6899287938652274, "epoch": 209, "n_parameters": 106143056}
{"train_lr": 0.0001707075291948745, "train_min_lr": 0.0001707075291948745, "train_mlm_acc_1": 0.11885501688433092, "train_mlm_acc_2": 0.11712159691321136, "train_loss_1": 4.973280167307053, "train_loss_2": 4.997862739686706, "train_loss": 9.971142907675254, "train_loss_scale": 1036.608619173263, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 210, "n_parameters": 106143056}
{"train_lr": 0.0001674145370813154, "train_min_lr": 0.0001674145370813154, "train_mlm_acc_1": 0.11903095270671678, "train_mlm_acc_2": 0.11730399172631868, "train_loss_1": 4.970471867628022, "train_loss_2": 4.994864311832656, "train_loss": 9.965336178307378, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.754193269430595, "epoch": 211, "n_parameters": 106143056}
{"train_lr": 0.0001641464928143861, "train_min_lr": 0.0001641464928143861, "train_mlm_acc_1": 0.11911944172155889, "train_mlm_acc_2": 0.11739250357781283, "train_loss_1": 4.969679528616349, "train_loss_2": 4.9942564681735915, "train_loss": 9.963935996108445, "train_loss_scale": 1550.8601583113457, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7193457226849693, "epoch": 212, "n_parameters": 106143056}
{"train_lr": 0.0001609037799135703, "train_min_lr": 0.0001609037799135703, "train_mlm_acc_1": 0.11930216854829719, "train_mlm_acc_2": 0.11757029465046648, "train_loss_1": 4.9670483558557486, "train_loss_2": 4.991550121164783, "train_loss": 9.958598477439914, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7237382963129377, "epoch": 213, "n_parameters": 106143056}
{"train_lr": 0.00015768677892560474, "train_min_lr": 0.00015768677892560474, "train_mlm_acc_1": 0.1194726303350852, "train_mlm_acc_2": 0.11778055190001414, "train_loss_1": 4.964895253969895, "train_loss_2": 4.989423931536176, "train_loss": 9.954319191167725, "train_loss_scale": 3595.2576956904136, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7808318569037405, "epoch": 214, "n_parameters": 106143056}
{"train_lr": 0.0001544958673798188, "train_min_lr": 0.0001544958673798188, "train_mlm_acc_1": 0.11953337133019219, "train_mlm_acc_2": 0.1178133616595805, "train_loss_1": 4.963131516044771, "train_loss_2": 4.987740734531466, "train_loss": 9.950872250156856, "train_loss_scale": 3476.376429199648, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 215, "n_parameters": 106143056}
{"train_lr": 0.00015133141974383045, "train_min_lr": 0.00015133141974383045, "train_mlm_acc_1": 0.11978421419721323, "train_mlm_acc_2": 0.11803431495313149, "train_loss_1": 4.960684068599289, "train_loss_2": 4.985256658852258, "train_loss": 9.945940724882831, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8343847777723952, "epoch": 216, "n_parameters": 106143056}
{"train_lr": 0.00014819380737959978, "train_min_lr": 0.00014819380737959978, "train_mlm_acc_1": 0.11987833755390626, "train_mlm_acc_2": 0.11817226482091657, "train_loss_1": 4.9592015311292315, "train_loss_2": 4.983651894430581, "train_loss": 9.942853426136463, "train_loss_scale": 3161.1609498680737, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8176424523247054, "epoch": 217, "n_parameters": 106143056}
{"train_lr": 0.0001450833984998489, "train_min_lr": 0.0001450833984998489, "train_mlm_acc_1": 0.12005670121383567, "train_mlm_acc_2": 0.11833019824919726, "train_loss_1": 4.956648249372433, "train_loss_2": 4.981220754857848, "train_loss": 9.937869004859355, "train_loss_scale": 2420.854881266491, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 218, "n_parameters": 106143056}
{"train_lr": 0.0001420005581248513, "train_min_lr": 0.0001420005581248513, "train_mlm_acc_1": 0.120274700025357, "train_mlm_acc_2": 0.11854248257270353, "train_loss_1": 4.953978513088159, "train_loss_2": 4.978549238559753, "train_loss": 9.932527751280952, "train_loss_scale": 2168.6824978012314, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.771904480016955, "epoch": 219, "n_parameters": 106143056}
{"train_lr": 0.00013894564803959363, "train_min_lr": 0.00013894564803959363, "train_mlm_acc_1": 0.12050133345856699, "train_mlm_acc_2": 0.11871776562888525, "train_loss_1": 4.951863411286471, "train_loss_2": 4.976399808099842, "train_loss": 9.928263220539613, "train_loss_scale": 2159.676341248901, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 220, "n_parameters": 106143056}
{"train_lr": 0.00013591902675131893, "train_min_lr": 0.00013591902675131893, "train_mlm_acc_1": 0.12053863238379452, "train_mlm_acc_2": 0.11879196262974931, "train_loss_1": 4.950508961524477, "train_loss_2": 4.9750384645914965, "train_loss": 9.92554743277366, "train_loss_scale": 2062.4098504837293, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 221, "n_parameters": 106143056}
{"train_lr": 0.00013292104944745455, "train_min_lr": 0.00013292104944745455, "train_mlm_acc_1": 0.12065094132500594, "train_mlm_acc_2": 0.11890927608155219, "train_loss_1": 4.948483577032517, "train_loss_2": 4.972918222321684, "train_loss": 9.921401795737033, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7355125591538931, "epoch": 222, "n_parameters": 106143056}
{"train_lr": 0.00012995206795392967, "train_min_lr": 0.00012995206795392967, "train_mlm_acc_1": 0.12076970917420919, "train_mlm_acc_2": 0.11903983948173996, "train_loss_1": 4.946708868392854, "train_loss_2": 4.971195037520131, "train_loss": 9.917903908534122, "train_loss_scale": 2545.1398416886545, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 223, "n_parameters": 106143056}
{"train_lr": 0.00012701243069388645, "train_min_lr": 0.00012701243069388645, "train_mlm_acc_1": 0.12102687350009865, "train_mlm_acc_2": 0.11928295220675154, "train_loss_1": 4.9439504400826175, "train_loss_2": 4.968439039108307, "train_loss": 9.912389477618241, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.849375487422356, "epoch": 224, "n_parameters": 106143056}
{"train_lr": 0.0001241024826467912, "train_min_lr": 0.0001241024826467912, "train_mlm_acc_1": 0.12112487903439825, "train_mlm_acc_2": 0.11939535284350997, "train_loss_1": 4.941943950944546, "train_loss_2": 4.966361570536514, "train_loss": 9.908305524416733, "train_loss_scale": 1060.0246262093228, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 225, "n_parameters": 106143056}
{"train_lr": 0.00012122256530794866, "train_min_lr": 0.00012122256530794866, "train_mlm_acc_1": 0.12130509793312799, "train_mlm_acc_2": 0.11958961171673885, "train_loss_1": 4.939357617337555, "train_loss_2": 4.963783054469234, "train_loss": 9.90314067259313, "train_loss_scale": 1125.7695690413368, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 226, "n_parameters": 106143056}
{"train_lr": 0.00011837301664842798, "train_min_lr": 0.00011837301664842798, "train_mlm_acc_1": 0.12145847346545209, "train_mlm_acc_2": 0.11971132272466191, "train_loss_1": 4.9377998384657715, "train_loss_2": 4.962309429754578, "train_loss": 9.900109269059113, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.911215284935927, "epoch": 227, "n_parameters": 106143056}
{"train_lr": 0.00011555417107539845, "train_min_lr": 0.00011555417107539845, "train_mlm_acc_1": 0.12169281415241584, "train_mlm_acc_2": 0.11994199876377823, "train_loss_1": 4.935139923842203, "train_loss_2": 4.959720679407279, "train_loss": 9.894860599055663, "train_loss_scale": 1379.7431838170623, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8310762554695446, "epoch": 228, "n_parameters": 106143056}
{"train_lr": 0.00011276635939288607, "train_min_lr": 0.00011276635939288607, "train_mlm_acc_1": 0.12170053273521318, "train_mlm_acc_2": 0.11991801851886925, "train_loss_1": 4.934471607575211, "train_loss_2": 4.9589433050931495, "train_loss": 9.89341491382166, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.878993823796694, "epoch": 229, "n_parameters": 106143056}
{"train_lr": 0.00011000990876295262, "train_min_lr": 0.00011000990876295262, "train_mlm_acc_1": 0.12180625686295848, "train_mlm_acc_2": 0.12009389707187916, "train_loss_1": 4.9326606884061395, "train_loss_2": 4.957007332443666, "train_loss": 9.889668019906198, "train_loss_scale": 2292.9674582233947, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 230, "n_parameters": 106143056}
{"train_lr": 0.00010728514266730062, "train_min_lr": 0.00010728514266730062, "train_mlm_acc_1": 0.12199562584298189, "train_mlm_acc_2": 0.12022670497831117, "train_loss_1": 4.930086879795229, "train_loss_2": 4.954638362926879, "train_loss": 9.884725242931799, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8438294775253234, "epoch": 231, "n_parameters": 106143056}
{"train_lr": 0.00010459238086931266, "train_min_lr": 0.00010459238086931266, "train_mlm_acc_1": 0.1222251337611345, "train_mlm_acc_2": 0.12048858747692252, "train_loss_1": 4.927867046551633, "train_loss_2": 4.952390987357238, "train_loss": 9.88025802620273, "train_loss_scale": 3501.593667546174, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8995725102034597, "epoch": 232, "n_parameters": 106143056}
{"train_lr": 0.0001019319393765248, "train_min_lr": 0.0001019319393765248, "train_mlm_acc_1": 0.12237426066703982, "train_mlm_acc_2": 0.12061391730375896, "train_loss_1": 4.925359701680424, "train_loss_2": 4.9497713295639665, "train_loss": 9.875131027889335, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8592573104454115, "epoch": 233, "n_parameters": 106143056}
{"train_lr": 9.930413040354184e-05, "train_min_lr": 9.930413040354184e-05, "train_mlm_acc_1": 0.12249088700510162, "train_mlm_acc_2": 0.12074653056213466, "train_loss_1": 4.923832680482873, "train_loss_2": 4.948258710148676, "train_loss": 9.872091391889695, "train_loss_scale": 3251.222515391381, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 234, "n_parameters": 106143056}
{"train_lr": 9.670926233539824e-05, "train_min_lr": 9.670926233539824e-05, "train_mlm_acc_1": 0.12255099811652641, "train_mlm_acc_2": 0.12080612633845841, "train_loss_1": 4.922547700537226, "train_loss_2": 4.946830205888002, "train_loss": 9.869377908522138, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9035689856991396, "epoch": 235, "n_parameters": 106143056}
{"train_lr": 9.414763969136625e-05, "train_min_lr": 9.414763969136625e-05, "train_mlm_acc_1": 0.12284916032534896, "train_mlm_acc_2": 0.12107711311645983, "train_loss_1": 4.919658164602681, "train_loss_2": 4.944221011671773, "train_loss": 9.863879177689867, "train_loss_scale": 2307.377308707124, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 236, "n_parameters": 106143056}
{"train_lr": 9.16195630892216e-05, "train_min_lr": 9.16195630892216e-05, "train_mlm_acc_1": 0.12292616305956347, "train_mlm_acc_2": 0.12114811503543807, "train_loss_1": 4.918176289755939, "train_loss_2": 4.942500376659416, "train_loss": 9.86067667359727, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8863514097720357, "epoch": 237, "n_parameters": 106143056}
{"train_lr": 8.91253292099618e-05, "train_min_lr": 8.91253292099618e-05, "train_mlm_acc_1": 0.12316373314973861, "train_mlm_acc_2": 0.12140207277019505, "train_loss_1": 4.915169806310558, "train_loss_2": 4.939629475852326, "train_loss": 9.854799281533811, "train_loss_scale": 2051.6024626209323, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 238, "n_parameters": 106143056}
{"train_lr": 8.66652307629916e-05, "train_min_lr": 8.66652307629916e-05, "train_mlm_acc_1": 0.12318669424679789, "train_mlm_acc_2": 0.12140384787593689, "train_loss_1": 4.914466386734653, "train_loss_2": 4.938843254940282, "train_loss": 9.85330963889653, "train_loss_scale": 2415.4511873350925, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.88940672174083, "epoch": 239, "n_parameters": 106143056}
{"train_lr": 8.423955645177132e-05, "train_min_lr": 8.423955645177132e-05, "train_mlm_acc_1": 0.12334595611376284, "train_mlm_acc_2": 0.12156829745045936, "train_loss_1": 4.912134093680503, "train_loss_2": 4.936547965309341, "train_loss": 9.848682064179695, "train_loss_scale": 1962.4415127528584, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 240, "n_parameters": 106143056}
{"train_lr": 8.184859093993656e-05, "train_min_lr": 8.184859093993656e-05, "train_mlm_acc_1": 0.12360120799372804, "train_mlm_acc_2": 0.12179913382122101, "train_loss_1": 4.909411059992294, "train_loss_2": 4.9338299001427, "train_loss": 9.843240961026181, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9600688806205018, "epoch": 241, "n_parameters": 106143056}
{"train_lr": 7.949261481789082e-05, "train_min_lr": 7.949261481789082e-05, "train_mlm_acc_1": 0.12363373139167079, "train_mlm_acc_2": 0.121882022801613, "train_loss_1": 4.907998696323435, "train_loss_2": 4.932329185877123, "train_loss": 9.840327886394377, "train_loss_scale": 1866.07563764292, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9736720377033807, "epoch": 242, "n_parameters": 106143056}
{"train_lr": 7.717190456987782e-05, "train_min_lr": 7.717190456987782e-05, "train_mlm_acc_1": 0.12379973849548696, "train_mlm_acc_2": 0.12202648871079441, "train_loss_1": 4.906608928895982, "train_loss_2": 4.930887518688158, "train_loss": 9.837496447164758, "train_loss_scale": 1737.287598944591, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 243, "n_parameters": 106143056}
{"train_lr": 7.488673254153478e-05, "train_min_lr": 7.488673254153478e-05, "train_mlm_acc_1": 0.12401403822152234, "train_mlm_acc_2": 0.12220764663660195, "train_loss_1": 4.903420154631085, "train_loss_2": 4.927822837152288, "train_loss": 9.831242990997033, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0681624996525843, "epoch": 244, "n_parameters": 106143056}
{"train_lr": 7.263736690793118e-05, "train_min_lr": 7.263736690793118e-05, "train_mlm_acc_1": 0.124196329838027, "train_mlm_acc_2": 0.1224013672840168, "train_loss_1": 4.901658114992744, "train_loss_2": 4.925919184793793, "train_loss": 9.827577303560973, "train_loss_scale": 1198.7194371152154, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 245, "n_parameters": 106143056}
{"train_lr": 7.04240716420974e-05, "train_min_lr": 7.04240716420974e-05, "train_mlm_acc_1": 0.12426230436880649, "train_mlm_acc_2": 0.12248548174075448, "train_loss_1": 4.900318361838449, "train_loss_2": 4.924678052111267, "train_loss": 9.824996418562916, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0097050131048775, "epoch": 246, "n_parameters": 106143056}
{"train_lr": 6.824710648404599e-05, "train_min_lr": 6.824710648404599e-05, "train_mlm_acc_1": 0.12444977234334749, "train_mlm_acc_2": 0.12271643264207698, "train_loss_1": 4.897600937696959, "train_loss_2": 4.921817645391248, "train_loss": 9.81941857816047, "train_loss_scale": 1653.5303430079155, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.042534724913256, "epoch": 247, "n_parameters": 106143056}
{"train_lr": 6.610672691029053e-05, "train_min_lr": 6.610672691029053e-05, "train_mlm_acc_1": 0.12456731484316637, "train_mlm_acc_2": 0.12276937481238717, "train_loss_1": 4.89684768150853, "train_loss_2": 4.921236389020922, "train_loss": 9.818084070214915, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.951601128674644, "epoch": 248, "n_parameters": 106143056}
{"train_lr": 6.400318410386393e-05, "train_min_lr": 6.400318410386393e-05, "train_mlm_acc_1": 0.12471342982237761, "train_mlm_acc_2": 0.12294345541153572, "train_loss_1": 4.894558084933718, "train_loss_2": 4.918863346310383, "train_loss": 9.813421430352914, "train_loss_scale": 1266.7159190853122, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 249, "n_parameters": 106143056}
{"train_lr": 6.19367249248409e-05, "train_min_lr": 6.19367249248409e-05, "train_mlm_acc_1": 0.1248881633187871, "train_mlm_acc_2": 0.12310188138167798, "train_loss_1": 4.892830812574586, "train_loss_2": 4.91706799108309, "train_loss": 9.809898801613189, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0354857504525095, "epoch": 250, "n_parameters": 106143056}
{"train_lr": 5.990759188136876e-05, "train_min_lr": 5.990759188136876e-05, "train_mlm_acc_1": 0.12495188178574845, "train_mlm_acc_2": 0.1231601716174024, "train_loss_1": 4.890813943788265, "train_loss_2": 4.915186277008308, "train_loss": 9.80600021728425, "train_loss_scale": 938.4415127528584, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0327110807415467, "epoch": 251, "n_parameters": 106143056}
{"train_lr": 5.791602310120655e-05, "train_min_lr": 5.791602310120655e-05, "train_mlm_acc_1": 0.12506729423780266, "train_mlm_acc_2": 0.1233038817325127, "train_loss_1": 4.889450449794662, "train_loss_2": 4.913685757335908, "train_loss": 9.803136206658765, "train_loss_scale": 1099.6517150395778, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0453718803174263, "epoch": 252, "n_parameters": 106143056}
{"train_lr": 5.59622523037808e-05, "train_min_lr": 5.59622523037808e-05, "train_mlm_acc_1": 0.12520900029662863, "train_mlm_acc_2": 0.12342381775100685, "train_loss_1": 4.8879260049646325, "train_loss_2": 4.9121339507761395, "train_loss": 9.800059952018758, "train_loss_scale": 1770.6103781882146, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 253, "n_parameters": 106143056}
{"train_lr": 5.4046508772757435e-05, "train_min_lr": 5.4046508772757435e-05, "train_mlm_acc_1": 0.12532818045306593, "train_mlm_acc_2": 0.12357183377501754, "train_loss_1": 4.886322447314217, "train_loss_2": 4.910518187121959, "train_loss": 9.796840638472725, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.11603007394175, "epoch": 254, "n_parameters": 106143056}
{"train_lr": 5.2169017329133505e-05, "train_min_lr": 5.2169017329133505e-05, "train_mlm_acc_1": 0.1254514260610718, "train_mlm_acc_2": 0.12367998572474341, "train_loss_1": 4.884716578240759, "train_loss_2": 4.908884560736838, "train_loss": 9.79360113882033, "train_loss_scale": 1153.688654353562, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 255, "n_parameters": 106143056}
{"train_lr": 5.03299983048543e-05, "train_min_lr": 5.03299983048543e-05, "train_mlm_acc_1": 0.12558163433002345, "train_mlm_acc_2": 0.12380776625198682, "train_loss_1": 4.883049441201706, "train_loss_2": 4.907267652642024, "train_loss": 9.790317095259145, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.073976615383212, "epoch": 256, "n_parameters": 106143056}
{"train_lr": 4.8529667516956426e-05, "train_min_lr": 4.8529667516956426e-05, "train_mlm_acc_1": 0.1257133543656823, "train_mlm_acc_2": 0.12392317873516702, "train_loss_1": 4.881472517758372, "train_loss_2": 4.905669077457622, "train_loss": 9.787141593171508, "train_loss_scale": 1394.1530343007917, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 257, "n_parameters": 106143056}
{"train_lr": 4.676823624223976e-05, "train_min_lr": 4.676823624223976e-05, "train_mlm_acc_1": 0.12596933909822108, "train_mlm_acc_2": 0.1241793238198288, "train_loss_1": 4.878930137832645, "train_loss_2": 4.903206562670889, "train_loss": 9.78213670291498, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0476995752690232, "epoch": 258, "n_parameters": 106143056}
{"train_lr": 4.5045911192474324e-05, "train_min_lr": 4.5045911192474324e-05, "train_mlm_acc_1": 0.12594340054568956, "train_mlm_acc_2": 0.12412253377767461, "train_loss_1": 4.878056856656976, "train_loss_2": 4.902241704436699, "train_loss": 9.780298560359757, "train_loss_scale": 1541.8540017590149, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.061324092517742, "epoch": 259, "n_parameters": 106143056}
{"train_lr": 4.336289449014104e-05, "train_min_lr": 4.336289449014104e-05, "train_mlm_acc_1": 0.1261149731619495, "train_mlm_acc_2": 0.12437520887237452, "train_loss_1": 4.876320068523773, "train_loss_2": 4.900489150429359, "train_loss": 9.776809217432872, "train_loss_scale": 1192.415127528584, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 260, "n_parameters": 106143056}
{"train_lr": 4.171938364471223e-05, "train_min_lr": 4.171938364471223e-05, "train_mlm_acc_1": 0.12621340243655307, "train_mlm_acc_2": 0.12444538623749843, "train_loss_1": 4.875057922451771, "train_loss_2": 4.899070840345314, "train_loss": 9.774128757974193, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.031480738858749, "epoch": 261, "n_parameters": 106143056}
{"train_lr": 4.011557152947225e-05, "train_min_lr": 4.011557152947225e-05, "train_mlm_acc_1": 0.12630521249609264, "train_mlm_acc_2": 0.12444647418690571, "train_loss_1": 4.87385070533635, "train_loss_2": 4.897934873374597, "train_loss": 9.771785584267757, "train_loss_scale": 891.1591908531223, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.097711554093642, "epoch": 262, "n_parameters": 106143056}
{"train_lr": 3.8551646358884036e-05, "train_min_lr": 3.8551646358884036e-05, "train_mlm_acc_1": 0.12649718107755575, "train_mlm_acc_2": 0.12473376853212963, "train_loss_1": 4.871247572812892, "train_loss_2": 4.895367316279164, "train_loss": 9.766614885212773, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.066040218662775, "epoch": 263, "n_parameters": 106143056}
{"train_lr": 3.702779166650029e-05, "train_min_lr": 3.702779166650029e-05, "train_mlm_acc_1": 0.12658997600211735, "train_mlm_acc_2": 0.1248180660924554, "train_loss_1": 4.869960063313222, "train_loss_2": 4.894004239203538, "train_loss": 9.763964309541405, "train_loss_scale": 1933.6218117854003, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 264, "n_parameters": 106143056}
{"train_lr": 3.55441862834257e-05, "train_min_lr": 3.55441862834257e-05, "train_mlm_acc_1": 0.12676594627770474, "train_mlm_acc_2": 0.12503682070050517, "train_loss_1": 4.86777481544196, "train_loss_2": 4.891792726338486, "train_loss": 9.759567541413487, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.026398931560332, "epoch": 265, "n_parameters": 106143056}
{"train_lr": 3.4101004317329864e-05, "train_min_lr": 3.4101004317329864e-05, "train_mlm_acc_1": 0.12683125646013305, "train_mlm_acc_2": 0.1250555904405216, "train_loss_1": 4.86765424043543, "train_loss_2": 4.891800462203584, "train_loss": 9.759454702009942, "train_loss_scale": 1366.2339489885665, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0444673610131994, "epoch": 266, "n_parameters": 106143056}
{"train_lr": 3.269841513201525e-05, "train_min_lr": 3.269841513201525e-05, "train_mlm_acc_1": 0.12691238188662335, "train_mlm_acc_2": 0.12512502335208545, "train_loss_1": 4.865395358023983, "train_loss_2": 4.889528757034946, "train_loss": 9.754924120877853, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.082291897389589, "epoch": 267, "n_parameters": 106143056}
{"train_lr": 3.1336583327541557e-05, "train_min_lr": 3.1336583327541557e-05, "train_mlm_acc_1": 0.12702236608778214, "train_mlm_acc_2": 0.125286850479506, "train_loss_1": 4.86424573136718, "train_loss_2": 4.888353311449368, "train_loss": 9.752599046957943, "train_loss_scale": 1119.4652594547053, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 268, "n_parameters": 106143056}
{"train_lr": 3.0015668720909095e-05, "train_min_lr": 3.0015668720909095e-05, "train_mlm_acc_1": 0.12706663926019807, "train_mlm_acc_2": 0.12529940176558604, "train_loss_1": 4.863624154525361, "train_loss_2": 4.887604342444276, "train_loss": 9.751228502054643, "train_loss_scale": 1175.3034300791558, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0912122805074524, "epoch": 269, "n_parameters": 106143056}
{"train_lr": 2.8735826327303497e-05, "train_min_lr": 2.8735826327303497e-05, "train_mlm_acc_1": 0.1272225342584461, "train_mlm_acc_2": 0.12546752747672502, "train_loss_1": 4.861717465003541, "train_loss_2": 4.885824910359311, "train_loss": 9.747542375729811, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0537904541851035, "epoch": 270, "n_parameters": 106143056}
{"train_lr": 2.7497206341904298e-05, "train_min_lr": 2.7497206341904298e-05, "train_mlm_acc_1": 0.12721349870525595, "train_mlm_acc_2": 0.1254017018535311, "train_loss_1": 4.861832983523161, "train_loss_2": 4.8858297825279005, "train_loss": 9.747662765159875, "train_loss_scale": 2273.1539138082676, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 271, "n_parameters": 106143056}
{"train_lr": 2.629995412225849e-05, "train_min_lr": 2.629995412225849e-05, "train_mlm_acc_1": 0.12730927112378776, "train_mlm_acc_2": 0.1255584671567526, "train_loss_1": 4.860450218619227, "train_loss_2": 4.8845359339143695, "train_loss": 9.744986156150764, "train_loss_scale": 1118.5646437994724, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 272, "n_parameters": 106143056}
{"train_lr": 2.514421017122239e-05, "train_min_lr": 2.514421017122239e-05, "train_mlm_acc_1": 0.12739370613733245, "train_mlm_acc_2": 0.125618280466931, "train_loss_1": 4.859415951326634, "train_loss_2": 4.883393703056409, "train_loss": 9.74280965967774, "train_loss_scale": 1176.2040457343887, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0948881269444892, "epoch": 273, "n_parameters": 106143056}
{"train_lr": 2.4030110120472967e-05, "train_min_lr": 2.4030110120472967e-05, "train_mlm_acc_1": 0.12756299992028883, "train_mlm_acc_2": 0.12578734523545468, "train_loss_1": 4.8582767470426065, "train_loss_2": 4.88228986230773, "train_loss": 9.740566613177196, "train_loss_scale": 1142.8812664907653, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 274, "n_parameters": 106143056}
{"train_lr": 2.29577847145909e-05, "train_min_lr": 2.29577847145909e-05, "train_mlm_acc_1": 0.12770613743256035, "train_mlm_acc_2": 0.12589531397756612, "train_loss_1": 4.8561088518291164, "train_loss_2": 4.880127987425476, "train_loss": 9.736236837734333, "train_loss_scale": 1151.8874230430959, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.066842468768332, "epoch": 275, "n_parameters": 106143056}
{"train_lr": 2.1927359795716904e-05, "train_min_lr": 2.1927359795716904e-05, "train_mlm_acc_1": 0.12778240723966267, "train_mlm_acc_2": 0.126024399992167, "train_loss_1": 4.85579307590961, "train_loss_2": 4.879853349090566, "train_loss": 9.735646425576826, "train_loss_scale": 1506.7299912049252, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 276, "n_parameters": 106143056}
{"train_lr": 2.093895628878402e-05, "train_min_lr": 2.093895628878402e-05, "train_mlm_acc_1": 0.1277583467158945, "train_mlm_acc_2": 0.125976759902707, "train_loss_1": 4.854845202902271, "train_loss_2": 4.87869240090631, "train_loss": 9.7335376022359, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0914710637447387, "epoch": 277, "n_parameters": 106143056}
{"train_lr": 1.9992690187326e-05, "train_min_lr": 1.9992690187326e-05, "train_mlm_acc_1": 0.1279319235514407, "train_mlm_acc_2": 0.1261648692406891, "train_loss_1": 4.852559434916749, "train_loss_2": 4.876483322290758, "train_loss": 9.729042762921583, "train_loss_scale": 1475.208443271768, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 278, "n_parameters": 106143056}
{"train_lr": 1.9088672539865457e-05, "train_min_lr": 1.9088672539865457e-05, "train_mlm_acc_1": 0.12804690075722067, "train_mlm_acc_2": 0.12623111856650812, "train_loss_1": 4.851660858305694, "train_loss_2": 4.875545576673489, "train_loss": 9.727206435555834, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0882548563503445, "epoch": 279, "n_parameters": 106143056}
{"train_lr": 1.8227009436881574e-05, "train_min_lr": 1.8227009436881574e-05, "train_mlm_acc_1": 0.12805412689890638, "train_mlm_acc_2": 0.12626604694650298, "train_loss_1": 4.852280633063723, "train_loss_2": 4.876119988522408, "train_loss": 9.728400619698913, "train_loss_scale": 1550.8601583113457, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 280, "n_parameters": 106143056}
{"train_lr": 1.7407801998359794e-05, "train_min_lr": 1.7407801998359794e-05, "train_mlm_acc_1": 0.12806644916645823, "train_mlm_acc_2": 0.12627486492979784, "train_loss_1": 4.851112660076289, "train_loss_2": 4.8748899482800025, "train_loss": 9.7260026069933, "train_loss_scale": 816.858399296394, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 281, "n_parameters": 106143056}
{"train_lr": 1.6631146361925272e-05, "train_min_lr": 1.6631146361925272e-05, "train_mlm_acc_1": 0.12819840965043874, "train_mlm_acc_2": 0.12639071261747795, "train_loss_1": 4.849395451099074, "train_loss_2": 4.8732649548701685, "train_loss": 9.722660409219452, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1524078181257558, "epoch": 282, "n_parameters": 106143056}
{"train_lr": 1.5897133671560495e-05, "train_min_lr": 1.5897133671560495e-05, "train_mlm_acc_1": 0.12817394830247186, "train_mlm_acc_2": 0.12638078368921735, "train_loss_1": 4.8496649610755105, "train_loss_2": 4.873545332340788, "train_loss": 9.723210294517175, "train_loss_scale": 842.5259454705365, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.141354135913396, "epoch": 283, "n_parameters": 106143056}
{"train_lr": 1.5205850066909038e-05, "train_min_lr": 1.5205850066909038e-05, "train_mlm_acc_1": 0.12832227367465446, "train_mlm_acc_2": 0.12651764559367035, "train_loss_1": 4.848217075240119, "train_loss_2": 4.872177838073452, "train_loss": 9.72039490964398, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1136292482324097, "epoch": 284, "n_parameters": 106143056}
{"train_lr": 1.4557376673166934e-05, "train_min_lr": 1.4557376673166934e-05, "train_mlm_acc_1": 0.12832397998948708, "train_mlm_acc_2": 0.12654876048294147, "train_loss_1": 4.848014755372741, "train_loss_2": 4.871870108938259, "train_loss": 9.719884864573114, "train_loss_scale": 1931.820580474934, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1401206272782836, "epoch": 285, "n_parameters": 106143056}
{"train_lr": 1.3951789591562158e-05, "train_min_lr": 1.3951789591562158e-05, "train_mlm_acc_1": 0.12832693456735203, "train_mlm_acc_2": 0.12656941979045577, "train_loss_1": 4.847327039025809, "train_loss_2": 4.871201509326408, "train_loss": 9.7185285499249, "train_loss_scale": 1701.2629727352682, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 286, "n_parameters": 106143056}
{"train_lr": 1.3389159890423752e-05, "train_min_lr": 1.3389159890423752e-05, "train_mlm_acc_1": 0.12851338337110838, "train_mlm_acc_2": 0.12672454749521528, "train_loss_1": 4.845647702640678, "train_loss_2": 4.869451983098724, "train_loss": 9.71509967494032, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1785665820749998, "epoch": 287, "n_parameters": 106143056}
{"train_lr": 1.2869553596841708e-05, "train_min_lr": 1.2869553596841708e-05, "train_mlm_acc_1": 0.12854045563645286, "train_mlm_acc_2": 0.1267584566012182, "train_loss_1": 4.845754727314938, "train_loss_2": 4.869621215363606, "train_loss": 9.715375946190866, "train_loss_scale": 1313.0976253298154, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 288, "n_parameters": 106143056}
{"train_lr": 1.2393031688918403e-05, "train_min_lr": 1.2393031688918403e-05, "train_mlm_acc_1": 0.1286334452737801, "train_mlm_acc_2": 0.12688119833668074, "train_loss_1": 4.844325032062246, "train_loss_2": 4.8681727050162245, "train_loss": 9.712497735400943, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2220870407401416, "epoch": 289, "n_parameters": 106143056}
{"train_lr": 1.1959650088612536e-05, "train_min_lr": 1.1959650088612536e-05, "train_mlm_acc_1": 0.12854574637843022, "train_mlm_acc_2": 0.1268190258258762, "train_loss_1": 4.844699733961855, "train_loss_2": 4.868458428189958, "train_loss": 9.71315816325269, "train_loss_scale": 1575.1767810026386, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1665967263563117, "epoch": 290, "n_parameters": 106143056}
{"train_lr": 1.1569459655176374e-05, "train_min_lr": 1.1569459655176374e-05, "train_mlm_acc_1": 0.12854330720529025, "train_mlm_acc_2": 0.12679086554969154, "train_loss_1": 4.844640166851755, "train_loss_2": 4.8684122784680826, "train_loss": 9.713052445267415, "train_loss_scale": 1566.1706244503077, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 291, "n_parameters": 106143056}
{"train_lr": 1.1222506179187317e-05, "train_min_lr": 1.1222506179187317e-05, "train_mlm_acc_1": 0.1286476685230603, "train_mlm_acc_2": 0.12685083929308433, "train_loss_1": 4.843873686714978, "train_loss_2": 4.867650808214408, "train_loss": 9.711524492098558, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1893815720616043, "epoch": 292, "n_parameters": 106143056}
{"train_lr": 1.0918830377174124e-05, "train_min_lr": 1.0918830377174124e-05, "train_mlm_acc_1": 0.12869654531879784, "train_mlm_acc_2": 0.1269562542258304, "train_loss_1": 4.843198379876851, "train_loss_2": 4.8669633060667525, "train_loss": 9.710161682274013, "train_loss_scale": 1146.4837291116974, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 293, "n_parameters": 106143056}
{"train_lr": 1.0658467886838543e-05, "train_min_lr": 1.0658467886838543e-05, "train_mlm_acc_1": 0.12875927895923509, "train_mlm_acc_2": 0.12701078823856884, "train_loss_1": 4.84250447728074, "train_loss_2": 4.866189440825369, "train_loss": 9.708693919521522, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1468920904812103, "epoch": 294, "n_parameters": 106143056}
{"train_lr": 1.0441449262873223e-05, "train_min_lr": 1.0441449262873223e-05, "train_mlm_acc_1": 0.1287435668978509, "train_mlm_acc_2": 0.12692520802917587, "train_loss_1": 4.842501365362602, "train_loss_2": 4.8664112703886175, "train_loss": 9.708912629460492, "train_loss_scale": 1876.883025505717, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1783658095169405, "epoch": 295, "n_parameters": 106143056}
{"train_lr": 1.0267799973375903e-05, "train_min_lr": 1.0267799973375903e-05, "train_mlm_acc_1": 0.12874085280926292, "train_mlm_acc_2": 0.12696989346049864, "train_loss_1": 4.842652172453066, "train_loss_2": 4.866583686600469, "train_loss": 9.709235861098023, "train_loss_scale": 1064.5277044854881, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 296, "n_parameters": 106143056}
{"train_lr": 1.0137540396860598e-05, "train_min_lr": 1.0137540396860598e-05, "train_mlm_acc_1": 0.12881446572015734, "train_mlm_acc_2": 0.12705231291506514, "train_loss_1": 4.841620683879735, "train_loss_2": 4.865456326655788, "train_loss": 9.70707701315666, "train_loss_scale": 1230.240985048373, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1328889915790072, "epoch": 297, "n_parameters": 106143056}
{"train_lr": 1.0050685819866211e-05, "train_min_lr": 1.0050685819866211e-05, "train_mlm_acc_1": 0.1287929590123074, "train_mlm_acc_2": 0.12700742135838447, "train_loss_1": 4.84147433025751, "train_loss_2": 4.86537100698409, "train_loss": 9.706845333205049, "train_loss_scale": 1362.6314863676341, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 298, "n_parameters": 106143056}
{"train_lr": 1.0007246435162376e-05, "train_min_lr": 1.0007246435162376e-05, "train_mlm_acc_1": 0.12885485669121263, "train_mlm_acc_2": 0.12703371502249358, "train_loss_1": 4.841749563957372, "train_loss_2": 4.865633934657618, "train_loss": 9.707383499506177, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.184718128663988, "epoch": 299, "n_parameters": 106143056}
