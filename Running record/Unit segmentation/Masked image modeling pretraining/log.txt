{"train_lr": 3.7470314011786434e-05, "train_min_lr": 3.7470314011786434e-05, "train_mlm_acc_1": 0.12628339665631452, "train_mlm_acc_2": 0.1264079478049197, "train_loss_1": 4.745111681121216, "train_loss_2": 4.740631538571867, "train_loss": 9.485743217438905, "train_loss_scale": 617.3720316622691, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 0, "n_parameters": 106143056}
{"train_lr": 0.00011247691089805615, "train_min_lr": 0.00011247691089805615, "train_mlm_acc_1": 0.13719401945971876, "train_mlm_acc_2": 0.13735636192469766, "train_loss_1": 4.557517963118372, "train_loss_2": 4.552809536771598, "train_loss": 9.110327496272802, "train_loss_scale": 353.0413368513632, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 1, "n_parameters": 106143056}
{"train_lr": 0.00018748350778432582, "train_min_lr": 0.00018748350778432582, "train_mlm_acc_1": 0.14160413118922982, "train_mlm_acc_2": 0.14178809492456462, "train_loss_1": 4.47513745102635, "train_loss_2": 4.470096091534238, "train_loss": 8.945233545391416, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.712756704214695, "epoch": 2, "n_parameters": 106143056}
{"train_lr": 0.0002624901046705954, "train_min_lr": 0.0002624901046705954, "train_mlm_acc_1": 0.14525883991464567, "train_mlm_acc_2": 0.1454450251688573, "train_loss_1": 4.4125987458040346, "train_loss_2": 4.407690403172083, "train_loss": 8.82028915018184, "train_loss_scale": 476.650835532102, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.045574326838122, "epoch": 3, "n_parameters": 106143056}
{"train_lr": 0.0003374967015568651, "train_min_lr": 0.0003374967015568651, "train_mlm_acc_1": 0.14825749093062174, "train_mlm_acc_2": 0.14837357904205037, "train_loss_1": 4.365076413727058, "train_loss_2": 4.360715292636616, "train_loss": 8.725791710767185, "train_loss_scale": 564.6860158311346, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.2259222995637273, "epoch": 4, "n_parameters": 106143056}
{"train_lr": 0.0004125032984431348, "train_min_lr": 0.0004125032984431348, "train_mlm_acc_1": 0.15077492082942026, "train_mlm_acc_2": 0.15080382547643537, "train_loss_1": 4.327009457187267, "train_loss_2": 4.323679295410267, "train_loss": 8.650688761666666, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.835726054383666, "epoch": 5, "n_parameters": 106143056}
{"train_lr": 0.00048750989532940465, "train_min_lr": 0.00048750989532940465, "train_mlm_acc_1": 0.15249928222803716, "train_mlm_acc_2": 0.15242676871682115, "train_loss_1": 4.299877499999345, "train_loss_2": 4.297636909294044, "train_loss": 8.597514405938336, "train_loss_scale": 1376.1407211961302, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.4807105143026185, "epoch": 6, "n_parameters": 106143056}
{"train_lr": 0.0005625164922156739, "train_min_lr": 0.0005625164922156739, "train_mlm_acc_1": 0.15389177850926772, "train_mlm_acc_2": 0.15375753910679668, "train_loss_1": 4.277485030045505, "train_loss_2": 4.276585103916094, "train_loss": 8.554070130187164, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1758977009103084, "epoch": 7, "n_parameters": 106143056}
{"train_lr": 0.0006375230891019436, "train_min_lr": 0.0006375230891019436, "train_mlm_acc_1": 0.15501808630517153, "train_mlm_acc_2": 0.1547662242591748, "train_loss_1": 4.262743883994764, "train_loss_2": 4.263097229450548, "train_loss": 8.525841115751913, "train_loss_scale": 3245.8188214599822, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0311822438827187, "epoch": 8, "n_parameters": 106143056}
{"train_lr": 0.0007125296859882135, "train_min_lr": 0.0007125296859882135, "train_mlm_acc_1": 0.15615348694002357, "train_mlm_acc_2": 0.1557823302619087, "train_loss_1": 4.245515720615706, "train_loss_2": 4.246871304071673, "train_loss": 8.492387018082114, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7934154280991332, "epoch": 9, "n_parameters": 106143056}
{"train_lr": 0.0007499927726594455, "train_min_lr": 0.0007499927726594455, "train_mlm_acc_1": 0.15788742219709784, "train_mlm_acc_2": 0.1574662091503724, "train_loss_1": 4.222721820168046, "train_loss_2": 4.22507654661239, "train_loss": 8.447798366754224, "train_loss_scale": 7478.712401055409, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5539735492741527, "epoch": 10, "n_parameters": 106143056}
{"train_lr": 0.0007499493714617194, "train_min_lr": 0.0007499493714617194, "train_mlm_acc_1": 0.16011013687410527, "train_mlm_acc_2": 0.1596423260893807, "train_loss_1": 4.19587682519131, "train_loss_2": 4.199000294494755, "train_loss": 8.394877123067332, "train_loss_scale": 8739.574318381707, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4014972319913308, "epoch": 11, "n_parameters": 106143056}
{"train_lr": 0.0007498625550649799, "train_min_lr": 0.0007498625550649799, "train_mlm_acc_1": 0.16206330781116124, "train_mlm_acc_2": 0.16150314859692055, "train_loss_1": 4.172627109414984, "train_loss_2": 4.176389366099996, "train_loss": 8.34901647800506, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.33448186655682, "epoch": 12, "n_parameters": 106143056}
{"train_lr": 0.000749732333657516, "train_min_lr": 0.000749732333657516, "train_mlm_acc_1": 0.16368194512708364, "train_mlm_acc_2": 0.16310862758464736, "train_loss_1": 4.1517417498503, "train_loss_2": 4.156109152625502, "train_loss": 8.307850900562373, "train_loss_scale": 17306.23043095866, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 13, "n_parameters": 106143056}
{"train_lr": 0.0007495587225213875, "train_min_lr": 0.0007495587225213875, "train_mlm_acc_1": 0.1652812515610703, "train_mlm_acc_2": 0.16465326266243674, "train_loss_1": 4.132528032245821, "train_loss_2": 4.137414667725878, "train_loss": 8.269942696616644, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1896096744239593, "epoch": 14, "n_parameters": 106143056}
{"train_lr": 0.0007493417420306326, "train_min_lr": 0.0007493417420306326, "train_mlm_acc_1": 0.16652668231775494, "train_mlm_acc_2": 0.16585009138156367, "train_loss_1": 4.117127262534232, "train_loss_2": 4.122666951770204, "train_loss": 8.239794217344953, "train_loss_scale": 20274.65963060686, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 15, "n_parameters": 106143056}
{"train_lr": 0.0007490814176488726, "train_min_lr": 0.0007490814176488726, "train_mlm_acc_1": 0.1678093547507688, "train_mlm_acc_2": 0.16710865752822282, "train_loss_1": 4.102756596256372, "train_loss_2": 4.108631360997416, "train_loss": 8.211387955681106, "train_loss_scale": 11095.584872471416, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 16, "n_parameters": 106143056}
{"train_lr": 0.0007487777799263258, "train_min_lr": 0.0007487777799263258, "train_mlm_acc_1": 0.1688783227817443, "train_mlm_acc_2": 0.16814582356191982, "train_loss_1": 4.08988887753105, "train_loss_2": 4.096073088042025, "train_loss": 8.185961963056783, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0807513576279424, "epoch": 17, "n_parameters": 106143056}
{"train_lr": 0.0007484308644962306, "train_min_lr": 0.0007484308644962306, "train_mlm_acc_1": 0.16978636846640913, "train_mlm_acc_2": 0.1690143143533743, "train_loss_1": 4.079050821752641, "train_loss_2": 4.0856098311977, "train_loss": 8.164660653002763, "train_loss_scale": 15454.564643799473, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0258880280672509, "epoch": 18, "n_parameters": 106143056}
{"train_lr": 0.000748040712070646, "train_min_lr": 0.000748040712070646, "train_mlm_acc_1": 0.17053778617984386, "train_mlm_acc_2": 0.16971094610469323, "train_loss_1": 4.0693749640212316, "train_loss_2": 4.076291734934273, "train_loss": 8.145666698405066, "train_loss_scale": 18473.42832014072, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0239381927508686, "epoch": 19, "n_parameters": 106143056}
{"train_lr": 0.0007476073684356914, "train_min_lr": 0.0007476073684356914, "train_mlm_acc_1": 0.17153271765381806, "train_mlm_acc_2": 0.17065954316495904, "train_loss_1": 4.058840774661528, "train_loss_2": 4.066051478724576, "train_loss": 8.124892263110521, "train_loss_scale": 16960.394019349165, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 20, "n_parameters": 106143056}
{"train_lr": 0.0007471308844461622, "train_min_lr": 0.0007471308844461622, "train_mlm_acc_1": 0.172364104134518, "train_mlm_acc_2": 0.1714753893301507, "train_loss_1": 4.049080032209817, "train_loss_2": 4.056537132674178, "train_loss": 8.105617166246986, "train_loss_scale": 17781.755496921724, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 21, "n_parameters": 106143056}
{"train_lr": 0.00074661131601957, "train_min_lr": 0.00074661131601957, "train_mlm_acc_1": 0.17294727038123572, "train_mlm_acc_2": 0.172027978864265, "train_loss_1": 4.041934670852587, "train_loss_2": 4.04964960648915, "train_loss": 8.091584276031169, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9648324040959777, "epoch": 22, "n_parameters": 106143056}
{"train_lr": 0.0007460487241295682, "train_min_lr": 0.0007460487241295682, "train_mlm_acc_1": 0.17367426107949663, "train_mlm_acc_2": 0.17274695336523818, "train_loss_1": 4.033527387556741, "train_loss_2": 4.041403568016403, "train_loss": 8.07493095494407, "train_loss_scale": 16556.918205804748, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 23, "n_parameters": 106143056}
{"train_lr": 0.0007454431747988132, "train_min_lr": 0.0007454431747988132, "train_mlm_acc_1": 0.1742412342772661, "train_mlm_acc_2": 0.17331436163071698, "train_loss_1": 4.026645147784719, "train_loss_2": 4.03475108263046, "train_loss": 8.061396231175308, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.961536752412271, "epoch": 24, "n_parameters": 106143056}
{"train_lr": 0.0007447947390912042, "train_min_lr": 0.0007447947390912042, "train_mlm_acc_1": 0.17486215738633692, "train_mlm_acc_2": 0.17392858534743363, "train_loss_1": 4.019847865941342, "train_loss_2": 4.028078899403465, "train_loss": 8.04792675908029, "train_loss_scale": 26081.829375549692, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9479284449533716, "epoch": 25, "n_parameters": 106143056}
{"train_lr": 0.0007441034931035458, "train_min_lr": 0.0007441034931035458, "train_mlm_acc_1": 0.17538756013027965, "train_mlm_acc_2": 0.17438999461231258, "train_loss_1": 4.014079903942928, "train_loss_2": 4.022556496562933, "train_loss": 8.036636400034057, "train_loss_scale": 18300.51011433597, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 26, "n_parameters": 106143056}
{"train_lr": 0.0007433695179566179, "train_min_lr": 0.0007433695179566179, "train_mlm_acc_1": 0.17590352643376236, "train_mlm_acc_2": 0.17491844359198838, "train_loss_1": 4.007976927774038, "train_loss_2": 4.016486620289669, "train_loss": 8.024463552231314, "train_loss_scale": 18415.788918205806, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9469601526109398, "epoch": 27, "n_parameters": 106143056}
{"train_lr": 0.0007425928997856612, "train_min_lr": 0.0007425928997856612, "train_mlm_acc_1": 0.17618818680543646, "train_mlm_acc_2": 0.17520572656311795, "train_loss_1": 4.003709097074225, "train_loss_2": 4.0124720577986075, "train_loss": 8.01618115599992, "train_loss_scale": 24568.795074758134, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 28, "n_parameters": 106143056}
{"train_lr": 0.0007417737297302581, "train_min_lr": 0.0007417737297302581, "train_mlm_acc_1": 0.1767496972728976, "train_mlm_acc_2": 0.17572818588868452, "train_loss_1": 3.997828146084003, "train_loss_2": 4.006735617378457, "train_loss": 8.004563768862, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9118324530260964, "epoch": 29, "n_parameters": 106143056}
{"train_lr": 0.0007409121039236501, "train_min_lr": 0.0007409121039236501, "train_mlm_acc_1": 0.17705213106192302, "train_mlm_acc_2": 0.17607273988379862, "train_loss_1": 3.993739193693629, "train_loss_2": 4.002857977240989, "train_loss": 7.996597174132405, "train_loss_scale": 28531.50395778364, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9268437289520639, "epoch": 30, "n_parameters": 106143056}
{"train_lr": 0.000740008123481444, "train_min_lr": 0.000740008123481444, "train_mlm_acc_1": 0.17753737180828785, "train_mlm_acc_2": 0.17649231534434864, "train_loss_1": 3.9885596815650675, "train_loss_2": 3.997768935500894, "train_loss": 7.986328611115981, "train_loss_scale": 23055.76077396658, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 31, "n_parameters": 106143056}
{"train_lr": 0.0007390618944897517, "train_min_lr": 0.0007390618944897517, "train_mlm_acc_1": 0.17783194963501647, "train_mlm_acc_2": 0.17679121057775687, "train_loss_1": 3.9852277828133094, "train_loss_2": 3.994502240482295, "train_loss": 7.979730019468746, "train_loss_scale": 13429.980650835532, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 32, "n_parameters": 106143056}
{"train_lr": 0.0007380735279927422, "train_min_lr": 0.0007380735279927422, "train_mlm_acc_1": 0.17819037183909534, "train_mlm_acc_2": 0.17716274518444283, "train_loss_1": 3.980728107056496, "train_loss_2": 3.9901294554915467, "train_loss": 7.970857563884822, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9145334985241517, "epoch": 33, "n_parameters": 106143056}
{"train_lr": 0.0007370431399796046, "train_min_lr": 0.0007370431399796046, "train_mlm_acc_1": 0.1785695562851775, "train_mlm_acc_2": 0.17746168613866325, "train_loss_1": 3.9771189475489375, "train_loss_2": 3.9866386534041656, "train_loss": 7.963757594269205, "train_loss_scale": 13120.168865435357, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9245862786771963, "epoch": 34, "n_parameters": 106143056}
{"train_lr": 0.0007359708513709434, "train_min_lr": 0.0007359708513709434, "train_mlm_acc_1": 0.17889064527137194, "train_mlm_acc_2": 0.1778105918216464, "train_loss_1": 3.9736306388438956, "train_loss_2": 3.983284025414533, "train_loss": 7.956914660169455, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9253768415543314, "epoch": 35, "n_parameters": 106143056}
{"train_lr": 0.000734856788004579, "train_min_lr": 0.000734856788004579, "train_mlm_acc_1": 0.1791448206882416, "train_mlm_acc_2": 0.17809820676954724, "train_loss_1": 3.9702577230273994, "train_loss_2": 3.9799569832356014, "train_loss": 7.950214703615654, "train_loss_scale": 21139.25065963061, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 36, "n_parameters": 106143056}
{"train_lr": 0.0007337010806207864, "train_min_lr": 0.0007337010806207864, "train_mlm_acc_1": 0.17950184577740172, "train_mlm_acc_2": 0.17843286624127505, "train_loss_1": 3.966089026122735, "train_loss_2": 3.97605757757353, "train_loss": 7.942146605111678, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9217157451437562, "epoch": 37, "n_parameters": 106143056}
{"train_lr": 0.0007325038648469556, "train_min_lr": 0.0007325038648469556, "train_mlm_acc_1": 0.17971792064194314, "train_mlm_acc_2": 0.17860067114659905, "train_loss_1": 3.963628539440395, "train_loss_2": 3.9736380823998463, "train_loss": 7.9372666193501615, "train_loss_scale": 24107.679859278804, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 38, "n_parameters": 106143056}
{"train_lr": 0.000731265281181661, "train_min_lr": 0.000731265281181661, "train_mlm_acc_1": 0.18000126401373662, "train_mlm_acc_2": 0.17890081465532617, "train_loss_1": 3.9603624096698895, "train_loss_2": 3.9705445971683964, "train_loss": 7.930907006418904, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9104998042002622, "epoch": 39, "n_parameters": 106143056}
{"train_lr": 0.0007299854749781874, "train_min_lr": 0.0007299854749781874, "train_mlm_acc_1": 0.18016520966738855, "train_mlm_acc_2": 0.17907208955552667, "train_loss_1": 3.958227773428802, "train_loss_2": 3.9684025045802116, "train_loss": 7.926630276436332, "train_loss_scale": 18271.690413368513, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 40, "n_parameters": 106143056}
{"train_lr": 0.0007286645964274694, "train_min_lr": 0.0007286645964274694, "train_mlm_acc_1": 0.18040773848345276, "train_mlm_acc_2": 0.17928343474956698, "train_loss_1": 3.955142081806087, "train_loss_2": 3.965415211025832, "train_loss": 7.9205572951123075, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9095130126100941, "epoch": 41, "n_parameters": 106143056}
{"train_lr": 0.0007273028005404614, "train_min_lr": 0.0007273028005404614, "train_mlm_acc_1": 0.18077165763350098, "train_mlm_acc_2": 0.1796027600811098, "train_loss_1": 3.9521003306803206, "train_loss_2": 3.9623958179325833, "train_loss": 7.91449614622767, "train_loss_scale": 21686.82497801231, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 42, "n_parameters": 106143056}
{"train_lr": 0.0007259002471299484, "train_min_lr": 0.0007259002471299484, "train_mlm_acc_1": 0.18098928987252524, "train_mlm_acc_2": 0.17986522663283108, "train_loss_1": 3.9488847408781163, "train_loss_2": 3.9593351676522794, "train_loss": 7.908219902790107, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9190064834311225, "epoch": 43, "n_parameters": 106143056}
{"train_lr": 0.0007244571007917912, "train_min_lr": 0.0007244571007917912, "train_mlm_acc_1": 0.18120088697744496, "train_mlm_acc_2": 0.18004304057244366, "train_loss_1": 3.94674332805548, "train_loss_2": 3.9572392252053517, "train_loss": 7.90398254977472, "train_loss_scale": 22666.694810905894, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 44, "n_parameters": 106143056}
{"train_lr": 0.0007229735308856102, "train_min_lr": 0.0007229735308856102, "train_mlm_acc_1": 0.1814019942349814, "train_mlm_acc_2": 0.18022238919404954, "train_loss_1": 3.9450751403076354, "train_loss_2": 3.955678783940346, "train_loss": 7.900753925375071, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9344161640895283, "epoch": 45, "n_parameters": 106143056}
{"train_lr": 0.0007214497115149132, "train_min_lr": 0.0007214497115149132, "train_mlm_acc_1": 0.18160341056710863, "train_mlm_acc_2": 0.1804138766462434, "train_loss_1": 3.9420262349731794, "train_loss_2": 3.9528012624569073, "train_loss": 7.894827502646148, "train_loss_scale": 23185.449428320142, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 46, "n_parameters": 106143056}
{"train_lr": 0.0007198858215066601, "train_min_lr": 0.0007198858215066601, "train_mlm_acc_1": 0.18184259532243932, "train_mlm_acc_2": 0.18064900755672572, "train_loss_1": 3.9400388595296714, "train_loss_2": 3.9506628538499093, "train_loss": 7.890701713169889, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9153439546742771, "epoch": 47, "n_parameters": 106143056}
{"train_lr": 0.0007182820443902745, "train_min_lr": 0.0007182820443902745, "train_mlm_acc_1": 0.18192315974625822, "train_mlm_acc_2": 0.18074002736325892, "train_loss_1": 3.937959125116402, "train_loss_2": 3.9488202333450317, "train_loss": 7.8867793606894, "train_loss_scale": 21124.840809146877, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.925983405836654, "epoch": 48, "n_parameters": 106143056}
{"train_lr": 0.0007166385683761166, "train_min_lr": 0.0007166385683761166, "train_mlm_acc_1": 0.18218363359203543, "train_mlm_acc_2": 0.18099277131521554, "train_loss_1": 3.93534815198723, "train_loss_2": 3.9462047261214614, "train_loss": 7.881552874465312, "train_loss_scale": 11455.831134564643, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 49, "n_parameters": 106143056}
{"train_lr": 0.0007149555863333774, "train_min_lr": 0.0007149555863333774, "train_mlm_acc_1": 0.18233369960201448, "train_mlm_acc_2": 0.18110258379261432, "train_loss_1": 3.9336260304759234, "train_loss_2": 3.9446297875075564, "train_loss": 7.878255815336132, "train_loss_scale": 8199.204925241864, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9179222349441146, "epoch": 50, "n_parameters": 106143056}
{"train_lr": 0.0007132332957674665, "train_min_lr": 0.0007132332957674665, "train_mlm_acc_1": 0.1825331004341391, "train_mlm_acc_2": 0.1813429366705469, "train_loss_1": 3.931640745834394, "train_loss_2": 3.942698205550092, "train_loss": 7.874338950834048, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9139759942115978, "epoch": 51, "n_parameters": 106143056}
{"train_lr": 0.0007114718987968146, "train_min_lr": 0.0007114718987968146, "train_mlm_acc_1": 0.18275177487308977, "train_mlm_acc_2": 0.181538489595606, "train_loss_1": 3.929313625095178, "train_loss_2": 3.9404499539179874, "train_loss": 7.869763574164063, "train_loss_scale": 20015.282321899736, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 52, "n_parameters": 106143056}
{"train_lr": 0.0007096716021291684, "train_min_lr": 0.0007096716021291684, "train_mlm_acc_1": 0.1828994702845943, "train_mlm_acc_2": 0.18164196915321687, "train_loss_1": 3.927631146360513, "train_loss_2": 3.938757394921287, "train_loss": 7.866388543247652, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9061109401619843, "epoch": 53, "n_parameters": 106143056}
{"train_lr": 0.0007078326170373227, "train_min_lr": 0.0007078326170373227, "train_mlm_acc_1": 0.1830247542759438, "train_mlm_acc_2": 0.1817710552030393, "train_loss_1": 3.9260612395948344, "train_loss_2": 3.9372824035722536, "train_loss": 7.863343643219511, "train_loss_scale": 16888.34476693052, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 54, "n_parameters": 106143056}
{"train_lr": 0.000705955159334333, "train_min_lr": 0.000705955159334333, "train_mlm_acc_1": 0.18315602762161007, "train_mlm_acc_2": 0.18190498546539113, "train_loss_1": 3.9239847564917443, "train_loss_2": 3.9352317507212478, "train_loss": 7.859216507108147, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9323441374165611, "epoch": 55, "n_parameters": 106143056}
{"train_lr": 0.0007040394493481837, "train_min_lr": 0.0007040394493481837, "train_mlm_acc_1": 0.18347565064218188, "train_mlm_acc_2": 0.1822108203969509, "train_loss_1": 3.920744791954572, "train_loss_2": 3.932088185478536, "train_loss": 7.852832977302051, "train_loss_scale": 18322.124890061565, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 56, "n_parameters": 106143056}
{"train_lr": 0.0007020857118959358, "train_min_lr": 0.0007020857118959358, "train_mlm_acc_1": 0.18345644582216952, "train_mlm_acc_2": 0.1821887411206646, "train_loss_1": 3.9204978765158036, "train_loss_2": 3.9318813778322417, "train_loss": 7.852379254688793, "train_loss_scale": 4193.2664907651715, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 57, "n_parameters": 106143056}
{"train_lr": 0.0007000941762573423, "train_min_lr": 0.0007000941762573423, "train_mlm_acc_1": 0.18383922634307187, "train_mlm_acc_2": 0.18260165160602138, "train_loss_1": 3.9173747254445455, "train_loss_2": 3.9288122781086305, "train_loss": 7.846187003002737, "train_loss_scale": 4985.808267370273, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9162905024349847, "epoch": 58, "n_parameters": 106143056}
{"train_lr": 0.0006980650761479382, "train_min_lr": 0.0006980650761479382, "train_mlm_acc_1": 0.18383472568782255, "train_mlm_acc_2": 0.18257472811720565, "train_loss_1": 3.9167030539131, "train_loss_2": 3.9282110747058034, "train_loss": 7.844914131869112, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9384979966343131, "epoch": 59, "n_parameters": 106143056}
{"train_lr": 0.0006959986496916213, "train_min_lr": 0.0006959986496916213, "train_mlm_acc_1": 0.1840388332374833, "train_mlm_acc_2": 0.18273877688145418, "train_loss_1": 3.914518288933822, "train_loss_2": 3.926125930371574, "train_loss": 7.840644218099673, "train_loss_scale": 11945.766051011433, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9281916019155356, "epoch": 60, "n_parameters": 106143056}
{"train_lr": 0.0006938951393926957, "train_min_lr": 0.0006938951393926957, "train_mlm_acc_1": 0.18410113178809537, "train_mlm_acc_2": 0.18284008067949833, "train_loss_1": 3.9140836822693035, "train_loss_2": 3.925680537389472, "train_loss": 7.839764220366482, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9435607612447563, "epoch": 61, "n_parameters": 106143056}
{"train_lr": 0.0006917547921074234, "train_min_lr": 0.0006917547921074234, "train_mlm_acc_1": 0.18427206314903607, "train_mlm_acc_2": 0.18301698988960463, "train_loss_1": 3.911570328940607, "train_loss_2": 3.9233869153255942, "train_loss": 7.834957241959601, "train_loss_scale": 16470.459102902376, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 62, "n_parameters": 106143056}
{"train_lr": 0.0006895778590150455, "train_min_lr": 0.0006895778590150455, "train_mlm_acc_1": 0.18443250445945544, "train_mlm_acc_2": 0.18315220268880628, "train_loss_1": 3.910062672306596, "train_loss_2": 3.9216581532173023, "train_loss": 7.831720820307837, "train_loss_scale": 11981.790677220757, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 63, "n_parameters": 106143056}
{"train_lr": 0.0006873645955883147, "train_min_lr": 0.0006873645955883147, "train_mlm_acc_1": 0.18462873317740314, "train_mlm_acc_2": 0.18331729360547314, "train_loss_1": 3.908233855230932, "train_loss_2": 3.9200289601438802, "train_loss": 7.828262814850585, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9411690617299646, "epoch": 64, "n_parameters": 106143056}
{"train_lr": 0.0006851152615635071, "train_min_lr": 0.0006851152615635071, "train_mlm_acc_1": 0.1847899418517541, "train_mlm_acc_2": 0.1835378232029518, "train_loss_1": 3.9065176560465664, "train_loss_2": 3.918358715118393, "train_loss": 7.824876367678848, "train_loss_scale": 14568.358839050132, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9658174666272199, "epoch": 65, "n_parameters": 106143056}
{"train_lr": 0.0006828301209099406, "train_min_lr": 0.0006828301209099406, "train_mlm_acc_1": 0.1849060642943376, "train_mlm_acc_2": 0.18358752457793595, "train_loss_1": 3.9053175506512114, "train_loss_2": 3.917177079299509, "train_loss": 7.822494631182654, "train_loss_scale": 16701.01671064204, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9677640160868434, "epoch": 66, "n_parameters": 106143056}
{"train_lr": 0.0006805094417990081, "train_min_lr": 0.0006805094417990081, "train_mlm_acc_1": 0.18510288838379038, "train_mlm_acc_2": 0.18378718879496517, "train_loss_1": 3.9028499520129034, "train_loss_2": 3.9148160358374855, "train_loss": 7.817665987247527, "train_loss_scale": 17580.017590149517, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 67, "n_parameters": 106143056}
{"train_lr": 0.0006781534965726882, "train_min_lr": 0.0006781534965726882, "train_mlm_acc_1": 0.18515796074111313, "train_mlm_acc_2": 0.18380747012721937, "train_loss_1": 3.902304059806998, "train_loss_2": 3.9142523325370298, "train_loss": 7.81655639583014, "train_loss_scale": 10511.985927880387, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 68, "n_parameters": 106143056}
{"train_lr": 0.0006757625617116008, "train_min_lr": 0.0006757625617116008, "train_mlm_acc_1": 0.18531072946067118, "train_mlm_acc_2": 0.18398562760609175, "train_loss_1": 3.8998688396226973, "train_loss_2": 3.911883663140375, "train_loss": 7.811752500980699, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9582626011776316, "epoch": 69, "n_parameters": 106143056}
{"train_lr": 0.0006733369178025507, "train_min_lr": 0.0006733369178025507, "train_mlm_acc_1": 0.18557313868486, "train_mlm_acc_2": 0.18419538101012653, "train_loss_1": 3.898716686373755, "train_loss_2": 3.910812993529814, "train_loss": 7.8095296828916645, "train_loss_scale": 16038.163588390502, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.961950059668894, "epoch": 70, "n_parameters": 106143056}
{"train_lr": 0.000670876849505609, "train_min_lr": 0.000670876849505609, "train_mlm_acc_1": 0.18559175948452666, "train_mlm_acc_2": 0.18425541199258838, "train_loss_1": 3.8971254975258938, "train_loss_2": 3.9092612652109713, "train_loss": 7.806386763837742, "train_loss_scale": 18977.77308707124, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 71, "n_parameters": 106143056}
{"train_lr": 0.000668382645520696, "train_min_lr": 0.000668382645520696, "train_mlm_acc_1": 0.18564858392745964, "train_mlm_acc_2": 0.18428980212629156, "train_loss_1": 3.8962326586351335, "train_loss_2": 3.9084779524761224, "train_loss": 7.804710610718085, "train_loss_scale": 12428.496042216359, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 72, "n_parameters": 106143056}
{"train_lr": 0.0006658545985537059, "train_min_lr": 0.0006658545985537059, "train_mlm_acc_1": 0.18573221725656625, "train_mlm_acc_2": 0.18442072045048183, "train_loss_1": 3.895233827063989, "train_loss_2": 3.9074857086074277, "train_loss": 7.8027195380042285, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0004428651842405, "epoch": 73, "n_parameters": 106143056}
{"train_lr": 0.0006632930052821623, "train_min_lr": 0.0006632930052821623, "train_mlm_acc_1": 0.18586828901040103, "train_mlm_acc_2": 0.18451442010700703, "train_loss_1": 3.8933870041695413, "train_loss_2": 3.905735956857156, "train_loss": 7.799122961813039, "train_loss_scale": 14121.65347405453, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9618608333504609, "epoch": 74, "n_parameters": 106143056}
{"train_lr": 0.0006606981663203897, "train_min_lr": 0.0006606981663203897, "train_mlm_acc_1": 0.18611557026317535, "train_mlm_acc_2": 0.1847363697527109, "train_loss_1": 3.8920847191135404, "train_loss_2": 3.9043701046532253, "train_loss": 7.796454821853335, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9538748390651525, "epoch": 75, "n_parameters": 106143056}
{"train_lr": 0.0006580703861842497, "train_min_lr": 0.0006580703861842497, "train_mlm_acc_1": 0.18633351191426173, "train_mlm_acc_2": 0.184947726386374, "train_loss_1": 3.89049002132399, "train_loss_2": 3.902865770283559, "train_loss": 7.7933557912668014, "train_loss_scale": 17118.902374670186, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 76, "n_parameters": 106143056}
{"train_lr": 0.0006554099732553881, "train_min_lr": 0.0006554099732553881, "train_mlm_acc_1": 0.1862917581037434, "train_mlm_acc_2": 0.18497525678952484, "train_loss_1": 3.8892003642747355, "train_loss_2": 3.901571075488521, "train_loss": 7.790771442961042, "train_loss_scale": 18012.31310466139, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 77, "n_parameters": 106143056}
{"train_lr": 0.0006527172397450622, "train_min_lr": 0.0006527172397450622, "train_mlm_acc_1": 0.18652423212866617, "train_mlm_acc_2": 0.18513637394034085, "train_loss_1": 3.8875392673564986, "train_loss_2": 3.9000101103369564, "train_loss": 7.787549379947632, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9806780128910967, "epoch": 78, "n_parameters": 106143056}
{"train_lr": 0.0006499925016574828, "train_min_lr": 0.0006499925016574828, "train_mlm_acc_1": 0.1865111196326811, "train_mlm_acc_2": 0.18509254740713296, "train_loss_1": 3.8869301582127154, "train_loss_2": 3.8995026273484177, "train_loss": 7.786432784643735, "train_loss_scale": 18055.54265611258, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 79, "n_parameters": 106143056}
{"train_lr": 0.0006472360787527486, "train_min_lr": 0.0006472360787527486, "train_mlm_acc_1": 0.1868060753535784, "train_mlm_acc_2": 0.18545039701738322, "train_loss_1": 3.884711400106903, "train_loss_2": 3.8971578012250867, "train_loss": 7.781869199733097, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9760116168355983, "epoch": 80, "n_parameters": 106143056}
{"train_lr": 0.000644448294509309, "train_min_lr": 0.000644448294509309, "train_mlm_acc_1": 0.18678770647789683, "train_mlm_acc_2": 0.18544843871057978, "train_loss_1": 3.8836629177356037, "train_loss_2": 3.8961833399854005, "train_loss": 7.779846256829818, "train_loss_scale": 19323.60949868074, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 81, "n_parameters": 106143056}
{"train_lr": 0.0006416294760860044, "train_min_lr": 0.0006416294760860044, "train_mlm_acc_1": 0.18709801915597266, "train_mlm_acc_2": 0.18565642854514988, "train_loss_1": 3.8819329934677955, "train_loss_2": 3.89459748889861, "train_loss": 7.776530481422797, "train_loss_scale": 11798.06508355321, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 82, "n_parameters": 106143056}
{"train_lr": 0.0006387799542836763, "train_min_lr": 0.0006387799542836763, "train_mlm_acc_1": 0.1870895676534351, "train_mlm_acc_2": 0.1857247849944373, "train_loss_1": 3.880417275869123, "train_loss_2": 3.893028284492677, "train_loss": 7.773445563297473, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9863012849812772, "epoch": 83, "n_parameters": 106143056}
{"train_lr": 0.0006359000635063394, "train_min_lr": 0.0006359000635063394, "train_mlm_acc_1": 0.18725792233887062, "train_mlm_acc_2": 0.1859212770530579, "train_loss_1": 3.8786002078544914, "train_loss_2": 3.8912775293713406, "train_loss": 7.769877736675394, "train_loss_scale": 6153.006156552331, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9635268198678445, "epoch": 84, "n_parameters": 106143056}
{"train_lr": 0.0006329901417219492, "train_min_lr": 0.0006329901417219492, "train_mlm_acc_1": 0.18732689728627838, "train_mlm_acc_2": 0.18595054816117176, "train_loss_1": 3.8786640123987577, "train_loss_2": 3.891335371380431, "train_loss": 7.7699993830976934, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9981362388756785, "epoch": 85, "n_parameters": 106143056}
{"train_lr": 0.0006300505304227264, "train_min_lr": 0.0006300505304227264, "train_mlm_acc_1": 0.18743570197599702, "train_mlm_acc_2": 0.18604918365369214, "train_loss_1": 3.877090266087439, "train_loss_2": 3.8898114498340988, "train_loss": 7.766901714348856, "train_loss_scale": 14280.16182937555, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9839764790987906, "epoch": 86, "n_parameters": 106143056}
{"train_lr": 0.0006270815745850904, "train_min_lr": 0.0006270815745850904, "train_mlm_acc_1": 0.1876325490347969, "train_mlm_acc_2": 0.18624514882291424, "train_loss_1": 3.8751518692536218, "train_loss_2": 3.887991137507723, "train_loss": 7.763143007757376, "train_loss_scale": 11816.07739665787, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 87, "n_parameters": 106143056}
{"train_lr": 0.0006240836226291734, "train_min_lr": 0.0006240836226291734, "train_mlm_acc_1": 0.18765546429309282, "train_mlm_acc_2": 0.18628047811639026, "train_loss_1": 3.874363587551612, "train_loss_2": 3.887183191043406, "train_loss": 7.761546775030272, "train_loss_scale": 4186.061565523307, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 88, "n_parameters": 106143056}
{"train_lr": 0.0006210570263779273, "train_min_lr": 0.0006210570263779273, "train_mlm_acc_1": 0.18801219172434996, "train_mlm_acc_2": 0.1865646001033439, "train_loss_1": 3.8717999324897137, "train_loss_2": 3.884701482093219, "train_loss": 7.7565014147402005, "train_loss_scale": 4993.013192612138, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0097176843079538, "epoch": 89, "n_parameters": 106143056}
{"train_lr": 0.0006180021410158472, "train_min_lr": 0.0006180021410158472, "train_mlm_acc_1": 0.1879523324607335, "train_mlm_acc_2": 0.18660434981907997, "train_loss_1": 3.8712095756906106, "train_loss_2": 3.8840959044066876, "train_loss": 7.7553054808836395, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.023858269317798, "epoch": 90, "n_parameters": 106143056}
{"train_lr": 0.0006149193250472682, "train_min_lr": 0.0006149193250472682, "train_mlm_acc_1": 0.18806327865831718, "train_mlm_acc_2": 0.18662078321314268, "train_loss_1": 3.870155280372398, "train_loss_2": 3.8830126053215435, "train_loss": 7.75316788642786, "train_loss_scale": 11960.175901495162, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0309132725498398, "epoch": 91, "n_parameters": 106143056}
{"train_lr": 0.0006118089402543174, "train_min_lr": 0.0006118089402543174, "train_mlm_acc_1": 0.18819064702166993, "train_mlm_acc_2": 0.18678834771437663, "train_loss_1": 3.869206123584808, "train_loss_2": 3.8821569952455235, "train_loss": 7.751363119066234, "train_loss_scale": 11232.478452066842, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 92, "n_parameters": 106143056}
{"train_lr": 0.0006086713516544388, "train_min_lr": 0.0006086713516544388, "train_mlm_acc_1": 0.18839044861574128, "train_mlm_acc_2": 0.18696836048119564, "train_loss_1": 3.8676377744557255, "train_loss_2": 3.8806173445996004, "train_loss": 7.748255118111717, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0438734959276916, "epoch": 93, "n_parameters": 106143056}
{"train_lr": 0.000605506927457566, "train_min_lr": 0.000605506927457566, "train_mlm_acc_1": 0.18861752873484827, "train_mlm_acc_2": 0.18715105312094157, "train_loss_1": 3.8658393546480196, "train_loss_2": 3.8788681620815497, "train_loss": 7.744707516808203, "train_loss_scale": 15317.671064204045, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9964433157769021, "epoch": 94, "n_parameters": 106143056}
{"train_lr": 0.0006023160390229106, "train_min_lr": 0.0006023160390229106, "train_mlm_acc_1": 0.18864519656418757, "train_mlm_acc_2": 0.1872378814549381, "train_loss_1": 3.86471586711803, "train_loss_2": 3.8777075668333283, "train_loss": 7.742423435733731, "train_loss_scale": 17724.116094986806, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 95, "n_parameters": 106143056}
{"train_lr": 0.0005990990608153761, "train_min_lr": 0.0005990990608153761, "train_mlm_acc_1": 0.18863847430569358, "train_mlm_acc_2": 0.18722042877132053, "train_loss_1": 3.863668153132906, "train_loss_2": 3.8767331164713585, "train_loss": 7.740401270521662, "train_loss_scale": 14438.67018469657, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 96, "n_parameters": 106143056}
{"train_lr": 0.000595856370361619, "train_min_lr": 0.000595856370361619, "train_mlm_acc_1": 0.1887718432762299, "train_mlm_acc_2": 0.1873268971912622, "train_loss_1": 3.8628432808891136, "train_loss_2": 3.875960818302663, "train_loss": 7.738804098693761, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0441027071880686, "epoch": 97, "n_parameters": 106143056}
{"train_lr": 0.0005925883482057425, "train_min_lr": 0.0005925883482057425, "train_mlm_acc_1": 0.18898830755647328, "train_mlm_acc_2": 0.1875836951240386, "train_loss_1": 3.8606974729971606, "train_loss_2": 3.8738296574265054, "train_loss": 7.7345271305023, "train_loss_scale": 12111.479331574319, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0096678267263381, "epoch": 98, "n_parameters": 106143056}
{"train_lr": 0.0005892953778646349, "train_min_lr": 0.0005892953778646349, "train_mlm_acc_1": 0.18905484319886515, "train_mlm_acc_2": 0.18765431911526487, "train_loss_1": 3.8599253627901655, "train_loss_2": 3.8730350664653796, "train_loss": 7.732960427499384, "train_loss_scale": 8199.204925241864, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 99, "n_parameters": 106143056}
{"train_lr": 0.0005859778457829658, "train_min_lr": 0.0005859778457829658, "train_mlm_acc_1": 0.18909970042029545, "train_mlm_acc_2": 0.1876854683791034, "train_loss_1": 3.859428938350451, "train_loss_2": 3.8725929009149027, "train_loss": 7.732021837037387, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0427593682665728, "epoch": 100, "n_parameters": 106143056}
{"train_lr": 0.0005826361412878357, "train_min_lr": 0.0005826361412878357, "train_mlm_acc_1": 0.18933280420439644, "train_mlm_acc_2": 0.18787161932673335, "train_loss_1": 3.8569262615661404, "train_loss_2": 3.8700853148204986, "train_loss": 7.727011575285761, "train_loss_scale": 5378.476693051891, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0402259661528555, "epoch": 101, "n_parameters": 106143056}
{"train_lr": 0.0005792706565430835, "train_min_lr": 0.0005792706565430835, "train_mlm_acc_1": 0.18951333231942216, "train_mlm_acc_2": 0.1881025702223221, "train_loss_1": 3.8554747496242574, "train_loss_2": 3.8686345164568254, "train_loss": 7.724109268020724, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0396272554246606, "epoch": 102, "n_parameters": 106143056}
{"train_lr": 0.0005758817865032646, "train_min_lr": 0.0005758817865032646, "train_mlm_acc_1": 0.18956642347431382, "train_mlm_acc_2": 0.188121431552221, "train_loss_1": 3.854303919991172, "train_loss_2": 3.867555945037013, "train_loss": 7.721859863848674, "train_loss_scale": 12731.10290237467, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0469794758286723, "epoch": 103, "n_parameters": 106143056}
{"train_lr": 0.0005724699288673034, "train_min_lr": 0.0005724699288673034, "train_mlm_acc_1": 0.18966154299394647, "train_mlm_acc_2": 0.1881837299832437, "train_loss_1": 3.8536825562215418, "train_loss_2": 3.8670032093843663, "train_loss": 7.720685768305679, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0584532214867617, "epoch": 104, "n_parameters": 106143056}
{"train_lr": 0.0005690354840318202, "train_min_lr": 0.0005690354840318202, "train_mlm_acc_1": 0.18975927375204593, "train_mlm_acc_2": 0.18832190878846558, "train_loss_1": 3.8523173013484153, "train_loss_2": 3.865610264955955, "train_loss": 7.7179275679818975, "train_loss_scale": 18127.591908531223, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 105, "n_parameters": 106143056}
{"train_lr": 0.0005655788550441483, "train_min_lr": 0.0005655788550441483, "train_mlm_acc_1": 0.18999632846534567, "train_mlm_acc_2": 0.18852460791464165, "train_loss_1": 3.850146482126065, "train_loss_2": 3.863661661731012, "train_loss": 7.713808148286797, "train_loss_scale": 10403.912049252418, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 106, "n_parameters": 106143056}
{"train_lr": 0.0005621004475550199, "train_min_lr": 0.0005621004475550199, "train_mlm_acc_1": 0.19006673487766645, "train_mlm_acc_2": 0.18855834514780745, "train_loss_1": 3.849292648289428, "train_loss_2": 3.862756599170027, "train_loss": 7.712049246568268, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0819911774880233, "epoch": 107, "n_parameters": 106143056}
{"train_lr": 0.0005586006697709787, "train_min_lr": 0.0005586006697709787, "train_mlm_acc_1": 0.1900498203559727, "train_mlm_acc_2": 0.18856577747382663, "train_loss_1": 3.849523464497916, "train_loss_2": 3.862927973899489, "train_loss": 7.712451436536398, "train_loss_scale": 16146.237467018469, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0834581363379379, "epoch": 108, "n_parameters": 106143056}
{"train_lr": 0.0005550799324064666, "train_min_lr": 0.0005550799324064666, "train_mlm_acc_1": 0.19034626488242112, "train_mlm_acc_2": 0.18885200674970787, "train_loss_1": 3.846795995060351, "train_loss_2": 3.8603943174306825, "train_loss": 7.707190315767455, "train_loss_scale": 15728.351802990326, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 109, "n_parameters": 106143056}
{"train_lr": 0.0005515386486356223, "train_min_lr": 0.0005515386486356223, "train_mlm_acc_1": 0.19048606987187447, "train_mlm_acc_2": 0.18899916398126826, "train_loss_1": 3.845132639403918, "train_loss_2": 3.8585789670992443, "train_loss": 7.703711606372106, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0845782744223964, "epoch": 110, "n_parameters": 106143056}
{"train_lr": 0.0005479772340437942, "train_min_lr": 0.0005479772340437942, "train_mlm_acc_1": 0.19042918819314886, "train_mlm_acc_2": 0.1889810127287238, "train_loss_1": 3.844675783693738, "train_loss_2": 3.858208870195776, "train_loss": 7.70288465514766, "train_loss_scale": 11210.863676341249, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0508097791315278, "epoch": 111, "n_parameters": 106143056}
{"train_lr": 0.0005443961065787804, "train_min_lr": 0.0005443961065787804, "train_mlm_acc_1": 0.1906566805973741, "train_mlm_acc_2": 0.18921538770015342, "train_loss_1": 3.8428655264402756, "train_loss_2": 3.8564435511748836, "train_loss": 7.699309075832787, "train_loss_scale": 8977.336851363236, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 112, "n_parameters": 106143056}
{"train_lr": 0.0005407956865017628, "train_min_lr": 0.0005407956865017628, "train_mlm_acc_1": 0.19087992439156262, "train_mlm_acc_2": 0.1894009202020857, "train_loss_1": 3.840730469978579, "train_loss_2": 3.8542381069486145, "train_loss": 7.694968573074123, "train_loss_scale": 9380.812664907651, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0537084169626865, "epoch": 113, "n_parameters": 106143056}
{"train_lr": 0.0005371763963380031, "train_min_lr": 0.0005371763963380031, "train_mlm_acc_1": 0.19087227450793473, "train_mlm_acc_2": 0.18931748151857808, "train_loss_1": 3.840651674656461, "train_loss_2": 3.854262333956327, "train_loss": 7.694914010028202, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0930504641620968, "epoch": 114, "n_parameters": 106143056}
{"train_lr": 0.0005335386608272497, "train_min_lr": 0.0005335386608272497, "train_mlm_acc_1": 0.19102950933124796, "train_mlm_acc_2": 0.18954111467276943, "train_loss_1": 3.8388258190194873, "train_loss_2": 3.85248341307162, "train_loss": 7.69130922926028, "train_loss_scale": 8883.672823218998, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 115, "n_parameters": 106143056}
{"train_lr": 0.0005298829068738921, "train_min_lr": 0.0005298829068738921, "train_mlm_acc_1": 0.19122358500832984, "train_mlm_acc_2": 0.18971311105882116, "train_loss_1": 3.837143326130685, "train_loss_2": 3.850670429076033, "train_loss": 7.687813754394165, "train_loss_scale": 9474.47669305189, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1071848075643589, "epoch": 116, "n_parameters": 106143056}
{"train_lr": 0.0005262095634968652, "train_min_lr": 0.0005262095634968652, "train_mlm_acc_1": 0.1912513674206527, "train_mlm_acc_2": 0.1897160198536219, "train_loss_1": 3.836855182651899, "train_loss_2": 3.8506070807930035, "train_loss": 7.687462267114493, "train_loss_scale": 13329.111697449429, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 117, "n_parameters": 106143056}
{"train_lr": 0.0005225190617793022, "train_min_lr": 0.0005225190617793022, "train_mlm_acc_1": 0.19150058412555812, "train_mlm_acc_2": 0.18995607496716782, "train_loss_1": 3.8349824726791266, "train_loss_2": 3.8487584741102987, "train_loss": 7.683740945583702, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.109896867602356, "epoch": 118, "n_parameters": 106143056}
{"train_lr": 0.0005188118348179412, "train_min_lr": 0.0005188118348179412, "train_mlm_acc_1": 0.19162327997065368, "train_mlm_acc_2": 0.1900862146876654, "train_loss_1": 3.833126255133326, "train_loss_2": 3.8468446468929502, "train_loss": 7.679970900584651, "train_loss_scale": 11952.970976253298, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 119, "n_parameters": 106143056}
{"train_lr": 0.0005150883176723058, "train_min_lr": 0.0005150883176723058, "train_mlm_acc_1": 0.19166275471442346, "train_mlm_acc_2": 0.1901476083662469, "train_loss_1": 3.832329115588726, "train_loss_2": 3.846097569640729, "train_loss": 7.678426684259635, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.074509876803966, "epoch": 120, "n_parameters": 106143056}
{"train_lr": 0.0005113489473136387, "train_min_lr": 0.0005113489473136387, "train_mlm_acc_1": 0.19181489353064077, "train_mlm_acc_2": 0.19026615857429272, "train_loss_1": 3.8306466015211407, "train_loss_2": 3.8443963473421916, "train_loss": 7.675042948863332, "train_loss_scale": 9604.165347405453, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 121, "n_parameters": 106143056}
{"train_lr": 0.0005075941625736347, "train_min_lr": 0.0005075941625736347, "train_mlm_acc_1": 0.19183408686024586, "train_mlm_acc_2": 0.1903361870875302, "train_loss_1": 3.8302330969715705, "train_loss_2": 3.843980100192621, "train_loss": 7.67421320020471, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1239557741709518, "epoch": 122, "n_parameters": 106143056}
{"train_lr": 0.0005038244040929274, "train_min_lr": 0.0005038244040929274, "train_mlm_acc_1": 0.1921150368771851, "train_mlm_acc_2": 0.1906491452885387, "train_loss_1": 3.8282754361996445, "train_loss_2": 3.841983310963464, "train_loss": 7.670258747451434, "train_loss_scale": 9107.025505716798, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 123, "n_parameters": 106143056}
{"train_lr": 0.0005000401142693911, "train_min_lr": 0.0005000401142693911, "train_mlm_acc_1": 0.19214788092367463, "train_mlm_acc_2": 0.19065167614166267, "train_loss_1": 3.8271442137743783, "train_loss_2": 3.8409035617097387, "train_loss": 7.66804777841979, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1025184157551016, "epoch": 124, "n_parameters": 106143056}
{"train_lr": 0.0004962417372062153, "train_min_lr": 0.0004962417372062153, "train_mlm_acc_1": 0.19227231760479005, "train_mlm_acc_2": 0.1907503114834677, "train_loss_1": 3.825810775802968, "train_loss_2": 3.839741602422065, "train_loss": 7.665552376914465, "train_loss_scale": 10425.526824978013, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 125, "n_parameters": 106143056}
{"train_lr": 0.0004924297186597878, "train_min_lr": 0.0004924297186597878, "train_mlm_acc_1": 0.19250061160171356, "train_mlm_acc_2": 0.19097744884492016, "train_loss_1": 3.823550556533255, "train_loss_2": 3.8374658773735937, "train_loss": 7.661016437759919, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1301150173079895, "epoch": 126, "n_parameters": 106143056}
{"train_lr": 0.0004886045059873886, "train_min_lr": 0.0004886045059873886, "train_mlm_acc_1": 0.19261358473073156, "train_mlm_acc_2": 0.1910780654448554, "train_loss_1": 3.822030960648544, "train_loss_2": 3.835985851712466, "train_loss": 7.658016810683483, "train_loss_scale": 12795.947229551452, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1372356528552248, "epoch": 127, "n_parameters": 106143056}
{"train_lr": 0.00048476654809468197, "train_min_lr": 0.00048476654809468197, "train_mlm_acc_1": 0.19273189456089873, "train_mlm_acc_2": 0.19122672297565058, "train_loss_1": 3.8214682196983665, "train_loss_2": 3.8354006678049464, "train_loss": 7.656868888342077, "train_loss_scale": 8952.11961301671, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 128, "n_parameters": 106143056}
{"train_lr": 0.0004809162953830467, "train_min_lr": 0.0004809162953830467, "train_mlm_acc_1": 0.1927930135427333, "train_mlm_acc_2": 0.19124501162981034, "train_loss_1": 3.8203516258360946, "train_loss_2": 3.834278923514231, "train_loss": 7.654630549612439, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.103197312711516, "epoch": 129, "n_parameters": 106143056}
{"train_lr": 0.0004770541996967091, "train_min_lr": 0.0004770541996967091, "train_mlm_acc_1": 0.19306351931515028, "train_mlm_acc_2": 0.19156599740383912, "train_loss_1": 3.818503699731491, "train_loss_2": 3.832456400128132, "train_loss": 7.65096010324089, "train_loss_scale": 5187.546174142481, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1335552368860236, "epoch": 130, "n_parameters": 106143056}
{"train_lr": 0.00047318071426971875, "train_min_lr": 0.00047318071426971875, "train_mlm_acc_1": 0.1929669223476788, "train_mlm_acc_2": 0.1915472277940604, "train_loss_1": 3.8182819170603755, "train_loss_2": 3.832181945954275, "train_loss": 7.650463862490423, "train_loss_scale": 6034.124890061566, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 131, "n_parameters": 106143056}
{"train_lr": 0.00046929629367276803, "train_min_lr": 0.00046929629367276803, "train_mlm_acc_1": 0.19322673203677543, "train_mlm_acc_2": 0.19170962744240921, "train_loss_1": 3.81684216406121, "train_loss_2": 3.8308568268149386, "train_loss": 7.647698992003237, "train_loss_scale": 2543.338610378188, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 132, "n_parameters": 106143056}
{"train_lr": 0.00046540139375983523, "train_min_lr": 0.00046540139375983523, "train_mlm_acc_1": 0.19328478182499725, "train_mlm_acc_2": 0.1917428378975748, "train_loss_1": 3.815117035241324, "train_loss_2": 3.829117767414506, "train_loss": 7.644234804490625, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1428490829446805, "epoch": 133, "n_parameters": 106143056}
{"train_lr": 0.00046149647161469406, "train_min_lr": 0.00046149647161469406, "train_mlm_acc_1": 0.1934996084650043, "train_mlm_acc_2": 0.19195065600183206, "train_loss_1": 3.81328292381061, "train_loss_2": 3.8273377460456253, "train_loss": 7.640620668676724, "train_loss_scale": 4094.198768689534, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1601536062692694, "epoch": 134, "n_parameters": 106143056}
{"train_lr": 0.000457581985497272, "train_min_lr": 0.000457581985497272, "train_mlm_acc_1": 0.19359953787502165, "train_mlm_acc_2": 0.19205781157073631, "train_loss_1": 3.812066345830287, "train_loss_2": 3.8261703416351276, "train_loss": 7.638236688435235, "train_loss_scale": 4625.562005277045, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 135, "n_parameters": 106143056}
{"train_lr": 0.00045365839478986964, "train_min_lr": 0.00045365839478986964, "train_mlm_acc_1": 0.19373697232825252, "train_mlm_acc_2": 0.19219047066377987, "train_loss_1": 3.8104775673271587, "train_loss_2": 3.824552800457207, "train_loss": 7.635030366866968, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1848763724954483, "epoch": 136, "n_parameters": 106143056}
{"train_lr": 0.00044972615994325554, "train_min_lr": 0.00044972615994325554, "train_mlm_acc_1": 0.19394743578343038, "train_mlm_acc_2": 0.19237853407125885, "train_loss_1": 3.8090953112382477, "train_loss_2": 3.8231517888520408, "train_loss": 7.632247097993379, "train_loss_scale": 5536.9850483729115, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1787764892414565, "epoch": 137, "n_parameters": 106143056}
{"train_lr": 0.00044578574242262216, "train_min_lr": 0.00044578574242262216, "train_mlm_acc_1": 0.19399301445467124, "train_mlm_acc_2": 0.1924604268379267, "train_loss_1": 3.8088254308427962, "train_loss_2": 3.8228118532880315, "train_loss": 7.631637284392942, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.178824722609608, "epoch": 138, "n_parameters": 106143056}
{"train_lr": 0.0004418376046534354, "train_min_lr": 0.0004418376046534354, "train_mlm_acc_1": 0.19427305969623432, "train_mlm_acc_2": 0.19268097935396794, "train_loss_1": 3.805926354049902, "train_loss_2": 3.8200683606331456, "train_loss": 7.625994716963437, "train_loss_scale": 13048.11961301671, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.196124556196711, "epoch": 139, "n_parameters": 106143056}
{"train_lr": 0.00043788220996717, "train_min_lr": 0.00043788220996717, "train_mlm_acc_1": 0.19428319456801146, "train_mlm_acc_2": 0.19276655958465766, "train_loss_1": 3.805026542962174, "train_loss_2": 3.8191164092422056, "train_loss": 7.62414295566428, "train_loss_scale": 10122.9199648197, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 140, "n_parameters": 106143056}
{"train_lr": 0.0004339200225469267, "train_min_lr": 0.0004339200225469267, "train_mlm_acc_1": 0.19444584624519082, "train_mlm_acc_2": 0.192898840701622, "train_loss_1": 3.804000041808805, "train_loss_2": 3.818102615987825, "train_loss": 7.622102657586939, "train_loss_scale": 8235.229551451188, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1857753821706813, "epoch": 141, "n_parameters": 106143056}
{"train_lr": 0.0004299515073729694, "train_min_lr": 0.0004299515073729694, "train_mlm_acc_1": 0.1945779441709228, "train_mlm_acc_2": 0.19301925765198108, "train_loss_1": 3.802447714140883, "train_loss_2": 3.816535280609508, "train_loss": 7.618982995562943, "train_loss_scale": 10036.460861917327, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 142, "n_parameters": 106143056}
{"train_lr": 0.0004259771301681481, "train_min_lr": 0.0004259771301681481, "train_mlm_acc_1": 0.19476723288928824, "train_mlm_acc_2": 0.19319770139172712, "train_loss_1": 3.801173070935482, "train_loss_2": 3.8152524209012038, "train_loss": 7.616425493304522, "train_loss_scale": 8321.688654353562, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2045214937356028, "epoch": 143, "n_parameters": 106143056}
{"train_lr": 0.00042199735734324876, "train_min_lr": 0.00042199735734324876, "train_mlm_acc_1": 0.19481946505678255, "train_mlm_acc_2": 0.19331148773982218, "train_loss_1": 3.799597241764228, "train_loss_2": 3.813714890938216, "train_loss": 7.613312134013013, "train_loss_scale": 8472.992084432717, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 144, "n_parameters": 106143056}
{"train_lr": 0.0004180126559422584, "train_min_lr": 0.0004180126559422584, "train_mlm_acc_1": 0.19513159871376598, "train_mlm_acc_2": 0.19360291617271297, "train_loss_1": 3.796942322266762, "train_loss_2": 3.811136794567318, "train_loss": 7.608079118432974, "train_loss_scale": 8570.25857519789, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 145, "n_parameters": 106143056}
{"train_lr": 0.00041402349358755474, "train_min_lr": 0.00041402349358755474, "train_mlm_acc_1": 0.1951346677173463, "train_mlm_acc_2": 0.19355619233019697, "train_loss_1": 3.796766225821949, "train_loss_2": 3.8109120215987993, "train_loss": 7.607678247630439, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2025752537797811, "epoch": 146, "n_parameters": 106143056}
{"train_lr": 0.00041003033842502425, "train_min_lr": 0.00041003033842502425, "train_mlm_acc_1": 0.19534881875613538, "train_mlm_acc_2": 0.19375825005115757, "train_loss_1": 3.7953096270666062, "train_loss_2": 3.8095038730582336, "train_loss": 7.604813500622856, "train_loss_scale": 5382.079155672824, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.261728872252643, "epoch": 147, "n_parameters": 106143056}
{"train_lr": 0.00040603365906913383, "train_min_lr": 0.00040603365906913383, "train_mlm_acc_1": 0.19545579115674228, "train_mlm_acc_2": 0.19386738685525712, "train_loss_1": 3.7942259360429165, "train_loss_2": 3.808549142397593, "train_loss": 7.602775076815405, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2214769051592917, "epoch": 148, "n_parameters": 106143056}
{"train_lr": 0.000402033924547923, "train_min_lr": 0.000402033924547923, "train_mlm_acc_1": 0.1954882916115493, "train_mlm_acc_2": 0.1938858473167256, "train_loss_1": 3.7927072522350853, "train_loss_2": 3.807113415044761, "train_loss": 7.599820668800105, "train_loss_scale": 8307.278803869833, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 149, "n_parameters": 106143056}
{"train_lr": 0.0003980316042479732, "train_min_lr": 0.0003980316042479732, "train_mlm_acc_1": 0.19567630934244776, "train_mlm_acc_2": 0.194086004002716, "train_loss_1": 3.791041759120443, "train_loss_2": 3.805261063596714, "train_loss": 7.596302823634554, "train_loss_scale": 4798.480211081795, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 150, "n_parameters": 106143056}
{"train_lr": 0.000394027167859318, "train_min_lr": 0.000394027167859318, "train_mlm_acc_1": 0.19584240802549802, "train_mlm_acc_2": 0.1942777549446599, "train_loss_1": 3.789030010409804, "train_loss_2": 3.8033480576076526, "train_loss": 7.5923780683057815, "train_loss_scale": 4380.59454705365, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.259712856331727, "epoch": 151, "n_parameters": 106143056}
{"train_lr": 0.00039002108532032085, "train_min_lr": 0.00039002108532032085, "train_mlm_acc_1": 0.195907924347209, "train_mlm_acc_2": 0.19434146204653704, "train_loss_1": 3.788450641703375, "train_loss_2": 3.802800669859875, "train_loss": 7.591251309702243, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2485749117617242, "epoch": 152, "n_parameters": 106143056}
{"train_lr": 0.00038601382676252893, "train_min_lr": 0.00038601382676252893, "train_mlm_acc_1": 0.196200944645463, "train_mlm_acc_2": 0.19457252733343877, "train_loss_1": 3.787233189521595, "train_loss_2": 3.8015802312861857, "train_loss": 7.588813419182676, "train_loss_scale": 8790.008795074758, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 153, "n_parameters": 106143056}
{"train_lr": 0.0003820058624555032, "train_min_lr": 0.0003820058624555032, "train_mlm_acc_1": 0.19626158260287374, "train_mlm_acc_2": 0.19468064497412563, "train_loss_1": 3.785002732418458, "train_loss_2": 3.7994000200074076, "train_loss": 7.584402753159784, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2395300466236359, "epoch": 154, "n_parameters": 106143056}
{"train_lr": 0.000377997662751625, "train_min_lr": 0.000377997662751625, "train_mlm_acc_1": 0.19648163123981882, "train_mlm_acc_2": 0.19490035002921743, "train_loss_1": 3.783634919683034, "train_loss_2": 3.798011683196275, "train_loss": 7.581646604923796, "train_loss_scale": 5688.288478452067, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2524295146253515, "epoch": 155, "n_parameters": 106143056}
{"train_lr": 0.0003739896980309009, "train_min_lr": 0.0003739896980309009, "train_mlm_acc_1": 0.19658114842860816, "train_mlm_acc_2": 0.19505122907643216, "train_loss_1": 3.7815673218134105, "train_loss_2": 3.7959565419634917, "train_loss": 7.577523868442525, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2610427770262342, "epoch": 156, "n_parameters": 106143056}
{"train_lr": 0.0003699824386457607, "train_min_lr": 0.0003699824386457607, "train_mlm_acc_1": 0.19672191551114082, "train_mlm_acc_2": 0.1951188183600114, "train_loss_1": 3.780661885635624, "train_loss_2": 3.794984801856698, "train_loss": 7.575646689091215, "train_loss_scale": 5173.136323658751, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 157, "n_parameters": 106143056}
{"train_lr": 0.00036597635486586153, "train_min_lr": 0.00036597635486586153, "train_mlm_acc_1": 0.19693992569839472, "train_mlm_acc_2": 0.1953385005506016, "train_loss_1": 3.7788282619459963, "train_loss_2": 3.793283459510107, "train_loss": 7.572111721718217, "train_loss_scale": 3530.4133685136326, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 158, "n_parameters": 106143056}
{"train_lr": 0.0003619719168228958, "train_min_lr": 0.0003619719168228958, "train_mlm_acc_1": 0.19720662955486312, "train_mlm_acc_2": 0.19556648539757665, "train_loss_1": 3.7765232177292347, "train_loss_2": 3.790987915995882, "train_loss": 7.5675111316019965, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2810577521642887, "epoch": 159, "n_parameters": 106143056}
{"train_lr": 0.00035796959445542426, "train_min_lr": 0.00035796959445542426, "train_mlm_acc_1": 0.19726174764610374, "train_mlm_acc_2": 0.19562168363661964, "train_loss_1": 3.775642451688503, "train_loss_2": 3.790228192100634, "train_loss": 7.565870640040912, "train_loss_scale": 3107.1240105540896, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3038408023910557, "epoch": 160, "n_parameters": 106143056}
{"train_lr": 0.0003539698574537211, "train_min_lr": 0.0003539698574537211, "train_mlm_acc_1": 0.19720717916460076, "train_mlm_acc_2": 0.1956462594438852, "train_loss_1": 3.7754417032973224, "train_loss_2": 3.7898469200077662, "train_loss": 7.5652886222304225, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3197252646599722, "epoch": 161, "n_parameters": 106143056}
{"train_lr": 0.0003499731752046559, "train_min_lr": 0.0003499731752046559, "train_mlm_acc_1": 0.19756150159005179, "train_mlm_acc_2": 0.19590779852774076, "train_loss_1": 3.773342814063858, "train_loss_2": 3.787802333908324, "train_loss": 7.561145148312931, "train_loss_scale": 7201.322779243624, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.296861793036616, "epoch": 162, "n_parameters": 106143056}
{"train_lr": 0.0003459800167366142, "train_min_lr": 0.0003459800167366142, "train_mlm_acc_1": 0.19782363601428643, "train_mlm_acc_2": 0.19619695929910336, "train_loss_1": 3.7710454602878976, "train_loss_2": 3.785507271923092, "train_loss": 7.556552731214958, "train_loss_scale": 6761.822339489886, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 163, "n_parameters": 106143056}
{"train_lr": 0.0003419908506644451, "train_min_lr": 0.0003419908506644451, "train_mlm_acc_1": 0.19783378243544641, "train_mlm_acc_2": 0.19627371020025344, "train_loss_1": 3.770083522209496, "train_loss_2": 3.7845584250586852, "train_loss": 7.5546419470060675, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3293165491145225, "epoch": 164, "n_parameters": 106143056}
{"train_lr": 0.00033800614513447493, "train_min_lr": 0.00033800614513447493, "train_mlm_acc_1": 0.19792417242382584, "train_mlm_acc_2": 0.1963642262112392, "train_loss_1": 3.7683478804827786, "train_loss_2": 3.7827743001695042, "train_loss": 7.5511221813862015, "train_loss_scale": 6513.2524186455585, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3279448947889718, "epoch": 165, "n_parameters": 106143056}
{"train_lr": 0.00033402636776956357, "train_min_lr": 0.00033402636776956357, "train_mlm_acc_1": 0.19822247211044047, "train_mlm_acc_2": 0.19659261188896582, "train_loss_1": 3.7665580867305595, "train_loss_2": 3.7812383497558146, "train_loss": 7.547796439002665, "train_loss_scale": 6898.715919085313, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 166, "n_parameters": 106143056}
{"train_lr": 0.000330051985614231, "train_min_lr": 0.000330051985614231, "train_mlm_acc_1": 0.19837773724630306, "train_mlm_acc_2": 0.1967938678435778, "train_loss_1": 3.7644861825433025, "train_loss_2": 3.7789828162132486, "train_loss": 7.543469000879672, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.371870866918522, "epoch": 167, "n_parameters": 106143056}
{"train_lr": 0.0003260834650798454, "train_min_lr": 0.0003260834650798454, "train_mlm_acc_1": 0.19831508376104012, "train_mlm_acc_2": 0.19675679805810606, "train_loss_1": 3.764564044714603, "train_loss_2": 3.779025494632956, "train_loss": 7.543589538246682, "train_loss_scale": 6376.358839050132, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.323721757874535, "epoch": 168, "n_parameters": 106143056}
{"train_lr": 0.00032212127188988656, "train_min_lr": 0.00032212127188988656, "train_mlm_acc_1": 0.19878823128131626, "train_mlm_acc_2": 0.19712106067697102, "train_loss_1": 3.761382008657816, "train_loss_2": 3.775920150331373, "train_loss": 7.537302159277514, "train_loss_scale": 6805.051890941073, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 169, "n_parameters": 106143056}
{"train_lr": 0.0003181658710252925, "train_min_lr": 0.0003181658710252925, "train_mlm_acc_1": 0.19875021093412776, "train_mlm_acc_2": 0.19710164974224914, "train_loss_1": 3.760814029654601, "train_loss_2": 3.775347447306206, "train_loss": 7.536161476305523, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.391327145074477, "epoch": 170, "n_parameters": 106143056}
{"train_lr": 0.0003142177266698921, "train_min_lr": 0.0003142177266698921, "train_mlm_acc_1": 0.19891603477790676, "train_mlm_acc_2": 0.19730129105545968, "train_loss_1": 3.7591584956530637, "train_loss_2": 3.773671071232676, "train_loss": 7.532829562403596, "train_loss_scale": 6470.022867194371, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3422874906341968, "epoch": 171, "n_parameters": 106143056}
{"train_lr": 0.00031027730215593045, "train_min_lr": 0.00031027730215593045, "train_mlm_acc_1": 0.19909635658982877, "train_mlm_acc_2": 0.1974946337923237, "train_loss_1": 3.7574849424911574, "train_loss_2": 3.771978465160363, "train_loss": 7.52946340628853, "train_loss_scale": 5749.530343007916, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 172, "n_parameters": 106143056}
{"train_lr": 0.0003063450599096958, "train_min_lr": 0.0003063450599096958, "train_mlm_acc_1": 0.199295494132065, "train_mlm_acc_2": 0.19764665805340703, "train_loss_1": 3.7557499481851635, "train_loss_2": 3.770292624765671, "train_loss": 7.52604257536228, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3440813999377328, "epoch": 173, "n_parameters": 106143056}
{"train_lr": 0.0003024214613972495, "train_min_lr": 0.0003024214613972495, "train_mlm_acc_1": 0.19943659320938922, "train_mlm_acc_2": 0.19785066260223128, "train_loss_1": 3.754125266821634, "train_loss_2": 3.7686813949699873, "train_loss": 7.522806664779717, "train_loss_scale": 7525.544415127529, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3588076251163332, "epoch": 174, "n_parameters": 106143056}
{"train_lr": 0.0002985069670702745, "train_min_lr": 0.0002985069670702745, "train_mlm_acc_1": 0.19966504751666136, "train_mlm_acc_2": 0.19805112839066205, "train_loss_1": 3.7519600518775174, "train_loss_2": 3.7665608018872607, "train_loss": 7.518520853345397, "train_loss_scale": 8833.238346525946, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3447640614752825, "epoch": 175, "n_parameters": 106143056}
{"train_lr": 0.0002946020363120353, "train_min_lr": 0.0002946020363120353, "train_mlm_acc_1": 0.19982680591542468, "train_mlm_acc_2": 0.1981818750467915, "train_loss_1": 3.751082803270957, "train_loss_2": 3.765679382292346, "train_loss": 7.516762182391727, "train_loss_scale": 8948.517150395779, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 176, "n_parameters": 106143056}
{"train_lr": 0.0002907071273834704, "train_min_lr": 0.0002907071273834704, "train_mlm_acc_1": 0.1998912002072197, "train_mlm_acc_2": 0.1982834879308939, "train_loss_1": 3.7493587142035114, "train_loss_2": 3.763903156329166, "train_loss": 7.513261868697882, "train_loss_scale": 8357.713280562884, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 177, "n_parameters": 106143056}
{"train_lr": 0.0002868226973694113, "train_min_lr": 0.0002868226973694113, "train_mlm_acc_1": 0.2001113403267444, "train_mlm_acc_2": 0.19849753582468396, "train_loss_1": 3.74750427837527, "train_loss_2": 3.7620482820372048, "train_loss": 7.5095525584204115, "train_loss_scale": 6300.707124010554, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 178, "n_parameters": 106143056}
{"train_lr": 0.00028294920212494217, "train_min_lr": 0.00028294920212494217, "train_mlm_acc_1": 0.20029988480943173, "train_mlm_acc_2": 0.19866548965315653, "train_loss_1": 3.7456402598553407, "train_loss_2": 3.760260597172807, "train_loss": 7.5059008578407, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.349418823249317, "epoch": 179, "n_parameters": 106143056}
{"train_lr": 0.00027908709622190573, "train_min_lr": 0.00027908709622190573, "train_mlm_acc_1": 0.2004429995620471, "train_mlm_acc_2": 0.19881430729443866, "train_loss_1": 3.74422938014293, "train_loss_2": 3.7588641031750902, "train_loss": 7.503093480958998, "train_loss_scale": 4384.197009674583, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 180, "n_parameters": 106143056}
{"train_lr": 0.00027523683289555303, "train_min_lr": 0.00027523683289555303, "train_mlm_acc_1": 0.20056851248673788, "train_mlm_acc_2": 0.1989166989444166, "train_loss_1": 3.7434874294930207, "train_loss_2": 3.7581487210990048, "train_loss": 7.501636151378366, "train_loss_scale": 2053.4036939313983, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 181, "n_parameters": 106143056}
{"train_lr": 0.0002713988639913556, "train_min_lr": 0.0002713988639913556, "train_mlm_acc_1": 0.2008184276622775, "train_mlm_acc_2": 0.19918936916455796, "train_loss_1": 3.7411153633655325, "train_loss_2": 3.7557204807653903, "train_loss": 7.496835843187314, "train_loss_scale": 2536.1336851363235, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4253027728490906, "epoch": 182, "n_parameters": 106143056}
{"train_lr": 0.00026757363991198143, "train_min_lr": 0.00026757363991198143, "train_mlm_acc_1": 0.20088535278426153, "train_mlm_acc_2": 0.19933073164153067, "train_loss_1": 3.740178106852341, "train_loss_2": 3.7547904652729303, "train_loss": 7.4949685698448825, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4593596013366075, "epoch": 183, "n_parameters": 106143056}
{"train_lr": 0.00026376160956443706, "train_min_lr": 0.00026376160956443706, "train_mlm_acc_1": 0.2010850970852029, "train_mlm_acc_2": 0.19943749794708654, "train_loss_1": 3.7380370371364773, "train_loss_2": 3.752642993011701, "train_loss": 7.490680029545317, "train_loss_scale": 2838.740545294635, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 184, "n_parameters": 106143056}
{"train_lr": 0.00025996322030738496, "train_min_lr": 0.00025996322030738496, "train_mlm_acc_1": 0.20128827714897765, "train_mlm_acc_2": 0.19965734041034652, "train_loss_1": 3.737229968831533, "train_loss_2": 3.751801510547061, "train_loss": 7.4890314792999595, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4721899962572016, "epoch": 185, "n_parameters": 106143056}
{"train_lr": 0.00025617891789864574, "train_min_lr": 0.00025617891789864574, "train_mlm_acc_1": 0.20142028340045937, "train_mlm_acc_2": 0.19979779822334137, "train_loss_1": 3.7342098682411113, "train_loss_2": 3.748936710461463, "train_loss": 7.483146576946413, "train_loss_scale": 2192.0985048372913, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 186, "n_parameters": 106143056}
{"train_lr": 0.0002524091464428861, "train_min_lr": 0.0002524091464428861, "train_mlm_acc_1": 0.20153930323098507, "train_mlm_acc_2": 0.19989216210043734, "train_loss_1": 3.7336649278485154, "train_loss_2": 3.7484375434217476, "train_loss": 7.482102473734132, "train_loss_scale": 2100.235708003518, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4702623185612387, "epoch": 187, "n_parameters": 106143056}
{"train_lr": 0.00024865434833949967, "train_min_lr": 0.00024865434833949967, "train_mlm_acc_1": 0.2017012449471229, "train_mlm_acc_2": 0.200086627129331, "train_loss_1": 3.7313854760156984, "train_loss_2": 3.7460181359250817, "train_loss": 7.4774036121766825, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4938146055740753, "epoch": 188, "n_parameters": 106143056}
{"train_lr": 0.0002449149642306928, "train_min_lr": 0.0002449149642306928, "train_mlm_acc_1": 0.20197034210602285, "train_mlm_acc_2": 0.20029454822787193, "train_loss_1": 3.7300977896679464, "train_loss_2": 3.744773708945738, "train_loss": 7.474871498613685, "train_loss_scale": 4139.229551451187, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 189, "n_parameters": 106143056}
{"train_lr": 0.0002411914329497703, "train_min_lr": 0.0002411914329497703, "train_mlm_acc_1": 0.20211456761111424, "train_mlm_acc_2": 0.20045612330106968, "train_loss_1": 3.7287219850348086, "train_loss_2": 3.7434612609832665, "train_loss": 7.472183245834596, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4668285791666338, "epoch": 190, "n_parameters": 106143056}
{"train_lr": 0.000237484191469636, "train_min_lr": 0.000237484191469636, "train_mlm_acc_1": 0.20233055078174686, "train_mlm_acc_2": 0.20063677739774646, "train_loss_1": 3.7264271876008865, "train_loss_2": 3.7412420442047725, "train_loss": 7.467669232801691, "train_loss_scale": 4101.403693931398, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 191, "n_parameters": 106143056}
{"train_lr": 0.00023379367485151643, "train_min_lr": 0.00023379367485151643, "train_mlm_acc_1": 0.2024401228009947, "train_mlm_acc_2": 0.20081436229098126, "train_loss_1": 3.724973907309241, "train_loss_2": 3.739704704326606, "train_loss": 7.464678614466675, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.521691676809165, "epoch": 192, "n_parameters": 106143056}
{"train_lr": 0.00023012031619389827, "train_min_lr": 0.00023012031619389827, "train_mlm_acc_1": 0.20273600600613978, "train_mlm_acc_2": 0.2010818334065358, "train_loss_1": 3.722451952825855, "train_loss_2": 3.737122311047954, "train_loss": 7.45957426350685, "train_loss_scale": 2105.6394019349164, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 193, "n_parameters": 106143056}
{"train_lr": 0.00022646454658170753, "train_min_lr": 0.00022646454658170753, "train_mlm_acc_1": 0.2029016924220921, "train_mlm_acc_2": 0.2012513218563879, "train_loss_1": 3.7208083319422856, "train_loss_2": 3.7354660384625644, "train_loss": 7.456274371086345, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.464878921877845, "epoch": 194, "n_parameters": 106143056}
{"train_lr": 0.00022282679503571708, "train_min_lr": 0.00022282679503571708, "train_mlm_acc_1": 0.2029172899144175, "train_mlm_acc_2": 0.20127226739938361, "train_loss_1": 3.7197302032062227, "train_loss_2": 3.734428816310334, "train_loss": 7.454159020696068, "train_loss_scale": 2890.976253298153, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 195, "n_parameters": 106143056}
{"train_lr": 0.00021920748846219963, "train_min_lr": 0.00021920748846219963, "train_mlm_acc_1": 0.20324583413044978, "train_mlm_acc_2": 0.20156042059111878, "train_loss_1": 3.717773945895642, "train_loss_2": 3.7325357084433657, "train_loss": 7.450309652976017, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.533986301357115, "epoch": 196, "n_parameters": 106143056}
{"train_lr": 0.00021560705160282874, "train_min_lr": 0.00021560705160282874, "train_mlm_acc_1": 0.20327797963094743, "train_mlm_acc_2": 0.20162842212049922, "train_loss_1": 3.717218786661522, "train_loss_2": 3.7319711948709733, "train_loss": 7.44918998124417, "train_loss_scale": 2842.3430079155673, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5308190880371169, "epoch": 197, "n_parameters": 106143056}
{"train_lr": 0.0002120259069848334, "train_min_lr": 0.0002120259069848334, "train_mlm_acc_1": 0.20364408610960372, "train_mlm_acc_2": 0.20196351670908266, "train_loss_1": 3.7136799029960064, "train_loss_2": 3.728380424418571, "train_loss": 7.442060327467, "train_loss_scale": 2487.5004397537377, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 198, "n_parameters": 106143056}
{"train_lr": 0.00020846447487141197, "train_min_lr": 0.00020846447487141197, "train_mlm_acc_1": 0.20377937907954266, "train_mlm_acc_2": 0.20209840891543668, "train_loss_1": 3.7122073450052855, "train_loss_2": 3.7270383641661105, "train_loss": 7.439245711530419, "train_loss_scale": 2102.036939313984, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5703569684200571, "epoch": 199, "n_parameters": 106143056}
{"train_lr": 0.0002049231732124145, "train_min_lr": 0.0002049231732124145, "train_mlm_acc_1": 0.2039179473627185, "train_mlm_acc_2": 0.2022302892114787, "train_loss_1": 3.711272724595317, "train_loss_2": 3.7260323122550023, "train_loss": 7.437305036561995, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5708486460863549, "epoch": 200, "n_parameters": 106143056}
{"train_lr": 0.00020140241759529154, "train_min_lr": 0.00020140241759529154, "train_mlm_acc_1": 0.20410925156634266, "train_mlm_acc_2": 0.20244127945284782, "train_loss_1": 3.7089524004369214, "train_loss_2": 3.723865119427469, "train_loss": 7.4328175173480995, "train_loss_scale": 4513.885664028145, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 201, "n_parameters": 106143056}
{"train_lr": 0.00019790262119632546, "train_min_lr": 0.00019790262119632546, "train_mlm_acc_1": 0.20436342702252935, "train_mlm_acc_2": 0.20266832522359876, "train_loss_1": 3.7069305108897814, "train_loss_2": 3.7217249717750147, "train_loss": 7.428655484316112, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.553016724928283, "epoch": 202, "n_parameters": 106143056}
{"train_lr": 0.0001944241947321401, "train_min_lr": 0.0001944241947321401, "train_mlm_acc_1": 0.20447317080485422, "train_mlm_acc_2": 0.2027904485731583, "train_loss_1": 3.70619051875309, "train_loss_2": 3.7209892749733955, "train_loss": 7.427179797710613, "train_loss_scale": 3047.6833773087073, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 203, "n_parameters": 106143056}
{"train_lr": 0.00019096754641150413, "train_min_lr": 0.00019096754641150413, "train_mlm_acc_1": 0.20463939545808807, "train_mlm_acc_2": 0.20292702406520316, "train_loss_1": 3.7041321781872654, "train_loss_2": 3.7190252637905097, "train_loss": 7.423157442108832, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5793712603070804, "epoch": 204, "n_parameters": 106143056}
{"train_lr": 0.00018753308188742345, "train_min_lr": 0.00018753308188742345, "train_mlm_acc_1": 0.20479161430907122, "train_mlm_acc_2": 0.2031243635847732, "train_loss_1": 3.7027967983992767, "train_loss_2": 3.7175610330719224, "train_loss": 7.420357829557769, "train_loss_scale": 2399.2401055408973, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 205, "n_parameters": 106143056}
{"train_lr": 0.00018412120420953888, "train_min_lr": 0.00018412120420953888, "train_mlm_acc_1": 0.20494378749330314, "train_mlm_acc_2": 0.2032602978452529, "train_loss_1": 3.700763978607946, "train_loss_2": 3.715659809406116, "train_loss": 7.416423787751948, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6677675769847007, "epoch": 206, "n_parameters": 106143056}
{"train_lr": 0.00018073231377682198, "train_min_lr": 0.00018073231377682198, "train_mlm_acc_1": 0.2052051546944923, "train_mlm_acc_2": 0.203552058449862, "train_loss_1": 3.6991756966791347, "train_loss_2": 3.713943313902265, "train_loss": 7.41311901000475, "train_loss_scale": 2093.0307827616534, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 207, "n_parameters": 106143056}
{"train_lr": 0.0001773668082905917, "train_min_lr": 0.0001773668082905917, "train_mlm_acc_1": 0.20538906109410363, "train_mlm_acc_2": 0.20373551826842176, "train_loss_1": 3.6969711415948003, "train_loss_2": 3.7117404124405473, "train_loss": 7.408711552882048, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6266751177183032, "epoch": 208, "n_parameters": 106143056}
{"train_lr": 0.00017402508270783777, "train_min_lr": 0.00017402508270783777, "train_mlm_acc_1": 0.20543059708817601, "train_mlm_acc_2": 0.20375003928618413, "train_loss_1": 3.696306740519449, "train_loss_2": 3.711078772863591, "train_loss": 7.407385512203528, "train_loss_scale": 1486.9164467897976, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5384735525335884, "epoch": 209, "n_parameters": 106143056}
{"train_lr": 0.0001707075291948745, "train_min_lr": 0.0001707075291948745, "train_mlm_acc_1": 0.20581925241317578, "train_mlm_acc_2": 0.20409171877096333, "train_loss_1": 3.69312401426499, "train_loss_2": 3.7079874155494132, "train_loss": 7.401111430050306, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5972021628390727, "epoch": 210, "n_parameters": 106143056}
{"train_lr": 0.0001674145370813154, "train_min_lr": 0.0001674145370813154, "train_mlm_acc_1": 0.20592923672081823, "train_mlm_acc_2": 0.20422412583353808, "train_loss_1": 3.692077703295618, "train_loss_2": 3.706840738588608, "train_loss": 7.398918442382242, "train_loss_scale": 3467.3702726473175, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6454689470213972, "epoch": 211, "n_parameters": 106143056}
{"train_lr": 0.0001641464928143861, "train_min_lr": 0.0001641464928143861, "train_mlm_acc_1": 0.20622276086704242, "train_mlm_acc_2": 0.20450371298726022, "train_loss_1": 3.68943859653821, "train_loss_2": 3.7042292937597057, "train_loss": 7.3936678919230205, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6068827776711765, "epoch": 212, "n_parameters": 106143056}
{"train_lr": 0.0001609037799135703, "train_min_lr": 0.0001609037799135703, "train_mlm_acc_1": 0.2063110322759486, "train_mlm_acc_2": 0.2046234429786891, "train_loss_1": 3.68775217142038, "train_loss_2": 3.7025971582246227, "train_loss": 7.39034932883245, "train_loss_scale": 4600.344766930519, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 213, "n_parameters": 106143056}
{"train_lr": 0.00015768677892560474, "train_min_lr": 0.00015768677892560474, "train_mlm_acc_1": 0.20655318310282791, "train_mlm_acc_2": 0.2048756486081773, "train_loss_1": 3.6862806021747825, "train_loss_2": 3.7010338546260995, "train_loss": 7.3873144552282, "train_loss_scale": 4117.614775725594, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 214, "n_parameters": 106143056}
{"train_lr": 0.0001544958673798188, "train_min_lr": 0.0001544958673798188, "train_mlm_acc_1": 0.20675033931321446, "train_mlm_acc_2": 0.20509967097984716, "train_loss_1": 3.684506966549782, "train_loss_2": 3.6993366240039665, "train_loss": 7.383843588902432, "train_loss_scale": 2152.471416007036, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 215, "n_parameters": 106143056}
{"train_lr": 0.00015133141974383045, "train_min_lr": 0.00015133141974383045, "train_mlm_acc_1": 0.20697390382803105, "train_mlm_acc_2": 0.20525138607459992, "train_loss_1": 3.6824362030025104, "train_loss_2": 3.6974039365297466, "train_loss": 7.3798401397681594, "train_loss_scale": 2437.065963060686, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.617317828465263, "epoch": 216, "n_parameters": 106143056}
{"train_lr": 0.00014819380737959978, "train_min_lr": 0.00014819380737959978, "train_mlm_acc_1": 0.20710657429025428, "train_mlm_acc_2": 0.20541759924561756, "train_loss_1": 3.6810896336350822, "train_loss_2": 3.6958913704807967, "train_loss": 7.376981004404204, "train_loss_scale": 3155.7572559366754, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 217, "n_parameters": 106143056}
{"train_lr": 0.0001450833984998489, "train_min_lr": 0.0001450833984998489, "train_mlm_acc_1": 0.2073561574808316, "train_mlm_acc_2": 0.20567509568015419, "train_loss_1": 3.6787783237749165, "train_loss_2": 3.693519725071933, "train_loss": 7.372298050471954, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6038463342682563, "epoch": 218, "n_parameters": 106143056}
{"train_lr": 0.0001420005581248513, "train_min_lr": 0.0001420005581248513, "train_mlm_acc_1": 0.20758263069543276, "train_mlm_acc_2": 0.2059007214010417, "train_loss_1": 3.6767035982487175, "train_loss_2": 3.691548289912986, "train_loss": 7.36825188865972, "train_loss_scale": 2206.50835532102, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 219, "n_parameters": 106143056}
{"train_lr": 0.00013894564803959363, "train_min_lr": 0.00013894564803959363, "train_mlm_acc_1": 0.20771555306853542, "train_mlm_acc_2": 0.20604612639300007, "train_loss_1": 3.6748219851401154, "train_loss_2": 3.689585452973056, "train_loss": 7.364407439764488, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6849738027615409, "epoch": 220, "n_parameters": 106143056}
{"train_lr": 0.00013591902675131893, "train_min_lr": 0.00013591902675131893, "train_mlm_acc_1": 0.20783424082399726, "train_mlm_acc_2": 0.20614172704845482, "train_loss_1": 3.6746128067020374, "train_loss_2": 3.689437855411855, "train_loss": 7.3640506614586085, "train_loss_scale": 1301.3896218117854, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6955974574873294, "epoch": 221, "n_parameters": 106143056}
{"train_lr": 0.00013292104944745455, "train_min_lr": 0.00013292104944745455, "train_mlm_acc_1": 0.2081543563397416, "train_mlm_acc_2": 0.20651683470819115, "train_loss_1": 3.6711162998944706, "train_loss_2": 3.6858933211264113, "train_loss": 7.3570096180327855, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6956872391721713, "epoch": 222, "n_parameters": 106143056}
{"train_lr": 0.00012995206795392967, "train_min_lr": 0.00012995206795392967, "train_mlm_acc_1": 0.2082711659230967, "train_mlm_acc_2": 0.20656189797224972, "train_loss_1": 3.6703841520068723, "train_loss_2": 3.685227281185442, "train_loss": 7.355611434817419, "train_loss_scale": 3096.3166226912927, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7259706704367015, "epoch": 223, "n_parameters": 106143056}
{"train_lr": 0.00012701243069388645, "train_min_lr": 0.00012701243069388645, "train_mlm_acc_1": 0.20842359094612675, "train_mlm_acc_2": 0.20674896517911026, "train_loss_1": 3.668310215521404, "train_loss_2": 3.683064906976678, "train_loss": 7.351375123179578, "train_loss_scale": 2590.170624450308, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 224, "n_parameters": 106143056}
{"train_lr": 0.0001241024826467912, "train_min_lr": 0.0001241024826467912, "train_mlm_acc_1": 0.20870083060014008, "train_mlm_acc_2": 0.2070092559221185, "train_loss_1": 3.666683240663408, "train_loss_2": 3.681435965715843, "train_loss": 7.348119206982112, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7173975881192385, "epoch": 225, "n_parameters": 106143056}
{"train_lr": 0.00012122256530794866, "train_min_lr": 0.00012122256530794866, "train_mlm_acc_1": 0.20876868313101424, "train_mlm_acc_2": 0.20708277716695372, "train_loss_1": 3.6647339379095465, "train_loss_2": 3.679553408080691, "train_loss": 7.34428734986952, "train_loss_scale": 2833.3368513632367, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 226, "n_parameters": 106143056}
{"train_lr": 0.00011837301664842798, "train_min_lr": 0.00011837301664842798, "train_mlm_acc_1": 0.2090564469824051, "train_mlm_acc_2": 0.20736806747964734, "train_loss_1": 3.662582822373381, "train_loss_2": 3.6774156754385934, "train_loss": 7.33999849812651, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.741509459211623, "epoch": 227, "n_parameters": 106143056}
{"train_lr": 0.00011555417107539845, "train_min_lr": 0.00011555417107539845, "train_mlm_acc_1": 0.2092564662913534, "train_mlm_acc_2": 0.20756394110239956, "train_loss_1": 3.661076240641251, "train_loss_2": 3.675952788891243, "train_loss": 7.337029030213989, "train_loss_scale": 2318.184696569921, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 228, "n_parameters": 106143056}
{"train_lr": 0.00011276635939288607, "train_min_lr": 0.00011276635939288607, "train_mlm_acc_1": 0.20946118074060535, "train_mlm_acc_2": 0.20769630240975973, "train_loss_1": 3.659298888768873, "train_loss_2": 3.674143691385851, "train_loss": 7.333442580049879, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7224775717357008, "epoch": 229, "n_parameters": 106143056}
{"train_lr": 0.00011000990876295262, "train_min_lr": 0.00011000990876295262, "train_mlm_acc_1": 0.20959239682754405, "train_mlm_acc_2": 0.20788019736155725, "train_loss_1": 3.65820589677325, "train_loss_2": 3.6729264251212856, "train_loss": 7.331132321422731, "train_loss_scale": 3609.6675461741424, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 230, "n_parameters": 106143056}
{"train_lr": 0.00010728514266730062, "train_min_lr": 0.00010728514266730062, "train_mlm_acc_1": 0.20986238739100221, "train_mlm_acc_2": 0.20821255496592508, "train_loss_1": 3.6556968435763055, "train_loss_2": 3.670510213576395, "train_loss": 7.326207058568114, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7716395032437307, "epoch": 231, "n_parameters": 106143056}
{"train_lr": 0.00010459238086931266, "train_min_lr": 0.00010459238086931266, "train_mlm_acc_1": 0.2100747402957268, "train_mlm_acc_2": 0.2083645906355052, "train_loss_1": 3.6537894807107216, "train_loss_2": 3.668540810820505, "train_loss": 7.322330295148395, "train_loss_scale": 1308.5945470536499, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.712024421679313, "epoch": 232, "n_parameters": 106143056}
{"train_lr": 0.0001019319393765248, "train_min_lr": 0.0001019319393765248, "train_mlm_acc_1": 0.21019057648235123, "train_mlm_acc_2": 0.20848768737196607, "train_loss_1": 3.6526886280052686, "train_loss_2": 3.667392659706302, "train_loss": 7.3200812896512115, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7803182768632995, "epoch": 233, "n_parameters": 106143056}
{"train_lr": 9.930413040354184e-05, "train_min_lr": 9.930413040354184e-05, "train_mlm_acc_1": 0.2103745860154941, "train_mlm_acc_2": 0.208680594980507, "train_loss_1": 3.650813526297832, "train_loss_2": 3.6655455797569942, "train_loss": 7.316359105189851, "train_loss_scale": 2417.2524186455585, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 234, "n_parameters": 106143056}
{"train_lr": 9.670926233539824e-05, "train_min_lr": 9.670926233539824e-05, "train_mlm_acc_1": 0.21059502397312496, "train_mlm_acc_2": 0.20889613153077105, "train_loss_1": 3.6491459215693864, "train_loss_2": 3.6638884787876145, "train_loss": 7.313034400828805, "train_loss_scale": 1469.8047493403694, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 235, "n_parameters": 106143056}
{"train_lr": 9.414763969136625e-05, "train_min_lr": 9.414763969136625e-05, "train_mlm_acc_1": 0.21074928139175045, "train_mlm_acc_2": 0.20901351377348315, "train_loss_1": 3.6475152437793863, "train_loss_2": 3.6623199642386055, "train_loss": 7.309835208122837, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7882711079001112, "epoch": 236, "n_parameters": 106143056}
{"train_lr": 9.16195630892216e-05, "train_min_lr": 9.16195630892216e-05, "train_mlm_acc_1": 0.2109016262456814, "train_mlm_acc_2": 0.20922813419884984, "train_loss_1": 3.6460411646382895, "train_loss_2": 3.660786287477379, "train_loss": 7.306827454265001, "train_loss_scale": 1848.9639401934917, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7860667661500795, "epoch": 237, "n_parameters": 106143056}
{"train_lr": 8.91253292099618e-05, "train_min_lr": 8.91253292099618e-05, "train_mlm_acc_1": 0.21105035228479455, "train_mlm_acc_2": 0.20937609299689716, "train_loss_1": 3.6444120007643286, "train_loss_2": 3.659189847208684, "train_loss": 7.303601849991288, "train_loss_scale": 2130.856640281442, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 238, "n_parameters": 106143056}
{"train_lr": 8.66652307629916e-05, "train_min_lr": 8.66652307629916e-05, "train_mlm_acc_1": 0.21137863300780035, "train_mlm_acc_2": 0.2096955557497138, "train_loss_1": 3.642133887991532, "train_loss_2": 3.656841501790175, "train_loss": 7.298975389676862, "train_loss_scale": 1265.3649956024626, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 239, "n_parameters": 106143056}
{"train_lr": 8.423955645177132e-05, "train_min_lr": 8.423955645177132e-05, "train_mlm_acc_1": 0.21143687757431623, "train_mlm_acc_2": 0.20975185349819528, "train_loss_1": 3.6407533706859634, "train_loss_2": 3.6555011329046967, "train_loss": 7.296254504481847, "train_loss_scale": 1029.4036939313985, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8518833544239626, "epoch": 240, "n_parameters": 106143056}
{"train_lr": 8.184859093993656e-05, "train_min_lr": 8.184859093993656e-05, "train_mlm_acc_1": 0.2117163045061531, "train_mlm_acc_2": 0.2100315666319303, "train_loss_1": 3.63904585199809, "train_loss_2": 3.653697339321504, "train_loss": 7.292743192341837, "train_loss_scale": 1127.570800351803, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 241, "n_parameters": 106143056}
{"train_lr": 7.949261481789082e-05, "train_min_lr": 7.949261481789082e-05, "train_mlm_acc_1": 0.21190348606828596, "train_mlm_acc_2": 0.2101912406980074, "train_loss_1": 3.6369905049012434, "train_loss_2": 3.651803440054782, "train_loss": 7.288793942597002, "train_loss_scale": 683.1169744942832, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 242, "n_parameters": 106143056}
{"train_lr": 7.717190456987782e-05, "train_min_lr": 7.717190456987782e-05, "train_mlm_acc_1": 0.21203049930695547, "train_mlm_acc_2": 0.21038224728959845, "train_loss_1": 3.635700926302605, "train_loss_2": 3.6504660634587704, "train_loss": 7.286166988293539, "train_loss_scale": 404.3764291996482, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 243, "n_parameters": 106143056}
{"train_lr": 7.488673254153478e-05, "train_min_lr": 7.488673254153478e-05, "train_mlm_acc_1": 0.21233256657590652, "train_mlm_acc_2": 0.21065145901182344, "train_loss_1": 3.6334603824108025, "train_loss_2": 3.6482197472214595, "train_loss": 7.281680129343937, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9210750724835257, "epoch": 244, "n_parameters": 106143056}
{"train_lr": 7.263736690793118e-05, "train_min_lr": 7.263736690793118e-05, "train_mlm_acc_1": 0.21234508357096787, "train_mlm_acc_2": 0.21065519234573463, "train_loss_1": 3.63326828620784, "train_loss_2": 3.6479357047991052, "train_loss": 7.281203990456507, "train_loss_scale": 425.31574318381706, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9446898493833886, "epoch": 245, "n_parameters": 106143056}
{"train_lr": 7.04240716420974e-05, "train_min_lr": 7.04240716420974e-05, "train_mlm_acc_1": 0.21270703298441915, "train_mlm_acc_2": 0.21104273682160396, "train_loss_1": 3.6300908192376244, "train_loss_2": 3.6447572973913127, "train_loss": 7.27484811725801, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8724128192941034, "epoch": 246, "n_parameters": 106143056}
{"train_lr": 6.824710648404599e-05, "train_min_lr": 6.824710648404599e-05, "train_mlm_acc_1": 0.2128449712430267, "train_mlm_acc_2": 0.21111670471957197, "train_loss_1": 3.62916008067844, "train_loss_2": 3.643890617705272, "train_loss": 7.273050699772915, "train_loss_scale": 974.0158311345647, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.012753277676296, "epoch": 247, "n_parameters": 106143056}
{"train_lr": 6.610672691029053e-05, "train_min_lr": 6.610672691029053e-05, "train_mlm_acc_1": 0.21298718136115197, "train_mlm_acc_2": 0.21125417360143117, "train_loss_1": 3.627814326300994, "train_loss_2": 3.6424843686237183, "train_loss": 7.270298696340126, "train_loss_scale": 1170.8003518029902, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9500244607396995, "epoch": 248, "n_parameters": 106143056}
{"train_lr": 6.400318410386393e-05, "train_min_lr": 6.400318410386393e-05, "train_mlm_acc_1": 0.21313772833330283, "train_mlm_acc_2": 0.2114431989905912, "train_loss_1": 3.6264316489954425, "train_loss_2": 3.640970740149497, "train_loss": 7.2674023875460465, "train_loss_scale": 1304.9920844327178, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 249, "n_parameters": 106143056}
{"train_lr": 6.19367249248409e-05, "train_min_lr": 6.19367249248409e-05, "train_mlm_acc_1": 0.2132818735398765, "train_mlm_acc_2": 0.21156839140925945, "train_loss_1": 3.6247295773438224, "train_loss_2": 3.6394960000101895, "train_loss": 7.264225576462826, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9966161448177582, "epoch": 250, "n_parameters": 106143056}
{"train_lr": 5.990759188136876e-05, "train_min_lr": 5.990759188136876e-05, "train_mlm_acc_1": 0.2134487279916056, "train_mlm_acc_2": 0.21176381848536255, "train_loss_1": 3.623041062131721, "train_loss_2": 3.637813687979808, "train_loss": 7.260854748119465, "train_loss_scale": 1445.4881266490765, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 251, "n_parameters": 106143056}
{"train_lr": 5.791602310120655e-05, "train_min_lr": 5.791602310120655e-05, "train_mlm_acc_1": 0.2136620086230331, "train_mlm_acc_2": 0.21190813547958642, "train_loss_1": 3.6217018375033962, "train_loss_2": 3.636337518665805, "train_loss": 7.258039358423379, "train_loss_scale": 707.4335971855761, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 252, "n_parameters": 106143056}
{"train_lr": 5.59622523037808e-05, "train_min_lr": 5.59622523037808e-05, "train_mlm_acc_1": 0.2139143517327707, "train_mlm_acc_2": 0.21224998683556456, "train_loss_1": 3.6197992735718465, "train_loss_2": 3.634348824161548, "train_loss": 7.2541480978644515, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0113508301863257, "epoch": 253, "n_parameters": 106143056}
{"train_lr": 5.4046508772757435e-05, "train_min_lr": 5.4046508772757435e-05, "train_mlm_acc_1": 0.21404719388598975, "train_mlm_acc_2": 0.2123135793954134, "train_loss_1": 3.618015588666644, "train_loss_2": 3.63263417323011, "train_loss": 7.250649760926934, "train_loss_scale": 951.9507475813544, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.04587008283132, "epoch": 254, "n_parameters": 106143056}
{"train_lr": 5.2169017329133505e-05, "train_min_lr": 5.2169017329133505e-05, "train_mlm_acc_1": 0.21412707101504533, "train_mlm_acc_2": 0.21240410672970897, "train_loss_1": 3.6175870647164112, "train_loss_2": 3.6322121810472736, "train_loss": 7.249799247624692, "train_loss_scale": 692.5734388742304, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 255, "n_parameters": 106143056}
{"train_lr": 5.03299983048543e-05, "train_min_lr": 5.03299983048543e-05, "train_mlm_acc_1": 0.21425285903620636, "train_mlm_acc_2": 0.2125970716821644, "train_loss_1": 3.6158595204929984, "train_loss_2": 3.6304034918887425, "train_loss": 7.246263010678002, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1172898317914104, "epoch": 256, "n_parameters": 106143056}
{"train_lr": 4.8529667516956426e-05, "train_min_lr": 4.8529667516956426e-05, "train_mlm_acc_1": 0.21452212802371176, "train_mlm_acc_2": 0.21280075553329555, "train_loss_1": 3.614251918297854, "train_loss_2": 3.628841668970247, "train_loss": 7.243093589522279, "train_loss_scale": 766.4239226033421, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 257, "n_parameters": 106143056}
{"train_lr": 4.676823624223976e-05, "train_min_lr": 4.676823624223976e-05, "train_mlm_acc_1": 0.21467352239292184, "train_mlm_acc_2": 0.2130427803654181, "train_loss_1": 3.6128826351834684, "train_loss_2": 3.6273287942824703, "train_loss": 7.240211430042589, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0234314243103606, "epoch": 258, "n_parameters": 106143056}
{"train_lr": 4.5045911192474324e-05, "train_min_lr": 4.5045911192474324e-05, "train_mlm_acc_1": 0.21477961298749965, "train_mlm_acc_2": 0.21307965552986402, "train_loss_1": 3.6121842008257707, "train_loss_2": 3.62663441327652, "train_loss": 7.238818612293707, "train_loss_scale": 835.7713280562884, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9866846939294927, "epoch": 259, "n_parameters": 106143056}
{"train_lr": 4.336289449014104e-05, "train_min_lr": 4.336289449014104e-05, "train_mlm_acc_1": 0.21486890360568842, "train_mlm_acc_2": 0.21317823370631944, "train_loss_1": 3.610412181026598, "train_loss_2": 3.6249218143280286, "train_loss": 7.235333994804188, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.875743290784596, "epoch": 260, "n_parameters": 106143056}
{"train_lr": 4.171938364471223e-05, "train_min_lr": 4.171938364471223e-05, "train_mlm_acc_1": 0.2150519624935658, "train_mlm_acc_2": 0.21336720175320315, "train_loss_1": 3.609398148278972, "train_loss_2": 3.6238943121626175, "train_loss": 7.233292461909426, "train_loss_scale": 1918.311345646438, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9400022365906413, "epoch": 261, "n_parameters": 106143056}
{"train_lr": 4.011557152947225e-05, "train_min_lr": 4.011557152947225e-05, "train_mlm_acc_1": 0.21517683429317508, "train_mlm_acc_2": 0.21350497995538467, "train_loss_1": 3.608095812870938, "train_loss_2": 3.622463753061957, "train_loss": 7.230559566195009, "train_loss_scale": 1848.0633245382585, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 262, "n_parameters": 106143056}
{"train_lr": 3.8551646358884036e-05, "train_min_lr": 3.8551646358884036e-05, "train_mlm_acc_1": 0.21537748345304134, "train_mlm_acc_2": 0.21369050098820644, "train_loss_1": 3.6064727535715413, "train_loss_2": 3.62093970625151, "train_loss": 7.227412460504547, "train_loss_scale": 678.1635883905013, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 263, "n_parameters": 106143056}
{"train_lr": 3.702779166650029e-05, "train_min_lr": 3.702779166650029e-05, "train_mlm_acc_1": 0.21557190269067975, "train_mlm_acc_2": 0.21388921468938876, "train_loss_1": 3.605051742982948, "train_loss_2": 3.6195816945222354, "train_loss": 7.224633438186679, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0737731045762384, "epoch": 264, "n_parameters": 106143056}
{"train_lr": 3.55441862834257e-05, "train_min_lr": 3.55441862834257e-05, "train_mlm_acc_1": 0.21560029196982963, "train_mlm_acc_2": 0.21386406635873761, "train_loss_1": 3.6038822706005713, "train_loss_2": 3.6183819555093453, "train_loss": 7.222264225638112, "train_loss_scale": 570.089709762533, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 265, "n_parameters": 106143056}
{"train_lr": 3.4101004317329864e-05, "train_min_lr": 3.4101004317329864e-05, "train_mlm_acc_1": 0.21589030031517817, "train_mlm_acc_2": 0.21418091807131087, "train_loss_1": 3.602484196162371, "train_loss_2": 3.6169210734499475, "train_loss": 7.2194052688784, "train_loss_scale": 534.5153913808267, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0762271066454283, "epoch": 266, "n_parameters": 106143056}
{"train_lr": 3.269841513201525e-05, "train_min_lr": 3.269841513201525e-05, "train_mlm_acc_1": 0.2159323404045905, "train_mlm_acc_2": 0.21422101116903855, "train_loss_1": 3.601737081558954, "train_loss_2": 3.6161172255257714, "train_loss": 7.217854306691555, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0628305853933435, "epoch": 267, "n_parameters": 106143056}
{"train_lr": 3.1336583327541557e-05, "train_min_lr": 3.1336583327541557e-05, "train_mlm_acc_1": 0.21604972259324165, "train_mlm_acc_2": 0.2143288998092175, "train_loss_1": 3.6008763032045508, "train_loss_2": 3.6153262972359923, "train_loss": 7.2162026008599245, "train_loss_scale": 1268.0668425681617, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 268, "n_parameters": 106143056}
{"train_lr": 3.0015668720909095e-05, "train_min_lr": 3.0015668720909095e-05, "train_mlm_acc_1": 0.21629775978179228, "train_mlm_acc_2": 0.21462829873660413, "train_loss_1": 3.598510371899542, "train_loss_2": 3.6129359973294752, "train_loss": 7.211446369019327, "train_loss_scale": 958.2550571679859, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 269, "n_parameters": 106143056}
{"train_lr": 2.8735826327303497e-05, "train_min_lr": 2.8735826327303497e-05, "train_mlm_acc_1": 0.2163072763209083, "train_mlm_acc_2": 0.2146682086955222, "train_loss_1": 3.5979846401652855, "train_loss_2": 3.6124073925674645, "train_loss": 7.210392032313368, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0720121049000277, "epoch": 270, "n_parameters": 106143056}
{"train_lr": 2.7497206341904298e-05, "train_min_lr": 2.7497206341904298e-05, "train_mlm_acc_1": 0.21646753452528225, "train_mlm_acc_2": 0.21476028209573467, "train_loss_1": 3.597179457768077, "train_loss_2": 3.611609397379054, "train_loss": 7.20878885493744, "train_loss_scale": 701.1292875989446, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.098990508203666, "epoch": 271, "n_parameters": 106143056}
{"train_lr": 2.629995412225849e-05, "train_min_lr": 2.629995412225849e-05, "train_mlm_acc_1": 0.21669532457594298, "train_mlm_acc_2": 0.21498665230294645, "train_loss_1": 3.595895817485313, "train_loss_2": 3.6102539171696546, "train_loss": 7.206149729963133, "train_loss_scale": 702.9305189094107, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 272, "n_parameters": 106143056}
{"train_lr": 2.514421017122239e-05, "train_min_lr": 2.514421017122239e-05, "train_mlm_acc_1": 0.21665643388364486, "train_mlm_acc_2": 0.21496998967247358, "train_loss_1": 3.5949431053357053, "train_loss_2": 3.6092718007434534, "train_loss": 7.204214905214184, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1183885991206375, "epoch": 273, "n_parameters": 106143056}
{"train_lr": 2.4030110120472967e-05, "train_min_lr": 2.4030110120472967e-05, "train_mlm_acc_1": 0.21667752829900466, "train_mlm_acc_2": 0.21507153390081912, "train_loss_1": 3.594253147838403, "train_loss_2": 3.608502628987781, "train_loss": 7.202755778687191, "train_loss_scale": 956.4538258575197, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0737042292860797, "epoch": 274, "n_parameters": 106143056}
{"train_lr": 2.29577847145909e-05, "train_min_lr": 2.29577847145909e-05, "train_mlm_acc_1": 0.21682023066165632, "train_mlm_acc_2": 0.21513497753096655, "train_loss_1": 3.5936519609225246, "train_loss_2": 3.608030187842504, "train_loss": 7.20168215109784, "train_loss_scale": 1135.6763412489006, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9927338140516189, "epoch": 275, "n_parameters": 106143056}
{"train_lr": 2.1927359795716904e-05, "train_min_lr": 2.1927359795716904e-05, "train_mlm_acc_1": 0.21695579861666722, "train_mlm_acc_2": 0.21527414124953767, "train_loss_1": 3.5925949138565447, "train_loss_2": 3.606853117545446, "train_loss": 7.19944803061565, "train_loss_scale": 1578.779243623571, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 276, "n_parameters": 106143056}
{"train_lr": 2.093895628878402e-05, "train_min_lr": 2.093895628878402e-05, "train_mlm_acc_1": 0.21705731972822676, "train_mlm_acc_2": 0.21540327326426562, "train_loss_1": 3.591347785088297, "train_loss_2": 3.605699512815937, "train_loss": 7.197047296646088, "train_loss_scale": 526.8601583113457, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 277, "n_parameters": 106143056}
{"train_lr": 1.9992690187326e-05, "train_min_lr": 1.9992690187326e-05, "train_mlm_acc_1": 0.21728340358773973, "train_mlm_acc_2": 0.21553785614702087, "train_loss_1": 3.5896071984826627, "train_loss_2": 3.6040388927872806, "train_loss": 7.193646091532057, "train_loss_scale": 620.5241864555849, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1430613076152145, "epoch": 278, "n_parameters": 106143056}
{"train_lr": 1.9088672539865457e-05, "train_min_lr": 1.9088672539865457e-05, "train_mlm_acc_1": 0.21725439599231083, "train_mlm_acc_2": 0.21555968354519198, "train_loss_1": 3.5898474546357426, "train_loss_2": 3.6041290985458025, "train_loss": 7.193976556300697, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.207517521677042, "epoch": 279, "n_parameters": 106143056}
{"train_lr": 1.8227009436881574e-05, "train_min_lr": 1.8227009436881574e-05, "train_mlm_acc_1": 0.2175112968980742, "train_mlm_acc_2": 0.21576642503727655, "train_loss_1": 3.588525887005352, "train_loss_2": 3.60292723698897, "train_loss": 7.191453124885509, "train_loss_scale": 919.0782761653475, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 280, "n_parameters": 106143056}
{"train_lr": 1.7407801998359794e-05, "train_min_lr": 1.7407801998359794e-05, "train_mlm_acc_1": 0.21745711781589105, "train_mlm_acc_2": 0.21579439048356358, "train_loss_1": 3.5882637771788457, "train_loss_2": 3.6025135408343196, "train_loss": 7.190777315156127, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2439975308659, "epoch": 281, "n_parameters": 106143056}
{"train_lr": 1.6631146361925272e-05, "train_min_lr": 1.6631146361925272e-05, "train_mlm_acc_1": 0.21753278074879445, "train_mlm_acc_2": 0.21587753154848527, "train_loss_1": 3.5872923802312466, "train_loss_2": 3.6015136983956593, "train_loss": 7.188806080147165, "train_loss_scale": 821.3614775725594, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3357063433320877, "epoch": 282, "n_parameters": 106143056}
{"train_lr": 1.5897133671560495e-05, "train_min_lr": 1.5897133671560495e-05, "train_mlm_acc_1": 0.21766957391312275, "train_mlm_acc_2": 0.21604005717848515, "train_loss_1": 3.5862689248647412, "train_loss_2": 3.600579959919501, "train_loss": 7.18684888321156, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2818476622211588, "epoch": 283, "n_parameters": 106143056}
{"train_lr": 1.5205850066909038e-05, "train_min_lr": 1.5205850066909038e-05, "train_mlm_acc_1": 0.21773583470969055, "train_mlm_acc_2": 0.21607396632052872, "train_loss_1": 3.5856102320743215, "train_loss_2": 3.5999047552270644, "train_loss": 7.185514990184636, "train_loss_scale": 1795.8276165347406, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 284, "n_parameters": 106143056}
{"train_lr": 1.4557376673166934e-05, "train_min_lr": 1.4557376673166934e-05, "train_mlm_acc_1": 0.21778591386744509, "train_mlm_acc_2": 0.2161011876032189, "train_loss_1": 3.5857155352647405, "train_loss_2": 3.599995002085007, "train_loss": 7.185710535724644, "train_loss_scale": 697.5268249780123, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 285, "n_parameters": 106143056}
{"train_lr": 1.3951789591562158e-05, "train_min_lr": 1.3951789591562158e-05, "train_mlm_acc_1": 0.21784742223549383, "train_mlm_acc_2": 0.21616799804065032, "train_loss_1": 3.5847810525430748, "train_loss_2": 3.5989887237863365, "train_loss": 7.183769776093509, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.226574103666589, "epoch": 286, "n_parameters": 106143056}
{"train_lr": 1.3389159890423752e-05, "train_min_lr": 1.3389159890423752e-05, "train_mlm_acc_1": 0.2179384534882026, "train_mlm_acc_2": 0.21625768954856625, "train_loss_1": 3.5840551514791206, "train_loss_2": 3.5983172612905294, "train_loss": 7.182372411826041, "train_loss_scale": 961.8575197889182, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.4075811255261264, "epoch": 287, "n_parameters": 106143056}
{"train_lr": 1.2869553596841708e-05, "train_min_lr": 1.2869553596841708e-05, "train_mlm_acc_1": 0.2179803903654493, "train_mlm_acc_2": 0.21627042405864286, "train_loss_1": 3.584103958273311, "train_loss_2": 3.598151260520034, "train_loss": 7.182255218505021, "train_loss_scale": 1146.4837291116974, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.309183698426031, "epoch": 288, "n_parameters": 106143056}
{"train_lr": 1.2393031688918403e-05, "train_min_lr": 1.2393031688918403e-05, "train_mlm_acc_1": 0.21809781846822146, "train_mlm_acc_2": 0.2164135729908786, "train_loss_1": 3.582870349510783, "train_loss_2": 3.5971634738678038, "train_loss": 7.180033824636733, "train_loss_scale": 1442.7862796833774, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 289, "n_parameters": 106143056}
{"train_lr": 1.1959650088612536e-05, "train_min_lr": 1.1959650088612536e-05, "train_mlm_acc_1": 0.21809329489113316, "train_mlm_acc_2": 0.21640160579067264, "train_loss_1": 3.5828681228815094, "train_loss_2": 3.5972013561318814, "train_loss": 7.1800694788037, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.405471204453219, "epoch": 290, "n_parameters": 106143056}
{"train_lr": 1.1569459655176374e-05, "train_min_lr": 1.1569459655176374e-05, "train_mlm_acc_1": 0.2181140572330673, "train_mlm_acc_2": 0.21646689311842857, "train_loss_1": 3.5822992255368984, "train_loss_2": 3.596544632339226, "train_loss": 7.178843861100122, "train_loss_scale": 1390.5505716798593, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 291, "n_parameters": 106143056}
{"train_lr": 1.1222506179187317e-05, "train_min_lr": 1.1222506179187317e-05, "train_mlm_acc_1": 0.21820700103408847, "train_mlm_acc_2": 0.2165491522986871, "train_loss_1": 3.581731671682029, "train_loss_2": 3.596034733082185, "train_loss": 7.177766403558492, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3897646787193856, "epoch": 292, "n_parameters": 106143056}
{"train_lr": 1.0918830377174124e-05, "train_min_lr": 1.0918830377174124e-05, "train_mlm_acc_1": 0.2182132652899285, "train_mlm_acc_2": 0.21648796466109568, "train_loss_1": 3.581818690846233, "train_loss_2": 3.59607971403928, "train_loss": 7.177898403994326, "train_loss_scale": 570.5400175901495, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 293, "n_parameters": 106143056}
{"train_lr": 1.0658467886838543e-05, "train_min_lr": 1.0658467886838543e-05, "train_mlm_acc_1": 0.21825453802032385, "train_mlm_acc_2": 0.21658990974640416, "train_loss_1": 3.581029465272957, "train_loss_2": 3.595242654296947, "train_loss": 7.176272118835986, "train_loss_scale": 576.844327176781, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3760896800585556, "epoch": 294, "n_parameters": 106143056}
{"train_lr": 1.0441449262873223e-05, "train_min_lr": 1.0441449262873223e-05, "train_mlm_acc_1": 0.21831582869970703, "train_mlm_acc_2": 0.21671566322753852, "train_loss_1": 3.580569131865036, "train_loss_2": 3.594709648777753, "train_loss": 7.175278783001811, "train_loss_scale": 657.4494283201407, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 295, "n_parameters": 106143056}
{"train_lr": 1.0267799973375903e-05, "train_min_lr": 1.0267799973375903e-05, "train_mlm_acc_1": 0.2183397860498075, "train_mlm_acc_2": 0.21667100067300396, "train_loss_1": 3.5801192545901293, "train_loss_2": 3.594336000181859, "train_loss": 7.174455253933225, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3360095162504897, "epoch": 296, "n_parameters": 106143056}
{"train_lr": 1.0137540396860598e-05, "train_min_lr": 1.0137540396860598e-05, "train_mlm_acc_1": 0.21841818594071513, "train_mlm_acc_2": 0.2167412125412948, "train_loss_1": 3.580256140614772, "train_loss_2": 3.594405756514641, "train_loss": 7.174661897941965, "train_loss_scale": 1001.9349164467898, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.331909109755577, "epoch": 297, "n_parameters": 106143056}
{"train_lr": 1.0050685819866211e-05, "train_min_lr": 1.0050685819866211e-05, "train_mlm_acc_1": 0.2183869563849117, "train_mlm_acc_2": 0.21672380558176585, "train_loss_1": 3.5802671403452924, "train_loss_2": 3.594394076101174, "train_loss": 7.174661218490953, "train_loss_scale": 1170.8003518029902, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 298, "n_parameters": 106143056}
{"train_lr": 1.0007246435162376e-05, "train_min_lr": 1.0007246435162376e-05, "train_mlm_acc_1": 0.21849357392786362, "train_mlm_acc_2": 0.2168567050788994, "train_loss_1": 3.579384900780236, "train_loss_2": 3.5935431386728296, "train_loss": 7.172928040658788, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3719107414822673, "epoch": 299, "n_parameters": 106143056}
