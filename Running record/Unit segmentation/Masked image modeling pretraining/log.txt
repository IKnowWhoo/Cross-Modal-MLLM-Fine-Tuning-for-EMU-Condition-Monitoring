{"train_lr": 3.7470314011786434e-05, "train_min_lr": 3.7470314011786434e-05, "train_mlm_acc_1": 0.022340418010698124, "train_mlm_acc_2": 0.02255206095817915, "train_loss_1": 7.663832422663689, "train_loss_2": 7.656382680463497, "train_loss": 15.3202151080025, "train_loss_scale": 321.97009674582233, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 0, "n_parameters": 106143056}
{"train_lr": 0.00011247691089805615, "train_min_lr": 0.00011247691089805615, "train_mlm_acc_1": 0.05467732051361218, "train_mlm_acc_2": 0.05454834897633029, "train_loss_1": 6.340018115603515, "train_loss_2": 6.341589332832615, "train_loss": 12.68160744591984, "train_loss_scale": 313.41424802110816, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 5.235779305770928, "epoch": 1, "n_parameters": 106143056}
{"train_lr": 0.00018748350778432582, "train_min_lr": 0.00018748350778432582, "train_mlm_acc_1": 0.06577341838329441, "train_mlm_acc_2": 0.06551668925248512, "train_loss_1": 6.061663452847128, "train_loss_2": 6.067014017593682, "train_loss": 12.128677472275605, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 5.588426841385236, "epoch": 2, "n_parameters": 106143056}
{"train_lr": 0.0002624901046705954, "train_min_lr": 0.0002624901046705954, "train_mlm_acc_1": 0.07245268245868994, "train_mlm_acc_2": 0.07201021455233243, "train_loss_1": 5.893294840867622, "train_loss_2": 5.902611762101753, "train_loss": 11.795906609574638, "train_loss_scale": 750.2128408091469, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.522071787843394, "epoch": 3, "n_parameters": 106143056}
{"train_lr": 0.0003374967015568651, "train_min_lr": 0.0003374967015568651, "train_mlm_acc_1": 0.07754239687334055, "train_mlm_acc_2": 0.07695322995063444, "train_loss_1": 5.768062620437659, "train_loss_2": 5.780143777896358, "train_loss": 11.54820640242299, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.01241299240025, "epoch": 4, "n_parameters": 106143056}
{"train_lr": 0.0004125032984431348, "train_min_lr": 0.0004125032984431348, "train_mlm_acc_1": 0.08091977435895614, "train_mlm_acc_2": 0.08028538375863561, "train_loss_1": 5.6839691490170825, "train_loss_2": 5.697364303084351, "train_loss": 11.381333452101433, "train_loss_scale": 1747.1943711521549, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.4760745625382676, "epoch": 5, "n_parameters": 106143056}
{"train_lr": 0.00048750989532940465, "train_min_lr": 0.00048750989532940465, "train_mlm_acc_1": 0.08375698768696768, "train_mlm_acc_2": 0.08304850316361549, "train_loss_1": 5.618321799875459, "train_loss_2": 5.632530488512867, "train_loss": 11.25085229022312, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.006833538845535, "epoch": 6, "n_parameters": 106143056}
{"train_lr": 0.0005625164922156739, "train_min_lr": 0.0005625164922156739, "train_mlm_acc_1": 0.08560519020024789, "train_mlm_acc_2": 0.08485114999957508, "train_loss_1": 5.572782936071029, "train_loss_2": 5.587731712569033, "train_loss": 11.160514652152385, "train_loss_scale": 3987.9261213720315, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.7518783294011757, "epoch": 7, "n_parameters": 106143056}
{"train_lr": 0.0006375230891019436, "train_min_lr": 0.0006375230891019436, "train_mlm_acc_1": 0.08726575304143845, "train_mlm_acc_2": 0.08645803764832706, "train_loss_1": 5.5366583253693555, "train_loss_2": 5.552280793299042, "train_loss": 11.088939118091748, "train_loss_scale": 4866.927000879507, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3608503401436716, "epoch": 8, "n_parameters": 106143056}
{"train_lr": 0.0007125296859882135, "train_min_lr": 0.0007125296859882135, "train_mlm_acc_1": 0.08864588125894729, "train_mlm_acc_2": 0.08779325140861298, "train_loss_1": 5.5043394350124855, "train_loss_2": 5.52041812952716, "train_loss": 11.024757566426864, "train_loss_scale": 6938.343007915567, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 9, "n_parameters": 106143056}
{"train_lr": 0.0007499927726594455, "train_min_lr": 0.0007499927726594455, "train_mlm_acc_1": 0.09027855866240532, "train_mlm_acc_2": 0.08941288509388948, "train_loss_1": 5.471029259651087, "train_loss_2": 5.487699676000348, "train_loss": 10.958728938324995, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0262387059399614, "epoch": 10, "n_parameters": 106143056}
{"train_lr": 0.0007499493714617194, "train_min_lr": 0.0007499493714617194, "train_mlm_acc_1": 0.0926492436344202, "train_mlm_acc_2": 0.09170739189701166, "train_loss_1": 5.426834586218144, "train_loss_2": 5.444051131514362, "train_loss": 10.870885718990651, "train_loss_scale": 6336.731750219877, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5586923475630365, "epoch": 11, "n_parameters": 106143056}
{"train_lr": 0.0007498625550649799, "train_min_lr": 0.0007498625550649799, "train_mlm_acc_1": 0.09343792596568166, "train_mlm_acc_2": 0.09242582810254688, "train_loss_1": 5.412115439995403, "train_loss_2": 5.4298719404135865, "train_loss": 10.841987377840276, "train_loss_scale": 5270.402814423923, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 12, "n_parameters": 106143056}
{"train_lr": 0.000749732333657516, "train_min_lr": 0.000749732333657516, "train_mlm_acc_1": 0.09581800152219197, "train_mlm_acc_2": 0.09476629144077173, "train_loss_1": 5.366917834485322, "train_loss_2": 5.384952839624494, "train_loss": 10.751870671174142, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3884479042303175, "epoch": 13, "n_parameters": 106143056}
{"train_lr": 0.0007495587225213875, "train_min_lr": 0.0007495587225213875, "train_mlm_acc_1": 0.09710736178916698, "train_mlm_acc_2": 0.09602051728594271, "train_loss_1": 5.342685836233795, "train_loss_2": 5.361045925420108, "train_loss": 10.703731760500604, "train_loss_scale": 3506.9973614775727, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3810671381291948, "epoch": 14, "n_parameters": 106143056}
{"train_lr": 0.0007493417420306326, "train_min_lr": 0.0007493417420306326, "train_mlm_acc_1": 0.09832612094907589, "train_mlm_acc_2": 0.09718121517869, "train_loss_1": 5.322009547666803, "train_loss_2": 5.34073760982344, "train_loss": 10.662747156651479, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3237815319495758, "epoch": 15, "n_parameters": 106143056}
{"train_lr": 0.0007490814176488726, "train_min_lr": 0.0007490814176488726, "train_mlm_acc_1": 0.09934703678076165, "train_mlm_acc_2": 0.09823494076011284, "train_loss_1": 5.303335484120546, "train_loss_2": 5.322277649568694, "train_loss": 10.625613138564553, "train_loss_scale": 8001.069481090589, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3099438674951083, "epoch": 16, "n_parameters": 106143056}
{"train_lr": 0.0007487777799263258, "train_min_lr": 0.0007487777799263258, "train_mlm_acc_1": 0.10041889073302611, "train_mlm_acc_2": 0.09926079240895434, "train_loss_1": 5.285532905222977, "train_loss_2": 5.304743706393682, "train_loss": 10.590276613294186, "train_loss_scale": 9784.288478452067, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.244860614195348, "epoch": 17, "n_parameters": 106143056}
{"train_lr": 0.0007484308644962306, "train_min_lr": 0.0007484308644962306, "train_mlm_acc_1": 0.10041536358344838, "train_mlm_acc_2": 0.09923315890257885, "train_loss_1": 5.286469792994681, "train_loss_2": 5.306003739724792, "train_loss": 10.592473533767928, "train_loss_scale": 13365.136323658751, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 18, "n_parameters": 106143056}
{"train_lr": 0.000748040712070646, "train_min_lr": 0.000748040712070646, "train_mlm_acc_1": 0.10200297769581737, "train_mlm_acc_2": 0.10081495545647233, "train_loss_1": 5.257876628988546, "train_loss_2": 5.2775009256659, "train_loss": 10.535377555702901, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1183074904096262, "epoch": 19, "n_parameters": 106143056}
{"train_lr": 0.0007476073684356914, "train_min_lr": 0.0007476073684356914, "train_mlm_acc_1": 0.10269888798667735, "train_mlm_acc_2": 0.10147022290307645, "train_loss_1": 5.245054713444638, "train_loss_2": 5.264767298021123, "train_loss": 10.509822009001894, "train_loss_scale": 5954.870712401055, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1493968142158857, "epoch": 20, "n_parameters": 106143056}
{"train_lr": 0.0007471308844461622, "train_min_lr": 0.0007471308844461622, "train_mlm_acc_1": 0.10291335953804177, "train_mlm_acc_2": 0.10168832468594652, "train_loss_1": 5.240991624437515, "train_loss_2": 5.26093772465237, "train_loss": 10.501929344162148, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3434309419457495, "epoch": 21, "n_parameters": 106143056}
{"train_lr": 0.00074661131601957, "train_min_lr": 0.00074661131601957, "train_mlm_acc_1": 0.1039700168082548, "train_mlm_acc_2": 0.10272773532336127, "train_loss_1": 5.22326021736509, "train_loss_2": 5.243369132725943, "train_loss": 10.466629352817016, "train_loss_scale": 13883.890941073, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0777950027372718, "epoch": 22, "n_parameters": 106143056}
{"train_lr": 0.0007460487241295682, "train_min_lr": 0.0007460487241295682, "train_mlm_acc_1": 0.10458032402522016, "train_mlm_acc_2": 0.10332908718080876, "train_loss_1": 5.2139741914672815, "train_loss_2": 5.234211616119797, "train_loss": 10.448185806014397, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.112042919941502, "epoch": 23, "n_parameters": 106143056}
{"train_lr": 0.0007454431747988132, "train_min_lr": 0.0007454431747988132, "train_mlm_acc_1": 0.10504506583994774, "train_mlm_acc_2": 0.1037578127324817, "train_loss_1": 5.205116192132837, "train_loss_2": 5.2254759912545365, "train_loss": 10.430592182024382, "train_loss_scale": 17335.05013192612, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 24, "n_parameters": 106143056}
{"train_lr": 0.0007447947390912042, "train_min_lr": 0.0007447947390912042, "train_mlm_acc_1": 0.10554849225437972, "train_mlm_acc_2": 0.10426106732813747, "train_loss_1": 5.196755670777726, "train_loss_2": 5.217291945937231, "train_loss": 10.414047618759444, "train_loss_scale": 18329.32981530343, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.085384690352669, "epoch": 25, "n_parameters": 106143056}
{"train_lr": 0.0007441034931035458, "train_min_lr": 0.0007441034931035458, "train_mlm_acc_1": 0.10601397850874257, "train_mlm_acc_2": 0.10470095855530381, "train_loss_1": 5.189198125845104, "train_loss_2": 5.20978607592503, "train_loss": 10.398984205020344, "train_loss_scale": 16686.60686015831, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 26, "n_parameters": 106143056}
{"train_lr": 0.0007433695179566179, "train_min_lr": 0.0007433695179566179, "train_mlm_acc_1": 0.10596823952223847, "train_mlm_acc_2": 0.10464628706641148, "train_loss_1": 5.190594999383391, "train_loss_2": 5.211354291952799, "train_loss": 10.401949291493459, "train_loss_scale": 15159.162708883025, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 27, "n_parameters": 106143056}
{"train_lr": 0.0007425928997856612, "train_min_lr": 0.0007425928997856612, "train_mlm_acc_1": 0.10679344199319339, "train_mlm_acc_2": 0.1054950232610185, "train_loss_1": 5.174961752711206, "train_loss_2": 5.19565973013456, "train_loss": 10.370621473199984, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0258994636141425, "epoch": 28, "n_parameters": 106143056}
{"train_lr": 0.0007417737297302581, "train_min_lr": 0.0007417737297302581, "train_mlm_acc_1": 0.10712068064896785, "train_mlm_acc_2": 0.1057927044708095, "train_loss_1": 5.169764734771866, "train_loss_2": 5.190563445460303, "train_loss": 10.36032817640531, "train_loss_scale": 5717.108179419525, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.040156673735029, "epoch": 29, "n_parameters": 106143056}
{"train_lr": 0.0007409121039236501, "train_min_lr": 0.0007409121039236501, "train_mlm_acc_1": 0.10753024708997318, "train_mlm_acc_2": 0.106221590355766, "train_loss_1": 5.162934975657635, "train_loss_2": 5.183813146152513, "train_loss": 10.346748121914993, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0478140770497821, "epoch": 30, "n_parameters": 106143056}
{"train_lr": 0.000740008123481444, "train_min_lr": 0.000740008123481444, "train_mlm_acc_1": 0.1078256379899781, "train_mlm_acc_2": 0.10646368396077747, "train_loss_1": 5.157963643183075, "train_loss_2": 5.179082235853821, "train_loss": 10.337045881343496, "train_loss_scale": 13408.36587510994, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0618105635060064, "epoch": 31, "n_parameters": 106143056}
{"train_lr": 0.0007390618944897517, "train_min_lr": 0.0007390618944897517, "train_mlm_acc_1": 0.10825705472560126, "train_mlm_acc_2": 0.10687723572848393, "train_loss_1": 5.15199082408333, "train_loss_2": 5.173017067770845, "train_loss": 10.325007890543606, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0567238384836477, "epoch": 32, "n_parameters": 106143056}
{"train_lr": 0.0007380735279927422, "train_min_lr": 0.0007380735279927422, "train_mlm_acc_1": 0.10847025511175289, "train_mlm_acc_2": 0.10711538982589909, "train_loss_1": 5.147218995851284, "train_loss_2": 5.168256590318134, "train_loss": 10.315475582237713, "train_loss_scale": 16499.278803869835, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 33, "n_parameters": 106143056}
{"train_lr": 0.0007370431399796046, "train_min_lr": 0.0007370431399796046, "train_mlm_acc_1": 0.10873501204534146, "train_mlm_acc_2": 0.10733895425061411, "train_loss_1": 5.142193486109678, "train_loss_2": 5.16338875829492, "train_loss": 10.305582245505475, "train_loss_scale": 17176.5417766051, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 34, "n_parameters": 106143056}
{"train_lr": 0.0007359708513709434, "train_min_lr": 0.0007359708513709434, "train_mlm_acc_1": 0.10858104099734975, "train_mlm_acc_2": 0.1072062493753255, "train_loss_1": 5.145451743978099, "train_loss_2": 5.1666905164404096, "train_loss": 10.312142264245368, "train_loss_scale": 8826.03342128408, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 35, "n_parameters": 106143056}
{"train_lr": 0.000734856788004579, "train_min_lr": 0.000734856788004579, "train_mlm_acc_1": 0.10934029187246987, "train_mlm_acc_2": 0.10792534983747212, "train_loss_1": 5.132898303638347, "train_loss_2": 5.153993261573392, "train_loss": 10.286891577216545, "train_loss_scale": 9532.116094986808, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0061003661197638, "epoch": 36, "n_parameters": 106143056}
{"train_lr": 0.0007337010806207864, "train_min_lr": 0.0007337010806207864, "train_mlm_acc_1": 0.10955311437919671, "train_mlm_acc_2": 0.10814720787035863, "train_loss_1": 5.129558059345134, "train_loss_2": 5.15090833233445, "train_loss": 10.280466388796334, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0265039605012356, "epoch": 37, "n_parameters": 106143056}
{"train_lr": 0.0007325038648469556, "train_min_lr": 0.0007325038648469556, "train_mlm_acc_1": 0.10932258718213757, "train_mlm_acc_2": 0.10788824556931106, "train_loss_1": 5.133631462314828, "train_loss_2": 5.1549380062018555, "train_loss": 10.288569467048847, "train_loss_scale": 10937.076517150395, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 38, "n_parameters": 106143056}
{"train_lr": 0.000731265281181661, "train_min_lr": 0.000731265281181661, "train_mlm_acc_1": 0.10998241251568812, "train_mlm_acc_2": 0.10859613462778016, "train_loss_1": 5.122127400172207, "train_loss_2": 5.143448323876373, "train_loss": 10.26557572189925, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9887921450530214, "epoch": 39, "n_parameters": 106143056}
{"train_lr": 0.0007299854749781874, "train_min_lr": 0.0007299854749781874, "train_mlm_acc_1": 0.11032750470221384, "train_mlm_acc_2": 0.10891721210636611, "train_loss_1": 5.117928479204287, "train_loss_2": 5.139507368403563, "train_loss": 10.257435849390223, "train_loss_scale": 5407.2963940193495, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.019950986380313, "epoch": 40, "n_parameters": 106143056}
{"train_lr": 0.0007286645964274694, "train_min_lr": 0.0007286645964274694, "train_mlm_acc_1": 0.11045656780070948, "train_mlm_acc_2": 0.10906455252096778, "train_loss_1": 5.114776314930006, "train_loss_2": 5.136305012038222, "train_loss": 10.251081329117559, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0337273544560637, "epoch": 41, "n_parameters": 106143056}
{"train_lr": 0.0007273028005404614, "train_min_lr": 0.0007273028005404614, "train_mlm_acc_1": 0.1106113290615714, "train_mlm_acc_2": 0.10920005163919957, "train_loss_1": 5.111636240752832, "train_loss_2": 5.133125836427734, "train_loss": 10.244762076446648, "train_loss_scale": 12788.742304309586, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0399754025900478, "epoch": 42, "n_parameters": 106143056}
{"train_lr": 0.0007259002471299484, "train_min_lr": 0.0007259002471299484, "train_mlm_acc_1": 0.11071944663345341, "train_mlm_acc_2": 0.10933405057287127, "train_loss_1": 5.108981553566697, "train_loss_2": 5.130550654131588, "train_loss": 10.239532219388554, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0399739905837972, "epoch": 43, "n_parameters": 106143056}
{"train_lr": 0.0007244571007917912, "train_min_lr": 0.0007244571007917912, "train_mlm_acc_1": 0.11097089648934813, "train_mlm_acc_2": 0.10952045348544155, "train_loss_1": 5.106451861462052, "train_loss_2": 5.1280590669565695, "train_loss": 10.234510927317745, "train_loss_scale": 18732.805628847844, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 44, "n_parameters": 106143056}
{"train_lr": 0.0007229735308856102, "train_min_lr": 0.0007229735308856102, "train_mlm_acc_1": 0.11123080925545807, "train_mlm_acc_2": 0.10980759895256767, "train_loss_1": 5.1021556270258825, "train_loss_2": 5.123876939086193, "train_loss": 10.22603256218037, "train_loss_scale": 11780.052770448548, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 45, "n_parameters": 106143056}
{"train_lr": 0.0007214497115149132, "train_min_lr": 0.0007214497115149132, "train_mlm_acc_1": 0.11141274594304561, "train_mlm_acc_2": 0.11000610654067867, "train_loss_1": 5.09972175717249, "train_loss_2": 5.121439094855896, "train_loss": 10.221160852814727, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0195411010698572, "epoch": 46, "n_parameters": 106143056}
{"train_lr": 0.0007198858215066601, "train_min_lr": 0.0007198858215066601, "train_mlm_acc_1": 0.11158717011749456, "train_mlm_acc_2": 0.11014291114790616, "train_loss_1": 5.096486106921207, "train_loss_2": 5.118136414804265, "train_loss": 10.214622519156759, "train_loss_scale": 14770.09674582234, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.047194489650592, "epoch": 47, "n_parameters": 106143056}
{"train_lr": 0.0007182820443902745, "train_min_lr": 0.0007182820443902745, "train_mlm_acc_1": 0.11177543972650823, "train_mlm_acc_2": 0.11034552999112751, "train_loss_1": 5.093676305068829, "train_loss_2": 5.115412339633666, "train_loss": 10.209088639617491, "train_loss_scale": 17104.492524186455, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0216916836241199, "epoch": 48, "n_parameters": 106143056}
{"train_lr": 0.0007166385683761166, "train_min_lr": 0.0007166385683761166, "train_mlm_acc_1": 0.11192922753985503, "train_mlm_acc_2": 0.11048286141812959, "train_loss_1": 5.090880269425526, "train_loss_2": 5.1125664255445, "train_loss": 10.203446694917604, "train_loss_scale": 8970.131926121372, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 49, "n_parameters": 106143056}
{"train_lr": 0.0007149555863333774, "train_min_lr": 0.0007149555863333774, "train_mlm_acc_1": 0.11211692447476777, "train_mlm_acc_2": 0.1106220022427113, "train_loss_1": 5.088087785527071, "train_loss_2": 5.109896730883874, "train_loss": 10.197984511535632, "train_loss_scale": 9517.706244503079, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0251950519380595, "epoch": 50, "n_parameters": 106143056}
{"train_lr": 0.0007132332957674665, "train_min_lr": 0.0007132332957674665, "train_mlm_acc_1": 0.11222619872880983, "train_mlm_acc_2": 0.11080654997136133, "train_loss_1": 5.085356658398319, "train_loss_2": 5.10714016420965, "train_loss": 10.192496821978896, "train_loss_scale": 9661.80474934037, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 51, "n_parameters": 106143056}
{"train_lr": 0.0007114718987968146, "train_min_lr": 0.0007114718987968146, "train_mlm_acc_1": 0.11188277853988668, "train_mlm_acc_2": 0.1103877990261677, "train_loss_1": 5.090878103475562, "train_loss_2": 5.112713147488831, "train_loss": 10.203591248185989, "train_loss_scale": 6531.26473175022, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 52, "n_parameters": 106143056}
{"train_lr": 0.0007096716021291684, "train_min_lr": 0.0007096716021291684, "train_mlm_acc_1": 0.11247936635963757, "train_mlm_acc_2": 0.11106648562900336, "train_loss_1": 5.0805601914828555, "train_loss_2": 5.10242440423739, "train_loss": 10.182984594619368, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 0.9663514993960332, "epoch": 53, "n_parameters": 106143056}
{"train_lr": 0.0007078326170373227, "train_min_lr": 0.0007078326170373227, "train_mlm_acc_1": 0.11271314585799304, "train_mlm_acc_2": 0.1112417344138249, "train_loss_1": 5.077942214152639, "train_loss_2": 5.099785358473829, "train_loss": 10.177727573779768, "train_loss_scale": 6743.810026385224, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.032442168751199, "epoch": 54, "n_parameters": 106143056}
{"train_lr": 0.000705955159334333, "train_min_lr": 0.000705955159334333, "train_mlm_acc_1": 0.11262189693709634, "train_mlm_acc_2": 0.1111585132871069, "train_loss_1": 5.0775833460670246, "train_loss_2": 5.099535976152412, "train_loss": 10.177119323739696, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0096041645097857, "epoch": 55, "n_parameters": 106143056}
{"train_lr": 0.0007040394493481837, "train_min_lr": 0.0007040394493481837, "train_mlm_acc_1": 0.11289341046770571, "train_mlm_acc_2": 0.11147346399255956, "train_loss_1": 5.074782788229283, "train_loss_2": 5.096689976352081, "train_loss": 10.171472765420127, "train_loss_scale": 15281.646437994723, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 56, "n_parameters": 106143056}
{"train_lr": 0.0007020857118959358, "train_min_lr": 0.0007020857118959358, "train_mlm_acc_1": 0.11305011864243732, "train_mlm_acc_2": 0.11159139585320034, "train_loss_1": 5.07299310902073, "train_loss_2": 5.094966409021862, "train_loss": 10.16795952202672, "train_loss_scale": 5133.509234828496, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 57, "n_parameters": 106143056}
{"train_lr": 0.0007000941762573423, "train_min_lr": 0.0007000941762573423, "train_mlm_acc_1": 0.11317626154009276, "train_mlm_acc_2": 0.11171389711822531, "train_loss_1": 5.070483080892052, "train_loss_2": 5.092483238892903, "train_loss": 10.162966315958096, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0436698401194449, "epoch": 58, "n_parameters": 106143056}
{"train_lr": 0.0006980650761479382, "train_min_lr": 0.0006980650761479382, "train_mlm_acc_1": 0.11338167463117194, "train_mlm_acc_2": 0.11190563656402819, "train_loss_1": 5.067073952029856, "train_loss_2": 5.089001274517784, "train_loss": 10.156075222930472, "train_loss_scale": 8141.565523306948, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0612577009641402, "epoch": 59, "n_parameters": 106143056}
{"train_lr": 0.0006959986496916213, "train_min_lr": 0.0006959986496916213, "train_mlm_acc_1": 0.1134851656210336, "train_mlm_acc_2": 0.11199059839570925, "train_loss_1": 5.065250383832524, "train_loss_2": 5.087211676249928, "train_loss": 10.152462064328693, "train_loss_scale": 6859.0888302550575, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 60, "n_parameters": 106143056}
{"train_lr": 0.0006938951393926957, "train_min_lr": 0.0006938951393926957, "train_mlm_acc_1": 0.11355168983608929, "train_mlm_acc_2": 0.112079556929824, "train_loss_1": 5.063553723464855, "train_loss_2": 5.085622017595363, "train_loss": 10.149175745096768, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0492371113654702, "epoch": 61, "n_parameters": 106143056}
{"train_lr": 0.0006917547921074234, "train_min_lr": 0.0006917547921074234, "train_mlm_acc_1": 0.11386266672818306, "train_mlm_acc_2": 0.11235648723320811, "train_loss_1": 5.061105863767018, "train_loss_2": 5.083198474600531, "train_loss": 10.14430433936358, "train_loss_scale": 6415.985927880387, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0399219775367643, "epoch": 62, "n_parameters": 106143056}
{"train_lr": 0.0006895778590150455, "train_min_lr": 0.0006895778590150455, "train_mlm_acc_1": 0.11384776775891464, "train_mlm_acc_2": 0.11232413559260868, "train_loss_1": 5.060126903084358, "train_loss_2": 5.08212149373879, "train_loss": 10.142248405944704, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0444324733189774, "epoch": 63, "n_parameters": 106143056}
{"train_lr": 0.0006873645955883147, "train_min_lr": 0.0006873645955883147, "train_mlm_acc_1": 0.11387383233650981, "train_mlm_acc_2": 0.11238021562457504, "train_loss_1": 5.058318976728981, "train_loss_2": 5.0804024629144156, "train_loss": 10.138721435344733, "train_loss_scale": 14806.121372031663, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0425479379052538, "epoch": 64, "n_parameters": 106143056}
{"train_lr": 0.0006851152615635071, "train_min_lr": 0.0006851152615635071, "train_mlm_acc_1": 0.1141214687131483, "train_mlm_acc_2": 0.11263318854181806, "train_loss_1": 5.0555728830678905, "train_loss_2": 5.077665180570742, "train_loss": 10.133238063533787, "train_loss_scale": 10454.34652594547, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 65, "n_parameters": 106143056}
{"train_lr": 0.0006828301209099406, "train_min_lr": 0.0006828301209099406, "train_mlm_acc_1": 0.11362082507336806, "train_mlm_acc_2": 0.11211313392226514, "train_loss_1": 5.064101335608131, "train_loss_2": 5.086220780274484, "train_loss": 10.150322118556174, "train_loss_scale": 3017.062445030783, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 66, "n_parameters": 106143056}
{"train_lr": 0.0006805094417990081, "train_min_lr": 0.0006805094417990081, "train_mlm_acc_1": 0.11433983386126441, "train_mlm_acc_2": 0.11286347524140918, "train_loss_1": 5.051881466870153, "train_loss_2": 5.073994021250055, "train_loss": 10.125875486232989, "train_loss_scale": 2217.315743183817, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.017907606894863, "epoch": 67, "n_parameters": 106143056}
{"train_lr": 0.0006781534965726882, "train_min_lr": 0.0006781534965726882, "train_mlm_acc_1": 0.1144145233204413, "train_mlm_acc_2": 0.11291242075106006, "train_loss_1": 5.049869262972943, "train_loss_2": 5.07211785161296, "train_loss": 10.121987115948894, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0670014249722792, "epoch": 68, "n_parameters": 106143056}
{"train_lr": 0.0006757625617116008, "train_min_lr": 0.0006757625617116008, "train_mlm_acc_1": 0.11445027620432507, "train_mlm_acc_2": 0.11295623577174484, "train_loss_1": 5.049288476310283, "train_loss_2": 5.0714024467854095, "train_loss": 10.12069092094636, "train_loss_scale": 5421.706244503078, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.053844341502026, "epoch": 69, "n_parameters": 106143056}
{"train_lr": 0.0006733369178025507, "train_min_lr": 0.0006733369178025507, "train_mlm_acc_1": 0.11461322558036266, "train_mlm_acc_2": 0.11308717701613588, "train_loss_1": 5.046950338593469, "train_loss_2": 5.069237067705723, "train_loss": 10.116187409234865, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0645543627814442, "epoch": 70, "n_parameters": 106143056}
{"train_lr": 0.000670876849505609, "train_min_lr": 0.000670876849505609, "train_mlm_acc_1": 0.11467033627352095, "train_mlm_acc_2": 0.11319594739190088, "train_loss_1": 5.045674920553897, "train_loss_2": 5.067779035922615, "train_loss": 10.113453954274757, "train_loss_scale": 8674.729991204926, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 71, "n_parameters": 106143056}
{"train_lr": 0.000668382645520696, "train_min_lr": 0.000668382645520696, "train_mlm_acc_1": 0.11487978049402396, "train_mlm_acc_2": 0.11333566079802464, "train_loss_1": 5.04361488537088, "train_loss_2": 5.06585815514822, "train_loss": 10.109473038998841, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.049301058971368, "epoch": 72, "n_parameters": 106143056}
{"train_lr": 0.0006658545985537059, "train_min_lr": 0.0006658545985537059, "train_mlm_acc_1": 0.11500099902643299, "train_mlm_acc_2": 0.11346641882169556, "train_loss_1": 5.041513192936739, "train_loss_2": 5.0637328212158454, "train_loss": 10.105246012108097, "train_loss_scale": 14308.981530343008, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0578743102997148, "epoch": 73, "n_parameters": 106143056}
{"train_lr": 0.0006632930052821623, "train_min_lr": 0.0006632930052821623, "train_mlm_acc_1": 0.11512706180495474, "train_mlm_acc_2": 0.113560977309169, "train_loss_1": 5.040042374043897, "train_loss_2": 5.062411485582249, "train_loss": 10.102453866021719, "train_loss_scale": 8602.68073878628, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 74, "n_parameters": 106143056}
{"train_lr": 0.0006606981663203897, "train_min_lr": 0.0006606981663203897, "train_mlm_acc_1": 0.1152360382675797, "train_mlm_acc_2": 0.11374297123418739, "train_loss_1": 5.037972429863905, "train_loss_2": 5.060240628641744, "train_loss": 10.098213061703436, "train_loss_scale": 9078.205804749341, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 75, "n_parameters": 106143056}
{"train_lr": 0.0006580703861842497, "train_min_lr": 0.0006580703861842497, "train_mlm_acc_1": 0.1152620226482262, "train_mlm_acc_2": 0.11373708498145707, "train_loss_1": 5.036557953716268, "train_loss_2": 5.058779329402256, "train_loss": 10.095337278400478, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0775823859971347, "epoch": 76, "n_parameters": 106143056}
{"train_lr": 0.0006554099732553881, "train_min_lr": 0.0006554099732553881, "train_mlm_acc_1": 0.1151671550280055, "train_mlm_acc_2": 0.1136313951676654, "train_loss_1": 5.037414870350216, "train_loss_2": 5.059866145973994, "train_loss": 10.097281017110552, "train_loss_scale": 10843.412489006156, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1665914496939331, "epoch": 77, "n_parameters": 106143056}
{"train_lr": 0.0006527172397450622, "train_min_lr": 0.0006527172397450622, "train_mlm_acc_1": 0.11557951571768774, "train_mlm_acc_2": 0.11407148103551609, "train_loss_1": 5.032184399631638, "train_loss_2": 5.054437817610872, "train_loss": 10.086622222327515, "train_loss_scale": 9265.533861037818, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 78, "n_parameters": 106143056}
{"train_lr": 0.0006499925016574828, "train_min_lr": 0.0006499925016574828, "train_mlm_acc_1": 0.1156899809072297, "train_mlm_acc_2": 0.11412877498625425, "train_loss_1": 5.031058218988705, "train_loss_2": 5.053399535261337, "train_loss": 10.08445775613726, "train_loss_scale": 5749.530343007916, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 79, "n_parameters": 106143056}
{"train_lr": 0.0006472360787527486, "train_min_lr": 0.0006472360787527486, "train_mlm_acc_1": 0.11569988688252532, "train_mlm_acc_2": 0.11417919777500835, "train_loss_1": 5.029727308081238, "train_loss_2": 5.0522348499654575, "train_loss": 10.081962156840973, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.079731942690981, "epoch": 80, "n_parameters": 106143056}
{"train_lr": 0.000644448294509309, "train_min_lr": 0.000644448294509309, "train_mlm_acc_1": 0.11581477252627242, "train_mlm_acc_2": 0.11431435335889498, "train_loss_1": 5.028146120415724, "train_loss_2": 5.050535051206171, "train_loss": 10.078681175501178, "train_loss_scale": 6714.990325417766, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 81, "n_parameters": 106143056}
{"train_lr": 0.0006416294760860044, "train_min_lr": 0.0006416294760860044, "train_mlm_acc_1": 0.11598699796034012, "train_mlm_acc_2": 0.11444910811530647, "train_loss_1": 5.026312860723326, "train_loss_2": 5.048839427026197, "train_loss": 10.075152288955245, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.073858623611581, "epoch": 82, "n_parameters": 106143056}
{"train_lr": 0.0006387799542836763, "train_min_lr": 0.0006387799542836763, "train_mlm_acc_1": 0.11609068360644914, "train_mlm_acc_2": 0.11456323794941946, "train_loss_1": 5.024022834334545, "train_loss_2": 5.046465272691655, "train_loss": 10.070488102413, "train_loss_scale": 5893.628847845207, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0863365149330233, "epoch": 83, "n_parameters": 106143056}
{"train_lr": 0.0006359000635063394, "train_min_lr": 0.0006359000635063394, "train_mlm_acc_1": 0.1162638595522682, "train_mlm_acc_2": 0.11469147653583513, "train_loss_1": 5.02245375427533, "train_loss_2": 5.045052976805386, "train_loss": 10.067506731133138, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1103413377084959, "epoch": 84, "n_parameters": 106143056}
{"train_lr": 0.0006329901417219492, "train_min_lr": 0.0006329901417219492, "train_mlm_acc_1": 0.1161997860720219, "train_mlm_acc_2": 0.1146570978745189, "train_loss_1": 5.021455993910264, "train_loss_2": 5.043852059539201, "train_loss": 10.065308056280292, "train_loss_scale": 9496.091468777484, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 85, "n_parameters": 106143056}
{"train_lr": 0.0006300505304227264, "train_min_lr": 0.0006300505304227264, "train_mlm_acc_1": 0.11641371941886901, "train_mlm_acc_2": 0.11487357353377127, "train_loss_1": 5.019605384286077, "train_loss_2": 5.042098910900827, "train_loss": 10.06170429204154, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1094848742690544, "epoch": 86, "n_parameters": 106143056}
{"train_lr": 0.0006270815745850904, "train_min_lr": 0.0006270815745850904, "train_mlm_acc_1": 0.11659412150473555, "train_mlm_acc_2": 0.11499358967631373, "train_loss_1": 5.017628188969907, "train_loss_2": 5.040096261203551, "train_loss": 10.057724450278304, "train_loss_scale": 12738.307827616534, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 87, "n_parameters": 106143056}
{"train_lr": 0.0006240836226291734, "train_min_lr": 0.0006240836226291734, "train_mlm_acc_1": 0.11657274076543099, "train_mlm_acc_2": 0.11500962237559632, "train_loss_1": 5.017041810007607, "train_loss_2": 5.039546869256146, "train_loss": 10.056588678582258, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1174970246137184, "epoch": 88, "n_parameters": 106143056}
{"train_lr": 0.0006210570263779273, "train_min_lr": 0.0006210570263779273, "train_mlm_acc_1": 0.11676135388339756, "train_mlm_acc_2": 0.11519940357193312, "train_loss_1": 5.014033337014751, "train_loss_2": 5.036430380746998, "train_loss": 10.050463711890403, "train_loss_scale": 11859.306948109059, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0964701306746525, "epoch": 89, "n_parameters": 106143056}
{"train_lr": 0.0006180021410158472, "train_min_lr": 0.0006180021410158472, "train_mlm_acc_1": 0.1168155443347604, "train_mlm_acc_2": 0.11524218796419017, "train_loss_1": 5.012943002510825, "train_loss_2": 5.03545556644022, "train_loss": 10.048398570628573, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0884240281718178, "epoch": 90, "n_parameters": 106143056}
{"train_lr": 0.0006149193250472682, "train_min_lr": 0.0006149193250472682, "train_mlm_acc_1": 0.11690545338799845, "train_mlm_acc_2": 0.11535990229261452, "train_loss_1": 5.011320904775366, "train_loss_2": 5.033815519214201, "train_loss": 10.045136422469307, "train_loss_scale": 17565.607739665786, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 91, "n_parameters": 106143056}
{"train_lr": 0.0006118089402543174, "train_min_lr": 0.0006118089402543174, "train_mlm_acc_1": 0.11699654194284738, "train_mlm_acc_2": 0.11542849924592277, "train_loss_1": 5.010394645502616, "train_loss_2": 5.032933368898843, "train_loss": 10.043328018595277, "train_loss_scale": 8051.503957783641, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 92, "n_parameters": 106143056}
{"train_lr": 0.0006086713516544388, "train_min_lr": 0.0006086713516544388, "train_mlm_acc_1": 0.11713300308944918, "train_mlm_acc_2": 0.11560064449287105, "train_loss_1": 5.008686622403228, "train_loss_2": 5.031304917318735, "train_loss": 10.03999153699598, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.105104285630618, "epoch": 93, "n_parameters": 106143056}
{"train_lr": 0.000605506927457566, "train_min_lr": 0.000605506927457566, "train_mlm_acc_1": 0.1172404449921275, "train_mlm_acc_2": 0.11568538872598816, "train_loss_1": 5.006039720149866, "train_loss_2": 5.028601273907416, "train_loss": 10.034640995472696, "train_loss_scale": 5864.809146877748, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1000549314623878, "epoch": 94, "n_parameters": 106143056}
{"train_lr": 0.0006023160390229106, "train_min_lr": 0.0006023160390229106, "train_mlm_acc_1": 0.11733641210048998, "train_mlm_acc_2": 0.11577011007084957, "train_loss_1": 5.004806765360904, "train_loss_2": 5.027291189974195, "train_loss": 10.032097959161957, "train_loss_scale": 7943.4300791556725, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 95, "n_parameters": 106143056}
{"train_lr": 0.0005990990608153761, "train_min_lr": 0.0005990990608153761, "train_mlm_acc_1": 0.11736564882174987, "train_mlm_acc_2": 0.11580672181025475, "train_loss_1": 5.003877000789844, "train_loss_2": 5.026325023740451, "train_loss": 10.030202018973485, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.103737123146745, "epoch": 96, "n_parameters": 106143056}
{"train_lr": 0.000595856370361619, "train_min_lr": 0.000595856370361619, "train_mlm_acc_1": 0.11749404777339419, "train_mlm_acc_2": 0.11594068640048502, "train_loss_1": 5.002164013572398, "train_loss_2": 5.024749322428238, "train_loss": 10.02691333474249, "train_loss_scale": 5331.644678979771, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1369221927622692, "epoch": 97, "n_parameters": 106143056}
{"train_lr": 0.0005925883482057425, "train_min_lr": 0.0005925883482057425, "train_mlm_acc_1": 0.11764417095527564, "train_mlm_acc_2": 0.11608556461935779, "train_loss_1": 4.999949053912805, "train_loss_2": 5.022686645192018, "train_loss": 10.022635699576627, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1210280148838314, "epoch": 98, "n_parameters": 106143056}
{"train_lr": 0.0005892953778646349, "train_min_lr": 0.0005892953778646349, "train_mlm_acc_1": 0.11779777558148563, "train_mlm_acc_2": 0.11620303845686696, "train_loss_1": 4.998887338130854, "train_loss_2": 5.021569246195237, "train_loss": 10.020456583854287, "train_loss_scale": 10144.534740545294, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 99, "n_parameters": 106143056}
{"train_lr": 0.0005859778457829658, "train_min_lr": 0.0005859778457829658, "train_mlm_acc_1": 0.11784209458119742, "train_mlm_acc_2": 0.11625649602534929, "train_loss_1": 4.996849798223065, "train_loss_2": 5.019365747979364, "train_loss": 10.016215545206396, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.139710782595444, "epoch": 100, "n_parameters": 106143056}
{"train_lr": 0.0005826361412878357, "train_min_lr": 0.0005826361412878357, "train_mlm_acc_1": 0.11784956118185319, "train_mlm_acc_2": 0.116306563766416, "train_loss_1": 4.997296837409967, "train_loss_2": 5.019868340425147, "train_loss": 10.01716518003687, "train_loss_scale": 4485.065963060686, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 101, "n_parameters": 106143056}
{"train_lr": 0.0005792706565430835, "train_min_lr": 0.0005792706565430835, "train_mlm_acc_1": 0.11811276063775167, "train_mlm_acc_2": 0.11655299769912698, "train_loss_1": 4.993425383049874, "train_loss_2": 5.016018991053052, "train_loss": 10.009444369175188, "train_loss_scale": 4694.008795074758, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1400692167781168, "epoch": 102, "n_parameters": 106143056}
{"train_lr": 0.0005758817865032646, "train_min_lr": 0.0005758817865032646, "train_mlm_acc_1": 0.11809799913972249, "train_mlm_acc_2": 0.11652937235119003, "train_loss_1": 4.993054681790955, "train_loss_2": 5.015790653732018, "train_loss": 10.008845337881995, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1488708680726607, "epoch": 103, "n_parameters": 106143056}
{"train_lr": 0.0005724699288673034, "train_min_lr": 0.0005724699288673034, "train_mlm_acc_1": 0.11820296743817515, "train_mlm_acc_2": 0.11660403886886941, "train_loss_1": 4.991302849277657, "train_loss_2": 5.013977465916854, "train_loss": 10.005280316138121, "train_loss_scale": 6289.899736147757, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 104, "n_parameters": 106143056}
{"train_lr": 0.0005690354840318202, "train_min_lr": 0.0005690354840318202, "train_mlm_acc_1": 0.1184269441152442, "train_mlm_acc_2": 0.11681888835126225, "train_loss_1": 4.989206476649802, "train_loss_2": 5.011946391094748, "train_loss": 10.001152873144092, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1414636716364557, "epoch": 105, "n_parameters": 106143056}
{"train_lr": 0.0005655788550441483, "train_min_lr": 0.0005655788550441483, "train_mlm_acc_1": 0.11850170219905196, "train_mlm_acc_2": 0.11691825660461644, "train_loss_1": 4.987449781718543, "train_loss_2": 5.010185797537432, "train_loss": 9.997635580304431, "train_loss_scale": 6985.175021987687, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1688122793363707, "epoch": 106, "n_parameters": 106143056}
{"train_lr": 0.0005621004475550199, "train_min_lr": 0.0005621004475550199, "train_mlm_acc_1": 0.11862471880081618, "train_mlm_acc_2": 0.11706720035451094, "train_loss_1": 4.985994885076844, "train_loss_2": 5.008682107862508, "train_loss": 9.99467699540322, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1614120032248418, "epoch": 107, "n_parameters": 106143056}
{"train_lr": 0.0005586006697709787, "train_min_lr": 0.0005586006697709787, "train_mlm_acc_1": 0.11874739173308291, "train_mlm_acc_2": 0.11711693601068453, "train_loss_1": 4.9843312050547635, "train_loss_2": 5.007181066112133, "train_loss": 9.991512270695091, "train_loss_scale": 11304.527704485488, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 108, "n_parameters": 106143056}
{"train_lr": 0.0005550799324064666, "train_min_lr": 0.0005550799324064666, "train_mlm_acc_1": 0.11873532140507914, "train_mlm_acc_2": 0.1171329000157123, "train_loss_1": 4.98359241444706, "train_loss_2": 5.006316827857505, "train_loss": 9.989909244191782, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1760311909904582, "epoch": 109, "n_parameters": 106143056}
{"train_lr": 0.0005515386486356223, "train_min_lr": 0.0005515386486356223, "train_mlm_acc_1": 0.11891091367264221, "train_mlm_acc_2": 0.11729972009860772, "train_loss_1": 4.9816997979121345, "train_loss_2": 5.0045387866000075, "train_loss": 9.986238587709929, "train_loss_scale": 14806.121372031663, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1914032730703932, "epoch": 110, "n_parameters": 106143056}
{"train_lr": 0.0005479772340437942, "train_min_lr": 0.0005479772340437942, "train_mlm_acc_1": 0.11905413139251077, "train_mlm_acc_2": 0.11746412389334242, "train_loss_1": 4.9794706691223585, "train_loss_2": 5.0023145813530965, "train_loss": 9.981785257447678, "train_loss_scale": 9013.36147757256, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 111, "n_parameters": 106143056}
{"train_lr": 0.0005443961065787804, "train_min_lr": 0.0005443961065787804, "train_mlm_acc_1": 0.11911316604493555, "train_mlm_acc_2": 0.1175170088614433, "train_loss_1": 4.977835195150518, "train_loss_2": 5.000523402015682, "train_loss": 9.978358603194815, "train_loss_scale": 8328.893579595426, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 112, "n_parameters": 106143056}
{"train_lr": 0.0005407956865017628, "train_min_lr": 0.0005407956865017628, "train_mlm_acc_1": 0.11926417111803302, "train_mlm_acc_2": 0.11765870348474203, "train_loss_1": 4.976084333663461, "train_loss_2": 4.99883495801986, "train_loss": 9.974919292207549, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.175006355123763, "epoch": 113, "n_parameters": 106143056}
{"train_lr": 0.0005371763963380031, "train_min_lr": 0.0005371763963380031, "train_mlm_acc_1": 0.11937662897747839, "train_mlm_acc_2": 0.11779747786542619, "train_loss_1": 4.974222135994658, "train_loss_2": 4.996967859035432, "train_loss": 9.971189992933182, "train_loss_scale": 9733.854001759015, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 114, "n_parameters": 106143056}
{"train_lr": 0.0005335386608272497, "train_min_lr": 0.0005335386608272497, "train_mlm_acc_1": 0.11946195719408145, "train_mlm_acc_2": 0.11781714079785263, "train_loss_1": 4.9734089473621195, "train_loss_2": 4.996109809546273, "train_loss": 9.969518756803549, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1708887765149643, "epoch": 115, "n_parameters": 106143056}
{"train_lr": 0.0005298829068738921, "train_min_lr": 0.0005298829068738921, "train_mlm_acc_1": 0.11945513184383026, "train_mlm_acc_2": 0.11788075620172547, "train_loss_1": 4.972555398888617, "train_loss_2": 4.995378894038439, "train_loss": 9.967934288785662, "train_loss_scale": 5137.111697449428, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 116, "n_parameters": 106143056}
{"train_lr": 0.0005262095634968652, "train_min_lr": 0.0005262095634968652, "train_mlm_acc_1": 0.1196629154293576, "train_mlm_acc_2": 0.11801751501360218, "train_loss_1": 4.97090719688746, "train_loss_2": 4.993674914985764, "train_loss": 9.964582112659565, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2009426382097532, "epoch": 117, "n_parameters": 106143056}
{"train_lr": 0.0005225190617793022, "train_min_lr": 0.0005225190617793022, "train_mlm_acc_1": 0.11978182079157446, "train_mlm_acc_2": 0.11816366444847226, "train_loss_1": 4.968727041569947, "train_loss_2": 4.9914522922762465, "train_loss": 9.96017933416073, "train_loss_scale": 8137.9630606860155, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2059940113870324, "epoch": 118, "n_parameters": 106143056}
{"train_lr": 0.0005188118348179412, "train_min_lr": 0.0005188118348179412, "train_mlm_acc_1": 0.11987640222464094, "train_mlm_acc_2": 0.11826184172455217, "train_loss_1": 4.967293627291472, "train_loss_2": 4.990126383650586, "train_loss": 9.957420010575099, "train_loss_scale": 8681.93491644679, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 119, "n_parameters": 106143056}
{"train_lr": 0.0005150883176723058, "train_min_lr": 0.0005150883176723058, "train_mlm_acc_1": 0.1200196313284331, "train_mlm_acc_2": 0.11841222835113291, "train_loss_1": 4.965874963773377, "train_loss_2": 4.988740659798041, "train_loss": 9.954615619901826, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2005105744670543, "epoch": 120, "n_parameters": 106143056}
{"train_lr": 0.0005113489473136387, "train_min_lr": 0.0005113489473136387, "train_mlm_acc_1": 0.12014844257092937, "train_mlm_acc_2": 0.11855720965848644, "train_loss_1": 4.963391702009485, "train_loss_2": 4.986221609874682, "train_loss": 9.94961331618283, "train_loss_scale": 11542.29023746702, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2022112856963902, "epoch": 121, "n_parameters": 106143056}
{"train_lr": 0.0005075941625736347, "train_min_lr": 0.0005075941625736347, "train_mlm_acc_1": 0.12018030178679928, "train_mlm_acc_2": 0.11860234168724287, "train_loss_1": 4.962459314467096, "train_loss_2": 4.985306450119119, "train_loss": 9.947765766578279, "train_loss_scale": 14056.80914687775, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 122, "n_parameters": 106143056}
{"train_lr": 0.0005038244040929274, "train_min_lr": 0.0005038244040929274, "train_mlm_acc_1": 0.1203279284589982, "train_mlm_acc_2": 0.11870426383514937, "train_loss_1": 4.960329700271184, "train_loss_2": 4.9831452763908874, "train_loss": 9.943474973831243, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2324997959896045, "epoch": 123, "n_parameters": 106143056}
{"train_lr": 0.0005000401142693911, "train_min_lr": 0.0005000401142693911, "train_mlm_acc_1": 0.12042096392116398, "train_mlm_acc_2": 0.11875223583503312, "train_loss_1": 4.9598192088731885, "train_loss_2": 4.9826815596985625, "train_loss": 9.94250076699907, "train_loss_scale": 9380.812664907651, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 124, "n_parameters": 106143056}
{"train_lr": 0.0004962417372062153, "train_min_lr": 0.0004962417372062153, "train_mlm_acc_1": 0.12055922292415364, "train_mlm_acc_2": 0.11891212757175547, "train_loss_1": 4.957113886519074, "train_loss_2": 4.980094418833941, "train_loss": 9.937208306716006, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2123153913723552, "epoch": 125, "n_parameters": 106143056}
{"train_lr": 0.0004924297186597878, "train_min_lr": 0.0004924297186597878, "train_mlm_acc_1": 0.12066261088860565, "train_mlm_acc_2": 0.11901798915026239, "train_loss_1": 4.955907868311503, "train_loss_2": 4.97876610798907, "train_loss": 9.934673970586497, "train_loss_scale": 5439.71855760774, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 126, "n_parameters": 106143056}
{"train_lr": 0.0004886045059873886, "train_min_lr": 0.0004886045059873886, "train_mlm_acc_1": 0.12088435442697194, "train_mlm_acc_2": 0.11920055565928013, "train_loss_1": 4.954011446305714, "train_loss_2": 4.976948391321781, "train_loss": 9.930959834586977, "train_loss_scale": 2912.5910290237466, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 127, "n_parameters": 106143056}
{"train_lr": 0.00048476654809468197, "train_min_lr": 0.00048476654809468197, "train_mlm_acc_1": 0.12084810910607208, "train_mlm_acc_2": 0.1191927111529882, "train_loss_1": 4.952825336835839, "train_loss_2": 4.975796255293706, "train_loss": 9.928621590504441, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1957464328227383, "epoch": 128, "n_parameters": 106143056}
{"train_lr": 0.0004809162953830467, "train_min_lr": 0.0004809162953830467, "train_mlm_acc_1": 0.12097314113493855, "train_mlm_acc_2": 0.11931380371439451, "train_loss_1": 4.951265822090176, "train_loss_2": 4.974255472552703, "train_loss": 9.925521289977256, "train_loss_scale": 3724.9463500439756, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2233275006817639, "epoch": 129, "n_parameters": 106143056}
{"train_lr": 0.0004770541996967091, "train_min_lr": 0.0004770541996967091, "train_mlm_acc_1": 0.12106694373660111, "train_mlm_acc_2": 0.1194753101342927, "train_loss_1": 4.9495894831319385, "train_loss_2": 4.972488373963583, "train_loss": 9.922077858877895, "train_loss_scale": 4340.967458223395, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2410989451429355, "epoch": 130, "n_parameters": 106143056}
{"train_lr": 0.00047318071426971875, "train_min_lr": 0.00047318071426971875, "train_mlm_acc_1": 0.12121688374363233, "train_mlm_acc_2": 0.1195825917102403, "train_loss_1": 4.948216458004404, "train_loss_2": 4.971076531586358, "train_loss": 9.919292989800452, "train_loss_scale": 5101.087071240106, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 131, "n_parameters": 106143056}
{"train_lr": 0.00046929629367276803, "train_min_lr": 0.00046929629367276803, "train_mlm_acc_1": 0.12129723050090155, "train_mlm_acc_2": 0.1196682864444604, "train_loss_1": 4.946653345119775, "train_loss_2": 4.969617616794774, "train_loss": 9.916270960918517, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2565754978616928, "epoch": 132, "n_parameters": 106143056}
{"train_lr": 0.00046540139375983523, "train_min_lr": 0.00046540139375983523, "train_mlm_acc_1": 0.12148523662262248, "train_mlm_acc_2": 0.11980115157603667, "train_loss_1": 4.944287238355886, "train_loss_2": 4.967310610264146, "train_loss": 9.911597844898019, "train_loss_scale": 8173.987686895339, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2580768481722608, "epoch": 133, "n_parameters": 106143056}
{"train_lr": 0.00046149647161469406, "train_min_lr": 0.00046149647161469406, "train_mlm_acc_1": 0.1216000421619798, "train_mlm_acc_2": 0.11994814841943345, "train_loss_1": 4.942885252395636, "train_loss_2": 4.965919135847738, "train_loss": 9.908804385622238, "train_loss_scale": 5706.300791556729, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 134, "n_parameters": 106143056}
{"train_lr": 0.000457581985497272, "train_min_lr": 0.000457581985497272, "train_mlm_acc_1": 0.12169714296513492, "train_mlm_acc_2": 0.12002512831126218, "train_loss_1": 4.941491532556404, "train_loss_2": 4.96449654193541, "train_loss": 9.905988071294027, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2619134167777726, "epoch": 135, "n_parameters": 106143056}
{"train_lr": 0.00045365839478986964, "train_min_lr": 0.00045365839478986964, "train_mlm_acc_1": 0.12172908236894334, "train_mlm_acc_2": 0.12014469780886289, "train_loss_1": 4.939719623342982, "train_loss_2": 4.962709075490319, "train_loss": 9.902428696002474, "train_loss_scale": 7568.773966578716, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2594479148914233, "epoch": 136, "n_parameters": 106143056}
{"train_lr": 0.00044972615994325554, "train_min_lr": 0.00044972615994325554, "train_mlm_acc_1": 0.12190951881463342, "train_mlm_acc_2": 0.12029280548255068, "train_loss_1": 4.93755114775744, "train_loss_2": 4.960524061214746, "train_loss": 9.898075208081, "train_loss_scale": 6077.354441512753, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 137, "n_parameters": 106143056}
{"train_lr": 0.00044578574242262216, "train_min_lr": 0.00044578574242262216, "train_mlm_acc_1": 0.12197630648339854, "train_mlm_acc_2": 0.1203141518300866, "train_loss_1": 4.937062375673413, "train_loss_2": 4.960037144109044, "train_loss": 9.89709951852431, "train_loss_scale": 3128.738786279683, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 138, "n_parameters": 106143056}
{"train_lr": 0.0004418376046534354, "train_min_lr": 0.0004418376046534354, "train_mlm_acc_1": 0.12215244844834351, "train_mlm_acc_2": 0.12054490801209064, "train_loss_1": 4.933989634824197, "train_loss_2": 4.956924538237019, "train_loss": 9.890914182654576, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2562441477779767, "epoch": 139, "n_parameters": 106143056}
{"train_lr": 0.00043788220996717, "train_min_lr": 0.00043788220996717, "train_mlm_acc_1": 0.12212781537825483, "train_mlm_acc_2": 0.12049094653338613, "train_loss_1": 4.933759612741445, "train_loss_2": 4.956727912736337, "train_loss": 9.890487525582628, "train_loss_scale": 3508.7985927880386, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.269878895217741, "epoch": 140, "n_parameters": 106143056}
{"train_lr": 0.0004339200225469267, "train_min_lr": 0.0004339200225469267, "train_mlm_acc_1": 0.12243833415301987, "train_mlm_acc_2": 0.1207756183495976, "train_loss_1": 4.930725646679508, "train_loss_2": 4.953807088871639, "train_loss": 9.884532729889493, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3143131678945261, "epoch": 141, "n_parameters": 106143056}
{"train_lr": 0.0004299515073729694, "train_min_lr": 0.0004299515073729694, "train_mlm_acc_1": 0.12250213279890956, "train_mlm_acc_2": 0.12080208378497481, "train_loss_1": 4.929651096712211, "train_loss_2": 4.952744115206267, "train_loss": 9.882395209716723, "train_loss_scale": 8004.671943711522, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3045816127941496, "epoch": 142, "n_parameters": 106143056}
{"train_lr": 0.0004259771301681481, "train_min_lr": 0.0004259771301681481, "train_mlm_acc_1": 0.12239404956883077, "train_mlm_acc_2": 0.12072528725884783, "train_loss_1": 4.931034285820883, "train_loss_2": 4.954014352621902, "train_loss": 9.885048641063921, "train_loss_scale": 7082.441512752858, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 143, "n_parameters": 106143056}
{"train_lr": 0.00042199735734324876, "train_min_lr": 0.00042199735734324876, "train_mlm_acc_1": 0.12277519236922448, "train_mlm_acc_2": 0.12110195231436373, "train_loss_1": 4.9255966393698065, "train_loss_2": 4.9485517335021925, "train_loss": 9.874148371246894, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2798329693975423, "epoch": 144, "n_parameters": 106143056}
{"train_lr": 0.0004180126559422584, "train_min_lr": 0.0004180126559422584, "train_mlm_acc_1": 0.12289007800559963, "train_mlm_acc_2": 0.12124001669305112, "train_loss_1": 4.923836328213741, "train_loss_2": 4.946929825641863, "train_loss": 9.87076615396045, "train_loss_scale": 6192.633245382585, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2858534434330284, "epoch": 145, "n_parameters": 106143056}
{"train_lr": 0.00041402349358755474, "train_min_lr": 0.00041402349358755474, "train_mlm_acc_1": 0.12291534095117945, "train_mlm_acc_2": 0.12124610914076328, "train_loss_1": 4.922854247172883, "train_loss_2": 4.94595806558822, "train_loss": 9.868812312761104, "train_loss_scale": 4261.713280562884, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 146, "n_parameters": 106143056}
{"train_lr": 0.00041003033842502425, "train_min_lr": 0.00041003033842502425, "train_mlm_acc_1": 0.12309632711145263, "train_mlm_acc_2": 0.12143422982335196, "train_loss_1": 4.921103190620845, "train_loss_2": 4.944019996606161, "train_loss": 9.865123187960924, "train_loss_scale": 4917.361477572559, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3048229525250725, "epoch": 147, "n_parameters": 106143056}
{"train_lr": 0.00040603365906913383, "train_min_lr": 0.00040603365906913383, "train_mlm_acc_1": 0.12329667848072087, "train_mlm_acc_2": 0.12160251574982335, "train_loss_1": 4.91881265657034, "train_loss_2": 4.941934775708533, "train_loss": 9.860747433379752, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3223818527467437, "epoch": 148, "n_parameters": 106143056}
{"train_lr": 0.000402033924547923, "train_min_lr": 0.000402033924547923, "train_mlm_acc_1": 0.12331633005461598, "train_mlm_acc_2": 0.12163154632852412, "train_loss_1": 4.91814925493435, "train_loss_2": 4.94126118482365, "train_loss": 9.859410440282225, "train_loss_scale": 4773.262972735269, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 149, "n_parameters": 106143056}
{"train_lr": 0.0003980316042479732, "train_min_lr": 0.0003980316042479732, "train_mlm_acc_1": 0.12339028645890028, "train_mlm_acc_2": 0.1217662093877504, "train_loss_1": 4.916488834138281, "train_loss_2": 4.939618587860855, "train_loss": 9.85610742241852, "train_loss_scale": 4405.811785400176, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3343021186067017, "epoch": 150, "n_parameters": 106143056}
{"train_lr": 0.000394027167859318, "train_min_lr": 0.000394027167859318, "train_mlm_acc_1": 0.12343008189626765, "train_mlm_acc_2": 0.12178378819390516, "train_loss_1": 4.914656880558218, "train_loss_2": 4.9376322258535765, "train_loss": 9.852289102217977, "train_loss_scale": 5835.989445910291, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 151, "n_parameters": 106143056}
{"train_lr": 0.00039002108532032085, "train_min_lr": 0.00039002108532032085, "train_mlm_acc_1": 0.12369487317329765, "train_mlm_acc_2": 0.12202723314797238, "train_loss_1": 4.9122367206643105, "train_loss_2": 4.93524976456071, "train_loss": 9.847486489890644, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.318805070172933, "epoch": 152, "n_parameters": 106143056}
{"train_lr": 0.00038601382676252893, "train_min_lr": 0.00038601382676252893, "train_mlm_acc_1": 0.12381136217117703, "train_mlm_acc_2": 0.12211825300774741, "train_loss_1": 4.9109972413947105, "train_loss_2": 4.934056926790622, "train_loss": 9.845054163362441, "train_loss_scale": 4114.012313104661, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 153, "n_parameters": 106143056}
{"train_lr": 0.0003820058624555032, "train_min_lr": 0.0003820058624555032, "train_mlm_acc_1": 0.12391210464382235, "train_mlm_acc_2": 0.12219990518438838, "train_loss_1": 4.909149129032145, "train_loss_2": 4.9322479567511, "train_loss": 9.84139708090793, "train_loss_scale": 4250.905892700088, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 154, "n_parameters": 106143056}
{"train_lr": 0.000377997662751625, "train_min_lr": 0.000377997662751625, "train_mlm_acc_1": 0.12409700733906832, "train_mlm_acc_2": 0.12239669499838546, "train_loss_1": 4.906804813820748, "train_loss_2": 4.929839113876289, "train_loss": 9.83664392911245, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3369241221599024, "epoch": 155, "n_parameters": 106143056}
{"train_lr": 0.0003739896980309009, "train_min_lr": 0.0003739896980309009, "train_mlm_acc_1": 0.12428408596425489, "train_mlm_acc_2": 0.12255394124330113, "train_loss_1": 4.90502780827914, "train_loss_2": 4.92806971885703, "train_loss": 9.833097528446737, "train_loss_scale": 2955.820580474934, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 156, "n_parameters": 106143056}
{"train_lr": 0.0003699824386457607, "train_min_lr": 0.0003699824386457607, "train_mlm_acc_1": 0.12427870355458011, "train_mlm_acc_2": 0.1225947330475653, "train_loss_1": 4.90371921084487, "train_loss_2": 4.926748107165334, "train_loss": 9.830467314078499, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.380574536774383, "epoch": 157, "n_parameters": 106143056}
{"train_lr": 0.00036597635486586153, "train_min_lr": 0.00036597635486586153, "train_mlm_acc_1": 0.12446906882286622, "train_mlm_acc_2": 0.12278575104110027, "train_loss_1": 4.901349062236024, "train_loss_2": 4.924643343650361, "train_loss": 9.825992410289896, "train_loss_scale": 3681.716798592788, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.395409070407495, "epoch": 158, "n_parameters": 106143056}
{"train_lr": 0.0003619719168228958, "train_min_lr": 0.0003619719168228958, "train_mlm_acc_1": 0.12456991445689267, "train_mlm_acc_2": 0.1228872608793154, "train_loss_1": 4.900024622338009, "train_loss_2": 4.923041640821002, "train_loss": 9.823066263001744, "train_loss_scale": 4254.508355321021, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3645325348685473, "epoch": 159, "n_parameters": 106143056}
{"train_lr": 0.00035796959445542426, "train_min_lr": 0.00035796959445542426, "train_mlm_acc_1": 0.12479583797902655, "train_mlm_acc_2": 0.12310395413385532, "train_loss_1": 4.89769587819788, "train_loss_2": 4.920715559808015, "train_loss": 9.818411436433214, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3755614332913724, "epoch": 160, "n_parameters": 106143056}
{"train_lr": 0.0003539698574537211, "train_min_lr": 0.0003539698574537211, "train_mlm_acc_1": 0.12489035067033012, "train_mlm_acc_2": 0.12317399401954894, "train_loss_1": 4.895675487757358, "train_loss_2": 4.918800500630284, "train_loss": 9.814475993262956, "train_loss_scale": 4420.221635883905, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 161, "n_parameters": 106143056}
{"train_lr": 0.0003499731752046559, "train_min_lr": 0.0003499731752046559, "train_mlm_acc_1": 0.12501919621531257, "train_mlm_acc_2": 0.12332229643221371, "train_loss_1": 4.894230571040588, "train_loss_2": 4.9172439999295205, "train_loss": 9.811474571546757, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3673219258783151, "epoch": 162, "n_parameters": 106143056}
{"train_lr": 0.0003459800167366142, "train_min_lr": 0.0003459800167366142, "train_mlm_acc_1": 0.12507329505549625, "train_mlm_acc_2": 0.12341874448063217, "train_loss_1": 4.8930512778362685, "train_loss_2": 4.916165477472538, "train_loss": 9.809216755046693, "train_loss_scale": 2615.387862796834, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 163, "n_parameters": 106143056}
{"train_lr": 0.0003419908506644451, "train_min_lr": 0.0003419908506644451, "train_mlm_acc_1": 0.12518184781221964, "train_mlm_acc_2": 0.12351179143238612, "train_loss_1": 4.891696773764326, "train_loss_2": 4.914726637231748, "train_loss": 9.806423414665666, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.418320088241849, "epoch": 164, "n_parameters": 106143056}
{"train_lr": 0.00033800614513447493, "train_min_lr": 0.00033800614513447493, "train_mlm_acc_1": 0.1253215841426397, "train_mlm_acc_2": 0.12363867864681108, "train_loss_1": 4.889118494962325, "train_loss_2": 4.9123128548775625, "train_loss": 9.80143134124256, "train_loss_scale": 3058.490765171504, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4179184598784333, "epoch": 165, "n_parameters": 106143056}
{"train_lr": 0.00033402636776956357, "train_min_lr": 0.00033402636776956357, "train_mlm_acc_1": 0.1255890094505569, "train_mlm_acc_2": 0.1238475158604201, "train_loss_1": 4.886853373092628, "train_loss_2": 4.910031216545072, "train_loss": 9.796884596819613, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4150503020907246, "epoch": 166, "n_parameters": 106143056}
{"train_lr": 0.000330051985614231, "train_min_lr": 0.000330051985614231, "train_mlm_acc_1": 0.1256438183066621, "train_mlm_acc_2": 0.12394016192408513, "train_loss_1": 4.88565315283907, "train_loss_2": 4.908869540418777, "train_loss": 9.794522692890888, "train_loss_scale": 5717.108179419525, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 167, "n_parameters": 106143056}
{"train_lr": 0.0003260834650798454, "train_min_lr": 0.0003260834650798454, "train_mlm_acc_1": 0.12576878164782662, "train_mlm_acc_2": 0.12406022385378732, "train_loss_1": 4.8832245988078355, "train_loss_2": 4.906426857255904, "train_loss": 9.789651458055804, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3809200448222398, "epoch": 168, "n_parameters": 106143056}
{"train_lr": 0.00032212127188988656, "train_min_lr": 0.00032212127188988656, "train_mlm_acc_1": 0.12593248678599023, "train_mlm_acc_2": 0.12421704647143551, "train_loss_1": 4.881305312942599, "train_loss_2": 4.904554655180758, "train_loss": 9.785859966760365, "train_loss_scale": 6470.022867194371, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.477645049413884, "epoch": 169, "n_parameters": 106143056}
{"train_lr": 0.0003181658710252925, "train_min_lr": 0.0003181658710252925, "train_mlm_acc_1": 0.12607184525091028, "train_mlm_acc_2": 0.12438664933963103, "train_loss_1": 4.880137003348811, "train_loss_2": 4.903237721064475, "train_loss": 9.78337473238154, "train_loss_scale": 7986.65963060686, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 170, "n_parameters": 106143056}
{"train_lr": 0.0003142177266698921, "train_min_lr": 0.0003142177266698921, "train_mlm_acc_1": 0.1261829174088483, "train_mlm_acc_2": 0.12450781067638357, "train_loss_1": 4.878797211192005, "train_loss_2": 4.902000465829223, "train_loss": 9.78079768032386, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4144721252937116, "epoch": 171, "n_parameters": 106143056}
{"train_lr": 0.00031027730215593045, "train_min_lr": 0.00031027730215593045, "train_mlm_acc_1": 0.12638771212385375, "train_mlm_acc_2": 0.12468268147120112, "train_loss_1": 4.875523337011496, "train_loss_2": 4.898681006309959, "train_loss": 9.774204341381814, "train_loss_scale": 5288.415127528584, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4298975981948874, "epoch": 172, "n_parameters": 106143056}
{"train_lr": 0.0003063450599096958, "train_min_lr": 0.0003063450599096958, "train_mlm_acc_1": 0.12640503887414747, "train_mlm_acc_2": 0.12465636497781192, "train_loss_1": 4.874977183425856, "train_loss_2": 4.898221608202187, "train_loss": 9.773198796031553, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4397672013221545, "epoch": 173, "n_parameters": 106143056}
{"train_lr": 0.0003024214613972495, "train_min_lr": 0.0003024214613972495, "train_mlm_acc_1": 0.1266528355193602, "train_mlm_acc_2": 0.12498142775197299, "train_loss_1": 4.871950104662275, "train_loss_2": 4.8951876940911765, "train_loss": 9.767137796184738, "train_loss_scale": 8545.041336851364, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 174, "n_parameters": 106143056}
{"train_lr": 0.0002985069670702745, "train_min_lr": 0.0002985069670702745, "train_mlm_acc_1": 0.1267271815015293, "train_mlm_acc_2": 0.1250592321419569, "train_loss_1": 4.870252392589784, "train_loss_2": 4.893305640107409, "train_loss": 9.763558030443015, "train_loss_scale": 3971.7150395778363, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 175, "n_parameters": 106143056}
{"train_lr": 0.0002946020363120353, "train_min_lr": 0.0002946020363120353, "train_mlm_acc_1": 0.12687786577290733, "train_mlm_acc_2": 0.12514824783650663, "train_loss_1": 4.868483331713009, "train_loss_2": 4.8915900242569785, "train_loss": 9.760073356074834, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5118119676803012, "epoch": 176, "n_parameters": 106143056}
{"train_lr": 0.0002907071273834704, "train_min_lr": 0.0002907071273834704, "train_mlm_acc_1": 0.12710169363167323, "train_mlm_acc_2": 0.12538292065259518, "train_loss_1": 4.866562946647956, "train_loss_2": 4.889824216944561, "train_loss": 9.75638716191499, "train_loss_scale": 3631.282321899736, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4938944395215445, "epoch": 177, "n_parameters": 106143056}
{"train_lr": 0.0002868226973694113, "train_min_lr": 0.0002868226973694113, "train_mlm_acc_1": 0.12715092545298232, "train_mlm_acc_2": 0.1253850506766058, "train_loss_1": 4.864665065822416, "train_loss_2": 4.887829643807709, "train_loss": 9.75249471356183, "train_loss_scale": 4153.639401934916, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5274144806354426, "epoch": 178, "n_parameters": 106143056}
{"train_lr": 0.00028294920212494217, "train_min_lr": 0.00028294920212494217, "train_mlm_acc_1": 0.1272846723963214, "train_mlm_acc_2": 0.12556122700956535, "train_loss_1": 4.8629811793539535, "train_loss_2": 4.886246043386015, "train_loss": 9.749227224994145, "train_loss_scale": 4222.08619173263, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 179, "n_parameters": 106143056}
{"train_lr": 0.00027908709622190573, "train_min_lr": 0.00027908709622190573, "train_mlm_acc_1": 0.12748369528840744, "train_mlm_acc_2": 0.12570813222130534, "train_loss_1": 4.860629457125248, "train_loss_2": 4.8838724348245215, "train_loss": 9.744501890272243, "train_loss_scale": 4546.307827616535, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 180, "n_parameters": 106143056}
{"train_lr": 0.00027523683289555303, "train_min_lr": 0.00027523683289555303, "train_mlm_acc_1": 0.1276364639743822, "train_mlm_acc_2": 0.12593627744743383, "train_loss_1": 4.8584695320016165, "train_loss_2": 4.881662857930914, "train_loss": 9.740132396223258, "train_loss_scale": 3099.919085312225, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 181, "n_parameters": 106143056}
{"train_lr": 0.0002713988639913556, "train_min_lr": 0.0002713988639913556, "train_mlm_acc_1": 0.12771440569799566, "train_mlm_acc_2": 0.12597298086272748, "train_loss_1": 4.856885294119517, "train_loss_2": 4.880235112384421, "train_loss": 9.737120406923319, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5302423565347885, "epoch": 182, "n_parameters": 106143056}
{"train_lr": 0.00026757363991198143, "train_min_lr": 0.00026757363991198143, "train_mlm_acc_1": 0.1278597306060419, "train_mlm_acc_2": 0.12608857652321523, "train_loss_1": 4.855188061033515, "train_loss_2": 4.878489368142218, "train_loss": 9.733677431482333, "train_loss_scale": 3514.2022867194373, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 183, "n_parameters": 106143056}
{"train_lr": 0.00026376160956443706, "train_min_lr": 0.00026376160956443706, "train_mlm_acc_1": 0.12803162393965345, "train_mlm_acc_2": 0.1262523619377807, "train_loss_1": 4.853542168515758, "train_loss_2": 4.876765314014522, "train_loss": 9.730307482058475, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4889100867085219, "epoch": 184, "n_parameters": 106143056}
{"train_lr": 0.00025996322030738496, "train_min_lr": 0.00025996322030738496, "train_mlm_acc_1": 0.12819058806926223, "train_mlm_acc_2": 0.1264545226128888, "train_loss_1": 4.850874972584589, "train_loss_2": 4.874122496697603, "train_loss": 9.724997465927137, "train_loss_scale": 2564.9533861037817, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5475777129699184, "epoch": 185, "n_parameters": 106143056}
{"train_lr": 0.00025617891789864574, "train_min_lr": 0.00025617891789864574, "train_mlm_acc_1": 0.12834611655153144, "train_mlm_acc_2": 0.1265722255033286, "train_loss_1": 4.849880943826761, "train_loss_2": 4.873116281594534, "train_loss": 9.722997227570627, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5264417189931072, "epoch": 186, "n_parameters": 106143056}
{"train_lr": 0.0002524091464428861, "train_min_lr": 0.0002524091464428861, "train_mlm_acc_1": 0.12838271688489716, "train_mlm_acc_2": 0.12660534436779267, "train_loss_1": 4.847758352284695, "train_loss_2": 4.87109257221851, "train_loss": 9.71885092728161, "train_loss_scale": 6116.981530343008, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5482823660002534, "epoch": 187, "n_parameters": 106143056}
{"train_lr": 0.00024865434833949967, "train_min_lr": 0.00024865434833949967, "train_mlm_acc_1": 0.12863043342817743, "train_mlm_acc_2": 0.1268982501985569, "train_loss_1": 4.845189940489062, "train_loss_2": 4.8685627149822635, "train_loss": 9.713752654108335, "train_loss_scale": 4106.8073878627965, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 188, "n_parameters": 106143056}
{"train_lr": 0.0002449149642306928, "train_min_lr": 0.0002449149642306928, "train_mlm_acc_1": 0.1287506098523998, "train_mlm_acc_2": 0.1270086925301501, "train_loss_1": 4.843391911545236, "train_loss_2": 4.866630850649761, "train_loss": 9.710022763715257, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.569561177266724, "epoch": 189, "n_parameters": 106143056}
{"train_lr": 0.0002411914329497703, "train_min_lr": 0.0002411914329497703, "train_mlm_acc_1": 0.12893797461477516, "train_mlm_acc_2": 0.12718307092972592, "train_loss_1": 4.841516629320126, "train_loss_2": 4.864787197417089, "train_loss": 9.706303828205051, "train_loss_scale": 2321.7871591908533, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 190, "n_parameters": 106143056}
{"train_lr": 0.000237484191469636, "train_min_lr": 0.000237484191469636, "train_mlm_acc_1": 0.12906522844101426, "train_mlm_acc_2": 0.12731225999430962, "train_loss_1": 4.83959783664794, "train_loss_2": 4.862841670987055, "train_loss": 9.702439513453918, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5662602431017154, "epoch": 191, "n_parameters": 106143056}
{"train_lr": 0.00023379367485151643, "train_min_lr": 0.00023379367485151643, "train_mlm_acc_1": 0.12918816491463464, "train_mlm_acc_2": 0.12744059027463409, "train_loss_1": 4.83738854923265, "train_loss_2": 4.860564267624861, "train_loss": 9.697952816018748, "train_loss_scale": 2087.627088830255, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 192, "n_parameters": 106143056}
{"train_lr": 0.00023012031619389827, "train_min_lr": 0.00023012031619389827, "train_mlm_acc_1": 0.1293163003290208, "train_mlm_acc_2": 0.12755054016675385, "train_loss_1": 4.835277984461034, "train_loss_2": 4.858587434969142, "train_loss": 9.693865418434143, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.625297886557818, "epoch": 193, "n_parameters": 106143056}
{"train_lr": 0.00022646454658170753, "train_min_lr": 0.00022646454658170753, "train_mlm_acc_1": 0.1295192169652975, "train_mlm_acc_2": 0.1278111400515195, "train_loss_1": 4.833176721211788, "train_loss_2": 4.856418728566316, "train_loss": 9.689595449882951, "train_loss_scale": 3298.0545294635003, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6114245007304424, "epoch": 194, "n_parameters": 106143056}
{"train_lr": 0.00022282679503571708, "train_min_lr": 0.00022282679503571708, "train_mlm_acc_1": 0.129620394691589, "train_mlm_acc_2": 0.12785577969813985, "train_loss_1": 4.832219693098764, "train_loss_2": 4.855686863892521, "train_loss": 9.687906551067517, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5730652044819653, "epoch": 195, "n_parameters": 106143056}
{"train_lr": 0.00021920748846219963, "train_min_lr": 0.00021920748846219963, "train_mlm_acc_1": 0.1298361603635885, "train_mlm_acc_2": 0.12811545201183255, "train_loss_1": 4.8289955603311014, "train_loss_2": 4.852280280835395, "train_loss": 9.68127584121892, "train_loss_scale": 2114.645558487247, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 196, "n_parameters": 106143056}
{"train_lr": 0.00021560705160282874, "train_min_lr": 0.00021560705160282874, "train_mlm_acc_1": 0.12997412162922198, "train_mlm_acc_2": 0.12824191551871775, "train_loss_1": 4.826846001645191, "train_loss_2": 4.8502482240831215, "train_loss": 9.677094222687794, "train_loss_scale": 2474.891820580475, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5717642429950685, "epoch": 197, "n_parameters": 106143056}
{"train_lr": 0.0002120259069848334, "train_min_lr": 0.0002120259069848334, "train_mlm_acc_1": 0.1301118195115891, "train_mlm_acc_2": 0.12841687800334856, "train_loss_1": 4.825234369216725, "train_loss_2": 4.848494203654736, "train_loss": 9.673728571193934, "train_loss_scale": 3789.790677220756, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 198, "n_parameters": 106143056}
{"train_lr": 0.00020846447487141197, "train_min_lr": 0.00020846447487141197, "train_mlm_acc_1": 0.13023495045879638, "train_mlm_acc_2": 0.1284829212332975, "train_loss_1": 4.824085798196449, "train_loss_2": 4.847406350004118, "train_loss": 9.671492145264892, "train_loss_scale": 1687.7537379067721, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 199, "n_parameters": 106143056}
{"train_lr": 0.0002049231732124145, "train_min_lr": 0.0002049231732124145, "train_mlm_acc_1": 0.13040284723331766, "train_mlm_acc_2": 0.12864159893821156, "train_loss_1": 4.821602806095083, "train_loss_2": 4.844971090581402, "train_loss": 9.666573897620095, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6186705673065958, "epoch": 200, "n_parameters": 106143056}
{"train_lr": 0.00020140241759529154, "train_min_lr": 0.00020140241759529154, "train_mlm_acc_1": 0.13069890219580607, "train_mlm_acc_2": 0.12890921888927043, "train_loss_1": 4.818584414407048, "train_loss_2": 4.842014319139714, "train_loss": 9.66059873139743, "train_loss_scale": 1631.0149516270887, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6617403016765597, "epoch": 201, "n_parameters": 106143056}
{"train_lr": 0.00019790262119632546, "train_min_lr": 0.00019790262119632546, "train_mlm_acc_1": 0.13072469192430075, "train_mlm_acc_2": 0.1289618748716073, "train_loss_1": 4.817023131337833, "train_loss_2": 4.8404683682513845, "train_loss": 9.657491496286585, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6955354277670331, "epoch": 202, "n_parameters": 106143056}
{"train_lr": 0.0001944241947321401, "train_min_lr": 0.0001944241947321401, "train_mlm_acc_1": 0.13091456484485323, "train_mlm_acc_2": 0.12910220670213196, "train_loss_1": 4.815175749748133, "train_loss_2": 4.838458555879148, "train_loss": 9.65363430484094, "train_loss_scale": 3575.444151275286, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 203, "n_parameters": 106143056}
{"train_lr": 0.00019096754641150413, "train_min_lr": 0.00019096754641150413, "train_mlm_acc_1": 0.13106393220317578, "train_mlm_acc_2": 0.12928221946731275, "train_loss_1": 4.812901184133196, "train_loss_2": 4.8362912146690755, "train_loss": 9.649192400741912, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6158399175633016, "epoch": 204, "n_parameters": 106143056}
{"train_lr": 0.00018753308188742345, "train_min_lr": 0.00018753308188742345, "train_mlm_acc_1": 0.13124029185023345, "train_mlm_acc_2": 0.12946249563541842, "train_loss_1": 4.810654996200518, "train_loss_2": 4.833914320198401, "train_loss": 9.644569316661032, "train_loss_scale": 2539.736147757256, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 205, "n_parameters": 106143056}
{"train_lr": 0.00018412120420953888, "train_min_lr": 0.00018412120420953888, "train_mlm_acc_1": 0.13139954223006753, "train_mlm_acc_2": 0.12963567151325175, "train_loss_1": 4.809119849951517, "train_loss_2": 4.832391838914171, "train_loss": 9.641511689389915, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.647326832553642, "epoch": 206, "n_parameters": 106143056}
{"train_lr": 0.00018073231377682198, "train_min_lr": 0.00018073231377682198, "train_mlm_acc_1": 0.1315811697169221, "train_mlm_acc_2": 0.12979032977409627, "train_loss_1": 4.8070773906946815, "train_loss_2": 4.830354114478371, "train_loss": 9.637431504858515, "train_loss_scale": 2723.4617414248023, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6868497651191583, "epoch": 207, "n_parameters": 106143056}
{"train_lr": 0.0001773668082905917, "train_min_lr": 0.0001773668082905917, "train_mlm_acc_1": 0.13172493710058922, "train_mlm_acc_2": 0.1299346124388035, "train_loss_1": 4.8047130644164175, "train_loss_2": 4.827997890237977, "train_loss": 9.632710956227077, "train_loss_scale": 2822.5294635004398, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 208, "n_parameters": 106143056}
{"train_lr": 0.00017402508270783777, "train_min_lr": 0.00017402508270783777, "train_mlm_acc_1": 0.13177535991064004, "train_mlm_acc_2": 0.1299930974274297, "train_loss_1": 4.803436662978841, "train_loss_2": 4.826800615512811, "train_loss": 9.630237278229538, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7415520353807938, "epoch": 209, "n_parameters": 106143056}
{"train_lr": 0.0001707075291948745, "train_min_lr": 0.0001707075291948745, "train_mlm_acc_1": 0.1319422944888748, "train_mlm_acc_2": 0.13019170811303163, "train_loss_1": 4.801070466781774, "train_loss_2": 4.824364466686047, "train_loss": 9.625434928225548, "train_loss_scale": 3815.0079155672825, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7033508986156032, "epoch": 210, "n_parameters": 106143056}
{"train_lr": 0.0001674145370813154, "train_min_lr": 0.0001674145370813154, "train_mlm_acc_1": 0.13226633809552762, "train_mlm_acc_2": 0.13049368379210027, "train_loss_1": 4.79773391110916, "train_loss_2": 4.820962741853065, "train_loss": 9.618696649135364, "train_loss_scale": 3481.780123131047, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 211, "n_parameters": 106143056}
{"train_lr": 0.0001641464928143861, "train_min_lr": 0.0001641464928143861, "train_mlm_acc_1": 0.13221796517560985, "train_mlm_acc_2": 0.13044235633609189, "train_loss_1": 4.797270801524479, "train_loss_2": 4.820471193828181, "train_loss": 9.617741989166776, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7455948163462818, "epoch": 212, "n_parameters": 106143056}
{"train_lr": 0.0001609037799135703, "train_min_lr": 0.0001609037799135703, "train_mlm_acc_1": 0.13254374948394934, "train_mlm_acc_2": 0.13079388447436804, "train_loss_1": 4.7943218742532485, "train_loss_2": 4.8177244198248905, "train_loss": 9.612046301312477, "train_loss_scale": 3155.7572559366754, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7372454248086968, "epoch": 213, "n_parameters": 106143056}
{"train_lr": 0.00015768677892560474, "train_min_lr": 0.00015768677892560474, "train_mlm_acc_1": 0.13266441829686063, "train_mlm_acc_2": 0.13087980818534195, "train_loss_1": 4.792083256110457, "train_loss_2": 4.815282716862235, "train_loss": 9.607365976118055, "train_loss_scale": 3998.7335092348285, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 214, "n_parameters": 106143056}
{"train_lr": 0.0001544958673798188, "train_min_lr": 0.0001544958673798188, "train_mlm_acc_1": 0.13284541596801872, "train_mlm_acc_2": 0.131032599795613, "train_loss_1": 4.790179608312739, "train_loss_2": 4.813607781941993, "train_loss": 9.603787384750346, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7316735689327605, "epoch": 215, "n_parameters": 106143056}
{"train_lr": 0.00015133141974383045, "train_min_lr": 0.00015133141974383045, "train_mlm_acc_1": 0.13299315713473786, "train_mlm_acc_2": 0.13118714338337237, "train_loss_1": 4.788117448384026, "train_loss_2": 4.811484553987977, "train_loss": 9.599601998283031, "train_loss_scale": 2638.8038698328937, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7520087933791972, "epoch": 216, "n_parameters": 106143056}
{"train_lr": 0.00014819380737959978, "train_min_lr": 0.00014819380737959978, "train_mlm_acc_1": 0.13323509038680723, "train_mlm_acc_2": 0.13144411301205922, "train_loss_1": 4.785051406321027, "train_loss_2": 4.808408033407458, "train_loss": 9.59345943558709, "train_loss_scale": 2878.36763412489, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 217, "n_parameters": 106143056}
{"train_lr": 0.0001450833984998489, "train_min_lr": 0.0001450833984998489, "train_mlm_acc_1": 0.13337276540713003, "train_mlm_acc_2": 0.13157345102272647, "train_loss_1": 4.783226504227312, "train_loss_2": 4.806563542092591, "train_loss": 9.58979004605779, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8011102594087915, "epoch": 218, "n_parameters": 106143056}
{"train_lr": 0.0001420005581248513, "train_min_lr": 0.0001420005581248513, "train_mlm_acc_1": 0.13360083040354565, "train_mlm_acc_2": 0.13176847724760035, "train_loss_1": 4.780544970102654, "train_loss_2": 4.80401469016138, "train_loss": 9.584559656175061, "train_loss_scale": 2174.0861917326297, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 219, "n_parameters": 106143056}
{"train_lr": 0.00013894564803959363, "train_min_lr": 0.00013894564803959363, "train_mlm_acc_1": 0.1336642511765634, "train_mlm_acc_2": 0.13186583007958602, "train_loss_1": 4.779416354633573, "train_loss_2": 4.802768111071675, "train_loss": 9.582184466439166, "train_loss_scale": 2078.6209322779246, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8086685650476575, "epoch": 220, "n_parameters": 106143056}
{"train_lr": 0.00013591902675131893, "train_min_lr": 0.00013591902675131893, "train_mlm_acc_1": 0.1338932895967401, "train_mlm_acc_2": 0.1321129051381976, "train_loss_1": 4.777016675986002, "train_loss_2": 4.800429199175973, "train_loss": 9.577445869605166, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6999402757055841, "epoch": 221, "n_parameters": 106143056}
{"train_lr": 0.00013292104944745455, "train_min_lr": 0.00013292104944745455, "train_mlm_acc_1": 0.13396579164949393, "train_mlm_acc_2": 0.13216974117064959, "train_loss_1": 4.775869201439561, "train_loss_2": 4.799119537245734, "train_loss": 9.574988734229363, "train_loss_scale": 2655.014951627089, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 222, "n_parameters": 106143056}
{"train_lr": 0.00012995206795392967, "train_min_lr": 0.00012995206795392967, "train_mlm_acc_1": 0.13411515912740585, "train_mlm_acc_2": 0.1323263003091961, "train_loss_1": 4.774225344548858, "train_loss_2": 4.797538979701442, "train_loss": 9.571764321209782, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8473392296697135, "epoch": 223, "n_parameters": 106143056}
{"train_lr": 0.00012701243069388645, "train_min_lr": 0.00012701243069388645, "train_mlm_acc_1": 0.13433354723913532, "train_mlm_acc_2": 0.13255206344890014, "train_loss_1": 4.771417746023851, "train_loss_2": 4.794716391578094, "train_loss": 9.56613413692045, "train_loss_scale": 3224.2040457343887, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 224, "n_parameters": 106143056}
{"train_lr": 0.0001241024826467912, "train_min_lr": 0.0001241024826467912, "train_mlm_acc_1": 0.13446967622057168, "train_mlm_acc_2": 0.1326717476236815, "train_loss_1": 4.768806097427794, "train_loss_2": 4.792087834082682, "train_loss": 9.560893933817075, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.91839561655318, "epoch": 225, "n_parameters": 106143056}
{"train_lr": 0.00012122256530794866, "train_min_lr": 0.00012122256530794866, "train_mlm_acc_1": 0.13462395652663373, "train_mlm_acc_2": 0.1328002037873644, "train_loss_1": 4.76741021415489, "train_loss_2": 4.790740478950943, "train_loss": 9.55815068744418, "train_loss_scale": 3299.8557607739667, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7830128115630506, "epoch": 226, "n_parameters": 106143056}
{"train_lr": 0.00011837301664842798, "train_min_lr": 0.00011837301664842798, "train_mlm_acc_1": 0.13478128297914643, "train_mlm_acc_2": 0.13299167986874033, "train_loss_1": 4.7643573145228935, "train_loss_2": 4.787709148808751, "train_loss": 9.552066466005202, "train_loss_scale": 2075.0184696569922, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 227, "n_parameters": 106143056}
{"train_lr": 0.00011555417107539845, "train_min_lr": 0.00011555417107539845, "train_mlm_acc_1": 0.1350432799747353, "train_mlm_acc_2": 0.13322090155386881, "train_loss_1": 4.762337491558431, "train_loss_2": 4.785734933724819, "train_loss": 9.548072428900417, "train_loss_scale": 2514.51890941073, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.873324905400121, "epoch": 228, "n_parameters": 106143056}
{"train_lr": 0.00011276635939288607, "train_min_lr": 0.00011276635939288607, "train_mlm_acc_1": 0.13513935013717612, "train_mlm_acc_2": 0.13332984364274544, "train_loss_1": 4.7607547923358995, "train_loss_2": 4.7840930691075725, "train_loss": 9.544847856935117, "train_loss_scale": 2954.0193491644677, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 229, "n_parameters": 106143056}
{"train_lr": 0.00011000990876295262, "train_min_lr": 0.00011000990876295262, "train_mlm_acc_1": 0.13530681161463864, "train_mlm_acc_2": 0.1334789017659326, "train_loss_1": 4.758654603595365, "train_loss_2": 4.782064999680616, "train_loss": 9.540719602542062, "train_loss_scale": 1550.8601583113457, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 230, "n_parameters": 106143056}
{"train_lr": 0.00010728514266730062, "train_min_lr": 0.00010728514266730062, "train_mlm_acc_1": 0.13541334889101794, "train_mlm_acc_2": 0.13363424719130274, "train_loss_1": 4.75671384569418, "train_loss_2": 4.780016601347777, "train_loss": 9.536730444315975, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9089876151755911, "epoch": 231, "n_parameters": 106143056}
{"train_lr": 0.00010459238086931266, "train_min_lr": 0.00010459238086931266, "train_mlm_acc_1": 0.13554465658176384, "train_mlm_acc_2": 0.1337716816928608, "train_loss_1": 4.755399540001191, "train_loss_2": 4.778742586874396, "train_loss": 9.534142126928009, "train_loss_scale": 1767.9085312225154, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9525827940032476, "epoch": 232, "n_parameters": 106143056}
{"train_lr": 0.0001019319393765248, "train_min_lr": 0.0001019319393765248, "train_mlm_acc_1": 0.1358384326634406, "train_mlm_acc_2": 0.13400721333580207, "train_loss_1": 4.752141455599585, "train_loss_2": 4.775377456724591, "train_loss": 9.527518907763397, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8706769226094349, "epoch": 233, "n_parameters": 106143056}
{"train_lr": 9.930413040354184e-05, "train_min_lr": 9.930413040354184e-05, "train_mlm_acc_1": 0.13591037370041734, "train_mlm_acc_2": 0.13410911252173344, "train_loss_1": 4.751130154128649, "train_loss_2": 4.774496361154575, "train_loss": 9.52562651617441, "train_loss_scale": 4029.354441512753, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9043799542290345, "epoch": 234, "n_parameters": 106143056}
{"train_lr": 9.670926233539824e-05, "train_min_lr": 9.670926233539824e-05, "train_mlm_acc_1": 0.1361619380270782, "train_mlm_acc_2": 0.1343308674972652, "train_loss_1": 4.748210807484079, "train_loss_2": 4.771465584386727, "train_loss": 9.519676391870806, "train_loss_scale": 2352.4080914687775, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 235, "n_parameters": 106143056}
{"train_lr": 9.414763969136625e-05, "train_min_lr": 9.414763969136625e-05, "train_mlm_acc_1": 0.13626865847503133, "train_mlm_acc_2": 0.13445388402285263, "train_loss_1": 4.745957964538165, "train_loss_2": 4.769267683293386, "train_loss": 9.51522564321835, "train_loss_scale": 1409.4635004397537, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 236, "n_parameters": 106143056}
{"train_lr": 9.16195630892216e-05, "train_min_lr": 9.16195630892216e-05, "train_mlm_acc_1": 0.1364281952263183, "train_mlm_acc_2": 0.13460299936790762, "train_loss_1": 4.7443918331002815, "train_loss_2": 4.767676956682951, "train_loss": 9.512068792299523, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9139808284785522, "epoch": 237, "n_parameters": 106143056}
{"train_lr": 8.91253292099618e-05, "train_min_lr": 8.91253292099618e-05, "train_mlm_acc_1": 0.13666779230772244, "train_mlm_acc_2": 0.13486650821211418, "train_loss_1": 4.741888896299226, "train_loss_2": 4.765097015189202, "train_loss": 9.506985903520173, "train_loss_scale": 1909.3051890941074, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9296886457512017, "epoch": 238, "n_parameters": 106143056}
{"train_lr": 8.66652307629916e-05, "train_min_lr": 8.66652307629916e-05, "train_mlm_acc_1": 0.13689322323802933, "train_mlm_acc_2": 0.13503639734200248, "train_loss_1": 4.739345201768682, "train_loss_2": 4.762779484847814, "train_loss": 9.502124688451293, "train_loss_scale": 1422.9727352682498, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 239, "n_parameters": 106143056}
{"train_lr": 8.423955645177132e-05, "train_min_lr": 8.423955645177132e-05, "train_mlm_acc_1": 0.13700926562045473, "train_mlm_acc_2": 0.13517006419078106, "train_loss_1": 4.7376893195753675, "train_loss_2": 4.760908306693444, "train_loss": 9.498597618667516, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9250325937489197, "epoch": 240, "n_parameters": 106143056}
{"train_lr": 8.184859093993656e-05, "train_min_lr": 8.184859093993656e-05, "train_mlm_acc_1": 0.13706330735508349, "train_mlm_acc_2": 0.1352701082796173, "train_loss_1": 4.736499904065983, "train_loss_2": 4.759782742070019, "train_loss": 9.496282649962863, "train_loss_scale": 1895.7959542656113, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9512376053457001, "epoch": 241, "n_parameters": 106143056}
{"train_lr": 7.949261481789082e-05, "train_min_lr": 7.949261481789082e-05, "train_mlm_acc_1": 0.13721731271702883, "train_mlm_acc_2": 0.13543145429251247, "train_loss_1": 4.735032880211883, "train_loss_2": 4.758231790891948, "train_loss": 9.493264677342136, "train_loss_scale": 2237.1292875989448, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8980818517185034, "epoch": 242, "n_parameters": 106143056}
{"train_lr": 7.717190456987782e-05, "train_min_lr": 7.717190456987782e-05, "train_mlm_acc_1": 0.1373945539964653, "train_mlm_acc_2": 0.13558721191289924, "train_loss_1": 4.732445211083404, "train_loss_2": 4.755728110002654, "train_loss": 9.488173325017764, "train_loss_scale": 2509.1152154793317, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 243, "n_parameters": 106143056}
{"train_lr": 7.488673254153478e-05, "train_min_lr": 7.488673254153478e-05, "train_mlm_acc_1": 0.13759288982313744, "train_mlm_acc_2": 0.13575427248916713, "train_loss_1": 4.730910295284728, "train_loss_2": 4.754304489495992, "train_loss": 9.485214784675874, "train_loss_scale": 1883.1873350923483, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 244, "n_parameters": 106143056}
{"train_lr": 7.263736690793118e-05, "train_min_lr": 7.263736690793118e-05, "train_mlm_acc_1": 0.13769796126904646, "train_mlm_acc_2": 0.13589093975621222, "train_loss_1": 4.7285886635461605, "train_loss_2": 4.75174844626701, "train_loss": 9.480337107611415, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0429593567902726, "epoch": 245, "n_parameters": 106143056}
{"train_lr": 7.04240716420974e-05, "train_min_lr": 7.04240716420974e-05, "train_mlm_acc_1": 0.13789938907683708, "train_mlm_acc_2": 0.13606244379125385, "train_loss_1": 4.7270112274085205, "train_loss_2": 4.750236356268877, "train_loss": 9.477247583415284, "train_loss_scale": 1435.5813544415128, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.949012016558081, "epoch": 246, "n_parameters": 106143056}
{"train_lr": 6.824710648404599e-05, "train_min_lr": 6.824710648404599e-05, "train_mlm_acc_1": 0.13805666968976732, "train_mlm_acc_2": 0.13624886943808803, "train_loss_1": 4.724845408554547, "train_loss_2": 4.748072245242623, "train_loss": 9.472917652905984, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9940465802986997, "epoch": 247, "n_parameters": 106143056}
{"train_lr": 6.610672691029053e-05, "train_min_lr": 6.610672691029053e-05, "train_mlm_acc_1": 0.13816587524627816, "train_mlm_acc_2": 0.13633469019737177, "train_loss_1": 4.723445718552632, "train_loss_2": 4.746773972412737, "train_loss": 9.470219687400624, "train_loss_scale": 2073.217238346526, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 248, "n_parameters": 106143056}
{"train_lr": 6.400318410386393e-05, "train_min_lr": 6.400318410386393e-05, "train_mlm_acc_1": 0.13834443366156668, "train_mlm_acc_2": 0.13651271032787066, "train_loss_1": 4.720638032062282, "train_loss_2": 4.743866512936883, "train_loss": 9.464504546309733, "train_loss_scale": 1908.4045734388742, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 249, "n_parameters": 106143056}
{"train_lr": 6.19367249248409e-05, "train_min_lr": 6.19367249248409e-05, "train_mlm_acc_1": 0.13856656649440738, "train_mlm_acc_2": 0.1367260940739903, "train_loss_1": 4.719236857868017, "train_loss_2": 4.7424202697153355, "train_loss": 9.46165712737366, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9837820644219297, "epoch": 250, "n_parameters": 106143056}
{"train_lr": 5.990759188136876e-05, "train_min_lr": 5.990759188136876e-05, "train_mlm_acc_1": 0.1386593844096128, "train_mlm_acc_2": 0.13683497887383245, "train_loss_1": 4.717315270854594, "train_loss_2": 4.740468673938811, "train_loss": 9.457783943849797, "train_loss_scale": 1130.272647317502, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 251, "n_parameters": 106143056}
{"train_lr": 5.791602310120655e-05, "train_min_lr": 5.791602310120655e-05, "train_mlm_acc_1": 0.1387644328378475, "train_mlm_acc_2": 0.13693418678325472, "train_loss_1": 4.716114161878483, "train_loss_2": 4.739325165381637, "train_loss": 9.455439326316512, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.125029197678612, "epoch": 252, "n_parameters": 106143056}
{"train_lr": 5.59622523037808e-05, "train_min_lr": 5.59622523037808e-05, "train_mlm_acc_1": 0.13892384349854242, "train_mlm_acc_2": 0.13707927117990812, "train_loss_1": 4.713985910516301, "train_loss_2": 4.737050784347135, "train_loss": 9.45103669627885, "train_loss_scale": 1063.6270888302552, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 253, "n_parameters": 106143056}
{"train_lr": 5.4046508772757435e-05, "train_min_lr": 5.4046508772757435e-05, "train_mlm_acc_1": 0.13907506610959008, "train_mlm_acc_2": 0.13724204871013904, "train_loss_1": 4.713233335928217, "train_loss_2": 4.736422717151877, "train_loss": 9.449656054338238, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.019895332260098, "epoch": 254, "n_parameters": 106143056}
{"train_lr": 5.2169017329133505e-05, "train_min_lr": 5.2169017329133505e-05, "train_mlm_acc_1": 0.13923795815809525, "train_mlm_acc_2": 0.1373820484377503, "train_loss_1": 4.710762608596497, "train_loss_2": 4.7339530295725964, "train_loss": 9.444715639951466, "train_loss_scale": 1758.0017590149516, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0770015814059013, "epoch": 255, "n_parameters": 106143056}
{"train_lr": 5.03299983048543e-05, "train_min_lr": 5.03299983048543e-05, "train_mlm_acc_1": 0.139341872982458, "train_mlm_acc_2": 0.13750082784862297, "train_loss_1": 4.709329805095257, "train_loss_2": 4.732442500933074, "train_loss": 9.441772307129208, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.000054809118219, "epoch": 256, "n_parameters": 106143056}
{"train_lr": 4.8529667516956426e-05, "train_min_lr": 4.8529667516956426e-05, "train_mlm_acc_1": 0.1394564952699692, "train_mlm_acc_2": 0.13761701910668883, "train_loss_1": 4.707322434364125, "train_loss_2": 4.7304379858777725, "train_loss": 9.437760419979783, "train_loss_scale": 4009.5408970976255, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0871417681795523, "epoch": 257, "n_parameters": 106143056}
{"train_lr": 4.676823624223976e-05, "train_min_lr": 4.676823624223976e-05, "train_mlm_acc_1": 0.13963720654346304, "train_mlm_acc_2": 0.1377890154362223, "train_loss_1": 4.705642020691878, "train_loss_2": 4.728699391466961, "train_loss": 9.434341411582189, "train_loss_scale": 3326.8742304309585, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 258, "n_parameters": 106143056}
{"train_lr": 4.5045911192474324e-05, "train_min_lr": 4.5045911192474324e-05, "train_mlm_acc_1": 0.1397692472637093, "train_mlm_acc_2": 0.1379252245982252, "train_loss_1": 4.704139715973075, "train_loss_2": 4.727280554429627, "train_loss": 9.431420267624297, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.0489981429243467, "epoch": 259, "n_parameters": 106143056}
{"train_lr": 4.336289449014104e-05, "train_min_lr": 4.336289449014104e-05, "train_mlm_acc_1": 0.13979433833890928, "train_mlm_acc_2": 0.13796765396736804, "train_loss_1": 4.703648336487269, "train_loss_2": 4.726791924935427, "train_loss": 9.430440262313883, "train_loss_scale": 2386.6314863676344, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 260, "n_parameters": 106143056}
{"train_lr": 4.171938364471223e-05, "train_min_lr": 4.171938364471223e-05, "train_mlm_acc_1": 0.1399058457840768, "train_mlm_acc_2": 0.1380820701409888, "train_loss_1": 4.701427261139493, "train_loss_2": 4.724521943897979, "train_loss": 9.425949213477532, "train_loss_scale": 1566.1706244503077, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 261, "n_parameters": 106143056}
{"train_lr": 4.011557152947225e-05, "train_min_lr": 4.011557152947225e-05, "train_mlm_acc_1": 0.14019026559029715, "train_mlm_acc_2": 0.13831893020459404, "train_loss_1": 4.699549609144843, "train_loss_2": 4.7227132282659685, "train_loss": 9.422262843177313, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2359777322020986, "epoch": 262, "n_parameters": 106143056}
{"train_lr": 3.8551646358884036e-05, "train_min_lr": 3.8551646358884036e-05, "train_mlm_acc_1": 0.14024501726794708, "train_mlm_acc_2": 0.13839946006872775, "train_loss_1": 4.69849825586891, "train_loss_2": 4.72171744444754, "train_loss": 9.420215696332322, "train_loss_scale": 651.5954265611258, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.257929185868987, "epoch": 263, "n_parameters": 106143056}
{"train_lr": 3.702779166650029e-05, "train_min_lr": 3.702779166650029e-05, "train_mlm_acc_1": 0.1404190406009961, "train_mlm_acc_2": 0.13854715549006155, "train_loss_1": 4.696867455068973, "train_loss_2": 4.719964396827768, "train_loss": 9.416831845239054, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2440202001321703, "epoch": 264, "n_parameters": 106143056}
{"train_lr": 3.55441862834257e-05, "train_min_lr": 3.55441862834257e-05, "train_mlm_acc_1": 0.14040749709686245, "train_mlm_acc_2": 0.13858689363921353, "train_loss_1": 4.696036094988032, "train_loss_2": 4.719125148121893, "train_loss": 9.415161242690543, "train_loss_scale": 1549.9595426561125, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.175916464158916, "epoch": 265, "n_parameters": 106143056}
{"train_lr": 3.4101004317329864e-05, "train_min_lr": 3.4101004317329864e-05, "train_mlm_acc_1": 0.14056609477602083, "train_mlm_acc_2": 0.13872305702552423, "train_loss_1": 4.694733001154142, "train_loss_2": 4.717799001182499, "train_loss": 9.412532000659114, "train_loss_scale": 718.2409850483729, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 266, "n_parameters": 106143056}
{"train_lr": 3.269841513201525e-05, "train_min_lr": 3.269841513201525e-05, "train_mlm_acc_1": 0.1407486498282146, "train_mlm_acc_2": 0.1389026918277315, "train_loss_1": 4.692539775224768, "train_loss_2": 4.715628113731965, "train_loss": 9.408167886545288, "train_loss_scale": 565.136323658751, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.326203763956759, "epoch": 267, "n_parameters": 106143056}
{"train_lr": 3.1336583327541557e-05, "train_min_lr": 3.1336583327541557e-05, "train_mlm_acc_1": 0.14084950691005485, "train_mlm_acc_2": 0.13899646016950135, "train_loss_1": 4.690720419560804, "train_loss_2": 4.713829558673614, "train_loss": 9.404549971209772, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.186328752479117, "epoch": 268, "n_parameters": 106143056}
{"train_lr": 3.0015668720909095e-05, "train_min_lr": 3.0015668720909095e-05, "train_mlm_acc_1": 0.14084788083066885, "train_mlm_acc_2": 0.13904339015130002, "train_loss_1": 4.69131691469471, "train_loss_2": 4.7143380676536255, "train_loss": 9.405654977892404, "train_loss_scale": 1303.1908531222516, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 269, "n_parameters": 106143056}
{"train_lr": 2.8735826327303497e-05, "train_min_lr": 2.8735826327303497e-05, "train_mlm_acc_1": 0.14110377388404274, "train_mlm_acc_2": 0.13923082374390167, "train_loss_1": 4.68819666820969, "train_loss_2": 4.711258439768168, "train_loss": 9.399455110861108, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2091715548682234, "epoch": 270, "n_parameters": 106143056}
{"train_lr": 2.7497206341904298e-05, "train_min_lr": 2.7497206341904298e-05, "train_mlm_acc_1": 0.141083252081351, "train_mlm_acc_2": 0.13924257344711266, "train_loss_1": 4.688042650226972, "train_loss_2": 4.711037978805149, "train_loss": 9.399080630762072, "train_loss_scale": 1344.6191732629727, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2273676846251744, "epoch": 271, "n_parameters": 106143056}
{"train_lr": 2.629995412225849e-05, "train_min_lr": 2.629995412225849e-05, "train_mlm_acc_1": 0.14135563597754758, "train_mlm_acc_2": 0.13950229147342652, "train_loss_1": 4.685742881126119, "train_loss_2": 4.708751373314081, "train_loss": 9.39449425999701, "train_loss_scale": 1040.2110817941953, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 272, "n_parameters": 106143056}
{"train_lr": 2.514421017122239e-05, "train_min_lr": 2.514421017122239e-05, "train_mlm_acc_1": 0.14137692505161203, "train_mlm_acc_2": 0.13953642960041499, "train_loss_1": 4.6843965292606, "train_loss_2": 4.707387502715581, "train_loss": 9.391784024532154, "train_loss_scale": 1254.5576077396659, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2536793599132916, "epoch": 273, "n_parameters": 106143056}
{"train_lr": 2.4030110120472967e-05, "train_min_lr": 2.4030110120472967e-05, "train_mlm_acc_1": 0.14151253874791275, "train_mlm_acc_2": 0.1396427149339698, "train_loss_1": 4.6839298450223374, "train_loss_2": 4.706845645067874, "train_loss": 9.390775484376134, "train_loss_scale": 1708.467897977133, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 274, "n_parameters": 106143056}
{"train_lr": 2.29577847145909e-05, "train_min_lr": 2.29577847145909e-05, "train_mlm_acc_1": 0.1415436077402641, "train_mlm_acc_2": 0.1396987835279516, "train_loss_1": 4.6827985426786185, "train_loss_2": 4.7057777705586785, "train_loss": 9.388576316225393, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2654422039302062, "epoch": 275, "n_parameters": 106143056}
{"train_lr": 2.1927359795716904e-05, "train_min_lr": 2.1927359795716904e-05, "train_mlm_acc_1": 0.1416335626183407, "train_mlm_acc_2": 0.13982528143725378, "train_loss_1": 4.681537054459463, "train_loss_2": 4.704392202873448, "train_loss": 9.385929255288426, "train_loss_scale": 1610.3007915567282, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.2050304058464136, "epoch": 276, "n_parameters": 106143056}
{"train_lr": 2.093895628878402e-05, "train_min_lr": 2.093895628878402e-05, "train_mlm_acc_1": 0.14176419468821014, "train_mlm_acc_2": 0.13990539902446034, "train_loss_1": 4.680567780815936, "train_loss_2": 4.7035046993061025, "train_loss": 9.38407247729121, "train_loss_scale": 666.905892700088, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 277, "n_parameters": 106143056}
{"train_lr": 1.9992690187326e-05, "train_min_lr": 1.9992690187326e-05, "train_mlm_acc_1": 0.14189716289024684, "train_mlm_acc_2": 0.14002807202225545, "train_loss_1": 4.678791359158703, "train_loss_2": 4.701690303776069, "train_loss": 9.380481665031681, "train_loss_scale": 544.4221635883905, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.26078304200185, "epoch": 278, "n_parameters": 106143056}
{"train_lr": 1.9088672539865457e-05, "train_min_lr": 1.9088672539865457e-05, "train_mlm_acc_1": 0.1418980562612218, "train_mlm_acc_2": 0.14008442695492596, "train_loss_1": 4.678671987463533, "train_loss_2": 4.701587904778718, "train_loss": 9.380259888153278, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3072066841779724, "epoch": 279, "n_parameters": 106143056}
{"train_lr": 1.8227009436881574e-05, "train_min_lr": 1.8227009436881574e-05, "train_mlm_acc_1": 0.14194062300331123, "train_mlm_acc_2": 0.14010309364741688, "train_loss_1": 4.678054414093232, "train_loss_2": 4.7011010160861355, "train_loss": 9.379155434844991, "train_loss_scale": 824.9639401934917, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 280, "n_parameters": 106143056}
{"train_lr": 1.7407801998359794e-05, "train_min_lr": 1.7407801998359794e-05, "train_mlm_acc_1": 0.14206031847846748, "train_mlm_acc_2": 0.14023016419396028, "train_loss_1": 4.677275679985891, "train_loss_2": 4.700051138562493, "train_loss": 9.377326820330758, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3410942257761223, "epoch": 281, "n_parameters": 106143056}
{"train_lr": 1.6631146361925272e-05, "train_min_lr": 1.6631146361925272e-05, "train_mlm_acc_1": 0.14209776623838025, "train_mlm_acc_2": 0.1402430932955749, "train_loss_1": 4.676118179382518, "train_loss_2": 4.699129580350538, "train_loss": 9.375247757898261, "train_loss_scale": 834.4204045734389, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3319843840787784, "epoch": 282, "n_parameters": 106143056}
{"train_lr": 1.5897133671560495e-05, "train_min_lr": 1.5897133671560495e-05, "train_mlm_acc_1": 0.14217133342518604, "train_mlm_acc_2": 0.14034001093944282, "train_loss_1": 4.6749423050838494, "train_loss_2": 4.6978507777422065, "train_loss": 9.372793080624302, "train_loss_scale": 742.5576077396657, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 283, "n_parameters": 106143056}
{"train_lr": 1.5205850066909038e-05, "train_min_lr": 1.5205850066909038e-05, "train_mlm_acc_1": 0.1421747231657765, "train_mlm_acc_2": 0.140364586704934, "train_loss_1": 4.674831414495316, "train_loss_2": 4.697742429760956, "train_loss": 9.372573842998126, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.411340975195248, "epoch": 284, "n_parameters": 106143056}
{"train_lr": 1.4557376673166934e-05, "train_min_lr": 1.4557376673166934e-05, "train_mlm_acc_1": 0.14221532014260035, "train_mlm_acc_2": 0.14035426877134316, "train_loss_1": 4.674904155332788, "train_loss_2": 4.697757152789711, "train_loss": 9.372661305291672, "train_loss_scale": 916.8267370272647, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3588753633574635, "epoch": 285, "n_parameters": 106143056}
{"train_lr": 1.3951789591562158e-05, "train_min_lr": 1.3951789591562158e-05, "train_mlm_acc_1": 0.14242186708082571, "train_mlm_acc_2": 0.1405542764571891, "train_loss_1": 4.672713774175317, "train_loss_2": 4.695684824528774, "train_loss": 9.368398606410231, "train_loss_scale": 519.2049252418645, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 286, "n_parameters": 106143056}
{"train_lr": 1.3389159890423752e-05, "train_min_lr": 1.3389159890423752e-05, "train_mlm_acc_1": 0.14236682918817198, "train_mlm_acc_2": 0.14050868631438038, "train_loss_1": 4.673195838508841, "train_loss_2": 4.696035961100378, "train_loss": 9.369231801339168, "train_loss_scale": 628.179419525066, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.4201554023286387, "epoch": 287, "n_parameters": 106143056}
{"train_lr": 1.2869553596841708e-05, "train_min_lr": 1.2869553596841708e-05, "train_mlm_acc_1": 0.14243254025213636, "train_mlm_acc_2": 0.140596282000841, "train_loss_1": 4.672340677145184, "train_loss_2": 4.695229885708164, "train_loss": 9.367570558554684, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.417834119515767, "epoch": 288, "n_parameters": 106143056}
{"train_lr": 1.2393031688918403e-05, "train_min_lr": 1.2393031688918403e-05, "train_mlm_acc_1": 0.1424679381276498, "train_mlm_acc_2": 0.1406226442904001, "train_loss_1": 4.671901127488968, "train_loss_2": 4.694660524212695, "train_loss": 9.366561656576977, "train_loss_scale": 1162.6948109058926, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 289, "n_parameters": 106143056}
{"train_lr": 1.1959650088612536e-05, "train_min_lr": 1.1959650088612536e-05, "train_mlm_acc_1": 0.14259979552724508, "train_mlm_acc_2": 0.14075613936954878, "train_loss_1": 4.670798050591897, "train_loss_2": 4.693661622919319, "train_loss": 9.364459674402402, "train_loss_scale": 823.1627088830255, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 290, "n_parameters": 106143056}
{"train_lr": 1.1569459655176374e-05, "train_min_lr": 1.1569459655176374e-05, "train_mlm_acc_1": 0.14270458070490846, "train_mlm_acc_2": 0.14083090896751788, "train_loss_1": 4.669130679328083, "train_loss_2": 4.69208664315357, "train_loss": 9.36121731760634, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.398696690247367, "epoch": 291, "n_parameters": 106143056}
{"train_lr": 1.1222506179187317e-05, "train_min_lr": 1.1222506179187317e-05, "train_mlm_acc_1": 0.14263386507055795, "train_mlm_acc_2": 0.14077162235015275, "train_loss_1": 4.670186737753785, "train_loss_2": 4.693015544060143, "train_loss": 9.36320228301965, "train_loss_scale": 519.2049252418645, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 292, "n_parameters": 106143056}
{"train_lr": 1.0918830377174124e-05, "train_min_lr": 1.0918830377174124e-05, "train_mlm_acc_1": 0.14268426487194463, "train_mlm_acc_2": 0.14083870774234925, "train_loss_1": 4.669192354723143, "train_loss_2": 4.692052897121577, "train_loss": 9.361245255461888, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.4601825065746996, "epoch": 293, "n_parameters": 106143056}
{"train_lr": 1.0658467886838543e-05, "train_min_lr": 1.0658467886838543e-05, "train_mlm_acc_1": 0.14287156098183956, "train_mlm_acc_2": 0.1410119752862418, "train_loss_1": 4.66791876083733, "train_loss_2": 4.690747456322035, "train_loss": 9.358666211550133, "train_loss_scale": 952.4010554089709, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.431906792817665, "epoch": 294, "n_parameters": 106143056}
{"train_lr": 1.0441449262873223e-05, "train_min_lr": 1.0441449262873223e-05, "train_mlm_acc_1": 0.1428050369027553, "train_mlm_acc_2": 0.14094383641667893, "train_loss_1": 4.667890163398984, "train_loss_2": 4.690753627630736, "train_loss": 9.358643790348225, "train_loss_scale": 693.023746701847, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 295, "n_parameters": 106143056}
{"train_lr": 1.0267799973375903e-05, "train_min_lr": 1.0267799973375903e-05, "train_mlm_acc_1": 0.1426885021136207, "train_mlm_acc_2": 0.14083191677895207, "train_loss_1": 4.669204649006786, "train_loss_2": 4.6920360615091985, "train_loss": 9.361240707370621, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.4177734146227206, "epoch": 296, "n_parameters": 106143056}
{"train_lr": 1.0137540396860598e-05, "train_min_lr": 1.0137540396860598e-05, "train_mlm_acc_1": 0.1427670852645655, "train_mlm_acc_2": 0.1409279410166235, "train_loss_1": 4.668573036567097, "train_loss_2": 4.691387855388034, "train_loss": 9.359960894366576, "train_loss_scale": 966.3605980650835, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.411632843256626, "epoch": 297, "n_parameters": 106143056}
{"train_lr": 1.0050685819866211e-05, "train_min_lr": 1.0050685819866211e-05, "train_mlm_acc_1": 0.1428418777368655, "train_mlm_acc_2": 0.1409659843806672, "train_loss_1": 4.667687765998387, "train_loss_2": 4.6905906416914815, "train_loss": 9.358278409367395, "train_loss_scale": 641.2383465259454, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 298, "n_parameters": 106143056}
{"train_lr": 1.0007246435162376e-05, "train_min_lr": 1.0007246435162376e-05, "train_mlm_acc_1": 0.1428021051754672, "train_mlm_acc_2": 0.1409564678251691, "train_loss_1": 4.6675107988120175, "train_loss_2": 4.690326647110539, "train_loss": 9.357837449382457, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.468542492903422, "epoch": 299, "n_parameters": 106143056}
