{"train_lr": 3.7470314011786434e-05, "train_min_lr": 3.7470314011786434e-05, "train_mlm_acc_1": 0.02493606451538919, "train_mlm_acc_2": 0.025025045929363787, "train_loss_1": 7.492066142007564, "train_loss_2": 7.487044754003158, "train_loss": 14.979110892026593, "train_loss_scale": 440.1759014951627, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 0, "n_parameters": 106143056}
{"train_lr": 0.00011247691089805615, "train_min_lr": 0.00011247691089805615, "train_mlm_acc_1": 0.051444512096511345, "train_mlm_acc_2": 0.05120584260174315, "train_loss_1": 6.353559284904282, "train_loss_2": 6.357086176608043, "train_loss": 12.71064546429073, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.459189895904158, "epoch": 1, "n_parameters": 106143056}
{"train_lr": 0.00018748350778432582, "train_min_lr": 0.00018748350778432582, "train_mlm_acc_1": 0.0602545546099098, "train_mlm_acc_2": 0.059952006338650755, "train_loss_1": 6.106994361340632, "train_loss_2": 6.113225616377073, "train_loss": 12.220219976774096, "train_loss_scale": 447.155672823219, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.348850750776373, "epoch": 2, "n_parameters": 106143056}
{"train_lr": 0.0002624901046705954, "train_min_lr": 0.0002624901046705954, "train_mlm_acc_1": 0.06521994705707582, "train_mlm_acc_2": 0.06481469794739245, "train_loss_1": 5.967431843490483, "train_loss_2": 5.976499711355832, "train_loss": 11.943931546144142, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.2567539045238245, "epoch": 3, "n_parameters": 106143056}
{"train_lr": 0.0003374967015568651, "train_min_lr": 0.0003374967015568651, "train_mlm_acc_1": 0.06860909724473731, "train_mlm_acc_2": 0.06813099096335058, "train_loss_1": 5.870999998132073, "train_loss_2": 5.881611609679099, "train_loss": 11.75261160587153, "train_loss_scale": 1017.6956904133685, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.5845701226877766, "epoch": 4, "n_parameters": 106143056}
{"train_lr": 0.0004125032984431348, "train_min_lr": 0.0004125032984431348, "train_mlm_acc_1": 0.07127050066361877, "train_mlm_acc_2": 0.07073479127826901, "train_loss_1": 5.798687581441438, "train_loss_2": 5.810316619059446, "train_loss": 11.609004199976656, "train_loss_scale": 1258.160070360598, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.1976746956087982, "epoch": 5, "n_parameters": 106143056}
{"train_lr": 0.00048750989532940465, "train_min_lr": 0.00048750989532940465, "train_mlm_acc_1": 0.07324687311861569, "train_mlm_acc_2": 0.07266344357955228, "train_loss_1": 5.745177952836455, "train_loss_2": 5.757418351993293, "train_loss": 11.50259630776542, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.721944193726794, "epoch": 6, "n_parameters": 106143056}
{"train_lr": 0.0005625164922156739, "train_min_lr": 0.0005625164922156739, "train_mlm_acc_1": 0.07476319903556974, "train_mlm_acc_2": 0.07414127959113768, "train_loss_1": 5.704402759710528, "train_loss_2": 5.717479595775235, "train_loss": 11.421882355328496, "train_loss_scale": 3009.857519788918, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.599837621262751, "epoch": 7, "n_parameters": 106143056}
{"train_lr": 0.0006375230891019436, "train_min_lr": 0.0006375230891019436, "train_mlm_acc_1": 0.07607752448537615, "train_mlm_acc_2": 0.07545649831116907, "train_loss_1": 5.671492225891053, "train_loss_2": 5.685101227793865, "train_loss": 11.356593453265537, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1705242594607377, "epoch": 8, "n_parameters": 106143056}
{"train_lr": 0.0007125296859882135, "train_min_lr": 0.0007125296859882135, "train_mlm_acc_1": 0.07670851382603025, "train_mlm_acc_2": 0.07604476049699695, "train_loss_1": 5.6519145024588155, "train_loss_2": 5.66641269436822, "train_loss": 11.318327195516467, "train_loss_scale": 3177.372031662269, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 9, "n_parameters": 106143056}
{"train_lr": 0.0007499927726594455, "train_min_lr": 0.0007499927726594455, "train_mlm_acc_1": 0.07848030915885194, "train_mlm_acc_2": 0.07775783040310955, "train_loss_1": 5.612096765267817, "train_loss_2": 5.627112475789841, "train_loss": 11.239209240743122, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7691799188876425, "epoch": 10, "n_parameters": 106143056}
{"train_lr": 0.0007499493714617194, "train_min_lr": 0.0007499493714617194, "train_mlm_acc_1": 0.07987257637527485, "train_mlm_acc_2": 0.07910091164722553, "train_loss_1": 5.584879275676758, "train_loss_2": 5.600527439446647, "train_loss": 11.185406714546755, "train_loss_scale": 3816.8091468777484, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9817088762709416, "epoch": 11, "n_parameters": 106143056}
{"train_lr": 0.0007498625550649799, "train_min_lr": 0.0007498625550649799, "train_mlm_acc_1": 0.08161788342378071, "train_mlm_acc_2": 0.08084870374080845, "train_loss_1": 5.546789244852678, "train_loss_2": 5.562965906022826, "train_loss": 11.109755146052613, "train_loss_scale": 4524.693051890941, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.425527696034944, "epoch": 12, "n_parameters": 106143056}
{"train_lr": 0.000749732333657516, "train_min_lr": 0.000749732333657516, "train_mlm_acc_1": 0.08302965329627432, "train_mlm_acc_2": 0.08220276736352092, "train_loss_1": 5.518117818794653, "train_loss_2": 5.534693833863201, "train_loss": 11.052811651347286, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4109630173198362, "epoch": 13, "n_parameters": 106143056}
{"train_lr": 0.0007495587225213875, "train_min_lr": 0.0007495587225213875, "train_mlm_acc_1": 0.08414108506850276, "train_mlm_acc_2": 0.08329249775936547, "train_loss_1": 5.495080909135579, "train_loss_2": 5.512080408337877, "train_loss": 11.007161318574333, "train_loss_scale": 11023.535620052771, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3717927359758812, "epoch": 14, "n_parameters": 106143056}
{"train_lr": 0.0007493417420306326, "train_min_lr": 0.0007493417420306326, "train_mlm_acc_1": 0.08522475738792616, "train_mlm_acc_2": 0.08429759846903587, "train_loss_1": 5.474086547380177, "train_loss_2": 5.491459256845707, "train_loss": 10.965545807476094, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3202292891899117, "epoch": 15, "n_parameters": 106143056}
{"train_lr": 0.0007490814176488726, "train_min_lr": 0.0007490814176488726, "train_mlm_acc_1": 0.08607994100093684, "train_mlm_acc_2": 0.08518053007557032, "train_loss_1": 5.4561902370071245, "train_loss_2": 5.473930964736217, "train_loss": 10.930121196815605, "train_loss_scale": 16650.58223394899, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 16, "n_parameters": 106143056}
{"train_lr": 0.0007487777799263258, "train_min_lr": 0.0007487777799263258, "train_mlm_acc_1": 0.08698689877551144, "train_mlm_acc_2": 0.08603472883912194, "train_loss_1": 5.439694204871447, "train_loss_2": 5.457766195138295, "train_loss": 10.897460405618975, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2588145193973967, "epoch": 17, "n_parameters": 106143056}
{"train_lr": 0.0007484308644962306, "train_min_lr": 0.0007484308644962306, "train_mlm_acc_1": 0.0876664443116835, "train_mlm_acc_2": 0.08672477576386907, "train_loss_1": 5.425438729418718, "train_loss_2": 5.443696432346404, "train_loss": 10.869135158777027, "train_loss_scale": 11326.142480211081, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1948074111313598, "epoch": 18, "n_parameters": 106143056}
{"train_lr": 0.000748040712070646, "train_min_lr": 0.000748040712070646, "train_mlm_acc_1": 0.08840243630733738, "train_mlm_acc_2": 0.08741987295196496, "train_loss_1": 5.411467020199188, "train_loss_2": 5.429983011860541, "train_loss": 10.841450032583957, "train_loss_scale": 15022.269129287599, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 19, "n_parameters": 106143056}
{"train_lr": 0.0007476073684356914, "train_min_lr": 0.0007476073684356914, "train_mlm_acc_1": 0.08894337924719906, "train_mlm_acc_2": 0.08794188588077863, "train_loss_1": 5.400342150120329, "train_loss_2": 5.419220428877791, "train_loss": 10.81956258361132, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.154267365301295, "epoch": 20, "n_parameters": 106143056}
{"train_lr": 0.0007471308844461622, "train_min_lr": 0.0007471308844461622, "train_mlm_acc_1": 0.08960657139622467, "train_mlm_acc_2": 0.0885869954518561, "train_loss_1": 5.388154168294623, "train_loss_2": 5.407077717068118, "train_loss": 10.795231886044236, "train_loss_scale": 11527.88038698329, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1474660830007064, "epoch": 21, "n_parameters": 106143056}
{"train_lr": 0.00074661131601957, "train_min_lr": 0.00074661131601957, "train_mlm_acc_1": 0.08953413803117283, "train_mlm_acc_2": 0.08853668716663238, "train_loss_1": 5.389946147969866, "train_loss_2": 5.409090902318845, "train_loss": 10.799037048978143, "train_loss_scale": 5850.399296394019, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 22, "n_parameters": 106143056}
{"train_lr": 0.0007460487241295682, "train_min_lr": 0.0007460487241295682, "train_mlm_acc_1": 0.09063486233615728, "train_mlm_acc_2": 0.0895458189557612, "train_loss_1": 5.369689625926257, "train_loss_2": 5.388954653117147, "train_loss": 10.758644284023564, "train_loss_scale": 4495.873350923483, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0961725215903477, "epoch": 23, "n_parameters": 106143056}
{"train_lr": 0.0007454431747988132, "train_min_lr": 0.0007454431747988132, "train_mlm_acc_1": 0.09101685251886633, "train_mlm_acc_2": 0.08999204306012198, "train_loss_1": 5.361322062520888, "train_loss_2": 5.38075657517845, "train_loss": 10.742078641893157, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.103236036858437, "epoch": 24, "n_parameters": 106143056}
{"train_lr": 0.0007447947390912042, "train_min_lr": 0.0007447947390912042, "train_mlm_acc_1": 0.0914270832222168, "train_mlm_acc_2": 0.09036892576580548, "train_loss_1": 5.3535929265101965, "train_loss_2": 5.373084116946634, "train_loss": 10.726677035803112, "train_loss_scale": 10965.896218117854, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1013094232390612, "epoch": 25, "n_parameters": 106143056}
{"train_lr": 0.0007441034931035458, "train_min_lr": 0.0007441034931035458, "train_mlm_acc_1": 0.0918040689918079, "train_mlm_acc_2": 0.09074523593909324, "train_loss_1": 5.346526558344681, "train_loss_2": 5.366167175214125, "train_loss": 10.712693728893182, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.088355840405772, "epoch": 26, "n_parameters": 106143056}
{"train_lr": 0.0007433695179566179, "train_min_lr": 0.0007433695179566179, "train_mlm_acc_1": 0.09219794637681679, "train_mlm_acc_2": 0.09109638613241618, "train_loss_1": 5.3386591745764935, "train_loss_2": 5.358437617410141, "train_loss": 10.697096794240812, "train_loss_scale": 17392.689533861037, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 27, "n_parameters": 106143056}
{"train_lr": 0.0007425928997856612, "train_min_lr": 0.0007425928997856612, "train_mlm_acc_1": 0.09251098461832487, "train_mlm_acc_2": 0.0913680141952246, "train_loss_1": 5.332814719557447, "train_loss_2": 5.352819034480797, "train_loss": 10.685633754772162, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0664910736478204, "epoch": 28, "n_parameters": 106143056}
{"train_lr": 0.0007417737297302581, "train_min_lr": 0.0007417737297302581, "train_mlm_acc_1": 0.09272262754890226, "train_mlm_acc_2": 0.0916160857345886, "train_loss_1": 5.32808633461896, "train_loss_2": 5.348041939179732, "train_loss": 10.676128275581064, "train_loss_scale": 17695.296394019348, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 29, "n_parameters": 106143056}
{"train_lr": 0.0007409121039236501, "train_min_lr": 0.0007409121039236501, "train_mlm_acc_1": 0.09308849350142186, "train_mlm_acc_2": 0.09198578804724816, "train_loss_1": 5.3207862541774125, "train_loss_2": 5.340908083353739, "train_loss": 10.661694336797233, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0659128591064413, "epoch": 30, "n_parameters": 106143056}
{"train_lr": 0.000740008123481444, "train_min_lr": 0.000740008123481444, "train_mlm_acc_1": 0.09342018693272702, "train_mlm_acc_2": 0.09228040018956862, "train_loss_1": 5.315351057545386, "train_loss_2": 5.335590770397673, "train_loss": 10.650941822543517, "train_loss_scale": 18660.7563764292, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 31, "n_parameters": 106143056}
{"train_lr": 0.0007390618944897517, "train_min_lr": 0.0007390618944897517, "train_mlm_acc_1": 0.09372037613441678, "train_mlm_acc_2": 0.09261897621101314, "train_loss_1": 5.31040841540225, "train_loss_2": 5.330648428636784, "train_loss": 10.641056846922284, "train_loss_scale": 16614.557607739665, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 32, "n_parameters": 106143056}
{"train_lr": 0.0007380735279927422, "train_min_lr": 0.0007380735279927422, "train_mlm_acc_1": 0.09404222091959696, "train_mlm_acc_2": 0.0928722926945464, "train_loss_1": 5.305436862018303, "train_loss_2": 5.325803268291286, "train_loss": 10.631240130519279, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0548496548292818, "epoch": 33, "n_parameters": 106143056}
{"train_lr": 0.0007370431399796046, "train_min_lr": 0.0007370431399796046, "train_mlm_acc_1": 0.09415671718286361, "train_mlm_acc_2": 0.092994519033475, "train_loss_1": 5.300639327671199, "train_loss_2": 5.321022826899744, "train_loss": 10.621662148385061, "train_loss_scale": 17104.492524186455, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 34, "n_parameters": 106143056}
{"train_lr": 0.0007359708513709434, "train_min_lr": 0.0007359708513709434, "train_mlm_acc_1": 0.09452880159587244, "train_mlm_acc_2": 0.09336533222065725, "train_loss_1": 5.295583202740343, "train_loss_2": 5.316174960859847, "train_loss": 10.61175816375746, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.03213379963931, "epoch": 35, "n_parameters": 106143056}
{"train_lr": 0.000734856788004579, "train_min_lr": 0.000734856788004579, "train_mlm_acc_1": 0.09462926921695995, "train_mlm_acc_2": 0.09349305544657963, "train_loss_1": 5.292696047217152, "train_loss_2": 5.3133252319161475, "train_loss": 10.606021275411285, "train_loss_scale": 10411.116974494284, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 36, "n_parameters": 106143056}
{"train_lr": 0.0007337010806207864, "train_min_lr": 0.0007337010806207864, "train_mlm_acc_1": 0.09491354026549095, "train_mlm_acc_2": 0.09376604638489171, "train_loss_1": 5.288249659768929, "train_loss_2": 5.308903953330812, "train_loss": 10.597153614148196, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0795887361625462, "epoch": 37, "n_parameters": 106143056}
{"train_lr": 0.0007325038648469556, "train_min_lr": 0.0007325038648469556, "train_mlm_acc_1": 0.09512952352950158, "train_mlm_acc_2": 0.09394588735586945, "train_loss_1": 5.284494020064463, "train_loss_2": 5.305319228346345, "train_loss": 10.589813246051785, "train_loss_scale": 15728.351802990326, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 38, "n_parameters": 106143056}
{"train_lr": 0.000731265281181661, "train_min_lr": 0.000731265281181661, "train_mlm_acc_1": 0.09535920319271093, "train_mlm_acc_2": 0.09416197362645032, "train_loss_1": 5.279799572500935, "train_loss_2": 5.300599483093255, "train_loss": 10.580399051610062, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0664823475173406, "epoch": 39, "n_parameters": 106143056}
{"train_lr": 0.0007299854749781874, "train_min_lr": 0.0007299854749781874, "train_mlm_acc_1": 0.09550445934588854, "train_mlm_acc_2": 0.09432228909200917, "train_loss_1": 5.277197220499513, "train_loss_2": 5.297992798562834, "train_loss": 10.575190019586575, "train_loss_scale": 10576.830255057168, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0609913204150339, "epoch": 40, "n_parameters": 106143056}
{"train_lr": 0.0007286645964274694, "train_min_lr": 0.0007286645964274694, "train_mlm_acc_1": 0.09573498653803306, "train_mlm_acc_2": 0.0945129062719938, "train_loss_1": 5.272968795127584, "train_loss_2": 5.293868747634015, "train_loss": 10.566837539039584, "train_loss_scale": 16384.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0630324590384383, "epoch": 41, "n_parameters": 106143056}
{"train_lr": 0.0007273028005404614, "train_min_lr": 0.0007273028005404614, "train_mlm_acc_1": 0.09586341980199281, "train_mlm_acc_2": 0.09465393667799817, "train_loss_1": 5.270176446532196, "train_loss_2": 5.291102850342804, "train_loss": 10.561279296036236, "train_loss_scale": 17673.681618293755, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 42, "n_parameters": 106143056}
{"train_lr": 0.0007259002471299484, "train_min_lr": 0.0007259002471299484, "train_mlm_acc_1": 0.0960541859165935, "train_mlm_acc_2": 0.09486964505850587, "train_loss_1": 5.2670077427291195, "train_loss_2": 5.288025058144106, "train_loss": 10.555032800663534, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0766672774061574, "epoch": 43, "n_parameters": 106143056}
{"train_lr": 0.0007244571007917912, "train_min_lr": 0.0007244571007917912, "train_mlm_acc_1": 0.09619574310878913, "train_mlm_acc_2": 0.0950040333857637, "train_loss_1": 5.264792632721135, "train_loss_2": 5.285711894091956, "train_loss": 10.55050452854304, "train_loss_scale": 10303.043095866315, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.065577234892648, "epoch": 44, "n_parameters": 106143056}
{"train_lr": 0.0007229735308856102, "train_min_lr": 0.0007229735308856102, "train_mlm_acc_1": 0.09632471462313606, "train_mlm_acc_2": 0.09511228836089923, "train_loss_1": 5.261787425821669, "train_loss_2": 5.2828100443725114, "train_loss": 10.544597468044849, "train_loss_scale": 8433.364995602462, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 45, "n_parameters": 106143056}
{"train_lr": 0.0007214497115149132, "train_min_lr": 0.0007214497115149132, "train_mlm_acc_1": 0.09650038710484903, "train_mlm_acc_2": 0.09531479264734839, "train_loss_1": 5.2587607539633225, "train_loss_2": 5.279709735247999, "train_loss": 10.538470491570344, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0592607879387044, "epoch": 46, "n_parameters": 106143056}
{"train_lr": 0.0007198858215066601, "train_min_lr": 0.0007198858215066601, "train_mlm_acc_1": 0.09667959818804904, "train_mlm_acc_2": 0.09546893548053298, "train_loss_1": 5.255571473819075, "train_loss_2": 5.2767089065901525, "train_loss": 10.532280382715827, "train_loss_scale": 5735.120492524186, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0620885900268453, "epoch": 47, "n_parameters": 106143056}
{"train_lr": 0.0007182820443902745, "train_min_lr": 0.0007182820443902745, "train_mlm_acc_1": 0.09677989414680943, "train_mlm_acc_2": 0.09556557828185322, "train_loss_1": 5.2532470495740675, "train_loss_2": 5.274412658252314, "train_loss": 10.527659710919322, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0773861869553671, "epoch": 48, "n_parameters": 106143056}
{"train_lr": 0.0007166385683761166, "train_min_lr": 0.0007166385683761166, "train_mlm_acc_1": 0.09698061196243254, "train_mlm_acc_2": 0.09575594352638528, "train_loss_1": 5.250047105073719, "train_loss_2": 5.271207712151654, "train_loss": 10.521254813870318, "train_loss_scale": 13444.390501319262, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0743033610736474, "epoch": 49, "n_parameters": 106143056}
{"train_lr": 0.0007149555863333774, "train_min_lr": 0.0007149555863333774, "train_mlm_acc_1": 0.09710381167761412, "train_mlm_acc_2": 0.09587111555305272, "train_loss_1": 5.248318309257611, "train_loss_2": 5.269499877459561, "train_loss": 10.517818188394699, "train_loss_scale": 9820.313104661389, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 50, "n_parameters": 106143056}
{"train_lr": 0.0007132332957674665, "train_min_lr": 0.0007132332957674665, "train_mlm_acc_1": 0.09726546699854503, "train_mlm_acc_2": 0.09602198312706138, "train_loss_1": 5.245264588475961, "train_loss_2": 5.2665305545483125, "train_loss": 10.51179514679871, "train_loss_scale": 8537.836411609498, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.093336567557896, "epoch": 51, "n_parameters": 106143056}
{"train_lr": 0.0007114718987968146, "train_min_lr": 0.0007114718987968146, "train_mlm_acc_1": 0.09737961973074297, "train_mlm_acc_2": 0.09617696199713564, "train_loss_1": 5.24265916292984, "train_loss_2": 5.263855582072007, "train_loss": 10.506514741646793, "train_loss_scale": 8285.66402814424, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 52, "n_parameters": 106143056}
{"train_lr": 0.0007096716021291684, "train_min_lr": 0.0007096716021291684, "train_mlm_acc_1": 0.09744964825135238, "train_mlm_acc_2": 0.09618937582016751, "train_loss_1": 5.241218023952309, "train_loss_2": 5.26250493704696, "train_loss": 10.503722958745092, "train_loss_scale": 8883.672823218998, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 53, "n_parameters": 106143056}
{"train_lr": 0.0007078326170373227, "train_min_lr": 0.0007078326170373227, "train_mlm_acc_1": 0.09767783921057967, "train_mlm_acc_2": 0.09645302198244064, "train_loss_1": 5.238719952295198, "train_loss_2": 5.259970433531671, "train_loss": 10.498690388028624, "train_loss_scale": 6549.277044854881, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 54, "n_parameters": 106143056}
{"train_lr": 0.000705955159334333, "train_min_lr": 0.000705955159334333, "train_mlm_acc_1": 0.09768057621035826, "train_mlm_acc_2": 0.09646306529382315, "train_loss_1": 5.2370699488393235, "train_loss_2": 5.2584206612883895, "train_loss": 10.495490614950604, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.089224606201957, "epoch": 55, "n_parameters": 106143056}
{"train_lr": 0.0007040394493481837, "train_min_lr": 0.0007040394493481837, "train_mlm_acc_1": 0.09730542279049269, "train_mlm_acc_2": 0.09605440351925298, "train_loss_1": 5.245071043230088, "train_loss_2": 5.266485702236598, "train_loss": 10.511556745204572, "train_loss_scale": 3296.2532981530344, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 56, "n_parameters": 106143056}
{"train_lr": 0.0007020857118959358, "train_min_lr": 0.0007020857118959358, "train_mlm_acc_1": 0.09802846265129463, "train_mlm_acc_2": 0.09673921690832761, "train_loss_1": 5.232269478871724, "train_loss_2": 5.2535445640353435, "train_loss": 10.485814042120726, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0556787542323849, "epoch": 57, "n_parameters": 106143056}
{"train_lr": 0.0007000941762573423, "train_min_lr": 0.0007000941762573423, "train_mlm_acc_1": 0.0979631294602022, "train_mlm_acc_2": 0.09675047414093921, "train_loss_1": 5.231421560284959, "train_loss_2": 5.252835651029068, "train_loss": 10.484257206858096, "train_loss_scale": 3683.518029903254, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.091094905122289, "epoch": 58, "n_parameters": 106143056}
{"train_lr": 0.0006980650761479382, "train_min_lr": 0.0006980650761479382, "train_mlm_acc_1": 0.09827978653618664, "train_mlm_acc_2": 0.09704548711319214, "train_loss_1": 5.227193786842108, "train_loss_2": 5.24856998266205, "train_loss": 10.475763774798853, "train_loss_scale": 4258.1108179419525, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1011187798010222, "epoch": 59, "n_parameters": 106143056}
{"train_lr": 0.0006959986496916213, "train_min_lr": 0.0006959986496916213, "train_mlm_acc_1": 0.09828853577689949, "train_mlm_acc_2": 0.09700939066957096, "train_loss_1": 5.225739340931046, "train_loss_2": 5.247171879915575, "train_loss": 10.472911219588475, "train_loss_scale": 7176.105540897098, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 60, "n_parameters": 106143056}
{"train_lr": 0.0006938951393926957, "train_min_lr": 0.0006938951393926957, "train_mlm_acc_1": 0.09841568643930011, "train_mlm_acc_2": 0.09710793440838786, "train_loss_1": 5.224147857598495, "train_loss_2": 5.245639954886105, "train_loss": 10.469787816259037, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.0680909819422633, "epoch": 61, "n_parameters": 106143056}
{"train_lr": 0.0006917547921074234, "train_min_lr": 0.0006917547921074234, "train_mlm_acc_1": 0.09858376633215339, "train_mlm_acc_2": 0.09730440357219995, "train_loss_1": 5.221497803480875, "train_loss_2": 5.2429487576270795, "train_loss": 10.464446564043627, "train_loss_scale": 6098.969217238347, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1149568176626006, "epoch": 62, "n_parameters": 106143056}
{"train_lr": 0.0006895778590150455, "train_min_lr": 0.0006895778590150455, "train_mlm_acc_1": 0.09863237967336241, "train_mlm_acc_2": 0.09739146103448477, "train_loss_1": 5.22053121603049, "train_loss_2": 5.24202252063399, "train_loss": 10.462553737031438, "train_loss_scale": 4582.332453825858, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 63, "n_parameters": 106143056}
{"train_lr": 0.0006873645955883147, "train_min_lr": 0.0006873645955883147, "train_mlm_acc_1": 0.09875742318772153, "train_mlm_acc_2": 0.09746438687586978, "train_loss_1": 5.218158130647849, "train_loss_2": 5.239636352477413, "train_loss": 10.457794484068872, "train_loss_scale": 4596.742304309587, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1006928066360184, "epoch": 64, "n_parameters": 106143056}
{"train_lr": 0.0006851152615635071, "train_min_lr": 0.0006851152615635071, "train_mlm_acc_1": 0.09887487412386933, "train_mlm_acc_2": 0.09761940004597291, "train_loss_1": 5.216001474343588, "train_loss_2": 5.2375158565340065, "train_loss": 10.453517330143676, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.097260971182569, "epoch": 65, "n_parameters": 106143056}
{"train_lr": 0.0006828301209099406, "train_min_lr": 0.0006828301209099406, "train_mlm_acc_1": 0.09898097620148248, "train_mlm_acc_2": 0.09772861698722646, "train_loss_1": 5.2143746123255195, "train_loss_2": 5.235943471588581, "train_loss": 10.450318083494718, "train_loss_scale": 11167.63412489006, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1271465268697043, "epoch": 66, "n_parameters": 106143056}
{"train_lr": 0.0006805094417990081, "train_min_lr": 0.0006805094417990081, "train_mlm_acc_1": 0.09907493914953427, "train_mlm_acc_2": 0.09779106432665385, "train_loss_1": 5.212654094949771, "train_loss_2": 5.234258547988815, "train_loss": 10.446912645664568, "train_loss_scale": 13206.62796833773, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 67, "n_parameters": 106143056}
{"train_lr": 0.0006781534965726882, "train_min_lr": 0.0006781534965726882, "train_mlm_acc_1": 0.0992074378699772, "train_mlm_acc_2": 0.09793193444278724, "train_loss_1": 5.210628284680393, "train_loss_2": 5.232238679206885, "train_loss": 10.44286696315336, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1236955023378055, "epoch": 68, "n_parameters": 106143056}
{"train_lr": 0.0006757625617116008, "train_min_lr": 0.0006757625617116008, "train_mlm_acc_1": 0.09920214710752222, "train_mlm_acc_2": 0.0979738140850604, "train_loss_1": 5.209496542300272, "train_loss_2": 5.231126593253858, "train_loss": 10.440623135658976, "train_loss_scale": 13343.521547933158, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1362107563354304, "epoch": 69, "n_parameters": 106143056}
{"train_lr": 0.0006733369178025507, "train_min_lr": 0.0006733369178025507, "train_mlm_acc_1": 0.09932315956863429, "train_mlm_acc_2": 0.09806411251386427, "train_loss_1": 5.207886711641058, "train_loss_2": 5.229304502591189, "train_loss": 10.437191213236217, "train_loss_scale": 11412.601583113457, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 70, "n_parameters": 106143056}
{"train_lr": 0.000670876849505609, "train_min_lr": 0.000670876849505609, "train_mlm_acc_1": 0.09945824642959743, "train_mlm_acc_2": 0.09815966734120404, "train_loss_1": 5.205384486268882, "train_loss_2": 5.226911121433832, "train_loss": 10.43229560476704, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1094435490635055, "epoch": 71, "n_parameters": 106143056}
{"train_lr": 0.000668382645520696, "train_min_lr": 0.000668382645520696, "train_mlm_acc_1": 0.09957038361919927, "train_mlm_acc_2": 0.09827182744609203, "train_loss_1": 5.203625910567315, "train_loss_2": 5.225352829133825, "train_loss": 10.428978738285725, "train_loss_scale": 8336.098504837291, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 72, "n_parameters": 106143056}
{"train_lr": 0.0006658545985537059, "train_min_lr": 0.0006658545985537059, "train_mlm_acc_1": 0.09961710747400186, "train_mlm_acc_2": 0.09838032289248422, "train_loss_1": 5.202618627665645, "train_loss_2": 5.224324838572043, "train_loss": 10.426943461205106, "train_loss_scale": 8775.598944591029, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.145168772473499, "epoch": 73, "n_parameters": 106143056}
{"train_lr": 0.0006632930052821623, "train_min_lr": 0.0006632930052821623, "train_mlm_acc_1": 0.09975514889808607, "train_mlm_acc_2": 0.09849045605692773, "train_loss_1": 5.201154691090999, "train_loss_2": 5.222810809299835, "train_loss": 10.423965507048521, "train_loss_scale": 8199.204925241864, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 74, "n_parameters": 106143056}
{"train_lr": 0.0006606981663203897, "train_min_lr": 0.0006606981663203897, "train_mlm_acc_1": 0.0999046995189031, "train_mlm_acc_2": 0.09860121901331366, "train_loss_1": 5.198587353175003, "train_loss_2": 5.220214418654077, "train_loss": 10.418801774030834, "train_loss_scale": 8523.426561125769, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 75, "n_parameters": 106143056}
{"train_lr": 0.0006580703861842497, "train_min_lr": 0.0006580703861842497, "train_mlm_acc_1": 0.0999538740937712, "train_mlm_acc_2": 0.09865298171313898, "train_loss_1": 5.196950890877421, "train_loss_2": 5.2186600798143035, "train_loss": 10.415610968280278, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1323253556941828, "epoch": 76, "n_parameters": 106143056}
{"train_lr": 0.0006554099732553881, "train_min_lr": 0.0006554099732553881, "train_mlm_acc_1": 0.10006256421770747, "train_mlm_acc_2": 0.0987800178351495, "train_loss_1": 5.195379607648103, "train_loss_2": 5.21719149224257, "train_loss": 10.412571100886705, "train_loss_scale": 11801.667546174143, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1402445907328562, "epoch": 77, "n_parameters": 106143056}
{"train_lr": 0.0006527172397450622, "train_min_lr": 0.0006527172397450622, "train_mlm_acc_1": 0.1000186575981301, "train_mlm_acc_2": 0.09874508950757739, "train_loss_1": 5.194515402681909, "train_loss_2": 5.216361429624214, "train_loss": 10.410876832935196, "train_loss_scale": 10000.436235708003, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 78, "n_parameters": 106143056}
{"train_lr": 0.0006499925016574828, "train_min_lr": 0.0006499925016574828, "train_mlm_acc_1": 0.10021268746921286, "train_mlm_acc_2": 0.09892212474848108, "train_loss_1": 5.192714186121522, "train_loss_2": 5.214494074135364, "train_loss": 10.407208256272758, "train_loss_scale": 8357.713280562884, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1339045976900488, "epoch": 79, "n_parameters": 106143056}
{"train_lr": 0.0006472360787527486, "train_min_lr": 0.0006472360787527486, "train_mlm_acc_1": 0.10031503329107581, "train_mlm_acc_2": 0.09904151104338199, "train_loss_1": 5.190614239626425, "train_loss_2": 5.212359111667623, "train_loss": 10.402973355383022, "train_loss_scale": 10439.936675461742, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 80, "n_parameters": 106143056}
{"train_lr": 0.000644448294509309, "train_min_lr": 0.000644448294509309, "train_mlm_acc_1": 0.1003229580385481, "train_mlm_acc_2": 0.09902279856782685, "train_loss_1": 5.189410227060108, "train_loss_2": 5.211304010690674, "train_loss": 10.400714235339336, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1480854832507479, "epoch": 81, "n_parameters": 106143056}
{"train_lr": 0.0006416294760860044, "train_min_lr": 0.0006416294760860044, "train_mlm_acc_1": 0.1005096243409376, "train_mlm_acc_2": 0.09920013154608671, "train_loss_1": 5.188025637425764, "train_loss_2": 5.209862756330713, "train_loss": 10.397888398736637, "train_loss_scale": 13790.22691292876, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 82, "n_parameters": 106143056}
{"train_lr": 0.0006387799542836763, "train_min_lr": 0.0006387799542836763, "train_mlm_acc_1": 0.10063303022816607, "train_mlm_acc_2": 0.09931595627752542, "train_loss_1": 5.185456163231071, "train_loss_2": 5.207342103949323, "train_loss": 10.392798266498898, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1701040047768867, "epoch": 83, "n_parameters": 106143056}
{"train_lr": 0.0006359000635063394, "train_min_lr": 0.0006359000635063394, "train_mlm_acc_1": 0.10078364592405951, "train_mlm_acc_2": 0.09948213510182519, "train_loss_1": 5.183443638297058, "train_loss_2": 5.205191263317957, "train_loss": 10.388634903974038, "train_loss_scale": 12486.135444151276, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.150556639977055, "epoch": 84, "n_parameters": 106143056}
{"train_lr": 0.0006329901417219492, "train_min_lr": 0.0006329901417219492, "train_mlm_acc_1": 0.1007436786769261, "train_mlm_acc_2": 0.0994636058666487, "train_loss_1": 5.182819862007151, "train_loss_2": 5.204592214567994, "train_loss": 10.387412079615665, "train_loss_scale": 8869.262972735269, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 85, "n_parameters": 106143056}
{"train_lr": 0.0006300505304227264, "train_min_lr": 0.0006300505304227264, "train_mlm_acc_1": 0.10088770948727217, "train_mlm_acc_2": 0.09959438684819923, "train_loss_1": 5.1805690204562485, "train_loss_2": 5.202421455972532, "train_loss": 10.382990477896618, "train_loss_scale": 9488.88654353562, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.176389099215874, "epoch": 86, "n_parameters": 106143056}
{"train_lr": 0.0006270815745850904, "train_min_lr": 0.0006270815745850904, "train_mlm_acc_1": 0.10102726257567539, "train_mlm_acc_2": 0.09967818050403655, "train_loss_1": 5.178807259759257, "train_loss_2": 5.200681395822171, "train_loss": 10.379488650706115, "train_loss_scale": 10641.674582233949, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 87, "n_parameters": 106143056}
{"train_lr": 0.0006240836226291734, "train_min_lr": 0.0006240836226291734, "train_mlm_acc_1": 0.10097693139728135, "train_mlm_acc_2": 0.09968376909968302, "train_loss_1": 5.178297326191539, "train_loss_2": 5.200120395490131, "train_loss": 10.378417717330583, "train_loss_scale": 4117.614775725594, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 88, "n_parameters": 106143056}
{"train_lr": 0.0006210570263779273, "train_min_lr": 0.0006210570263779273, "train_mlm_acc_1": 0.10127166946391553, "train_mlm_acc_2": 0.09995698897788922, "train_loss_1": 5.17511843277261, "train_loss_2": 5.197103988316988, "train_loss": 10.372222419988722, "train_loss_scale": 5061.45998240985, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.183622022155302, "epoch": 89, "n_parameters": 106143056}
{"train_lr": 0.0006180021410158472, "train_min_lr": 0.0006180021410158472, "train_mlm_acc_1": 0.10121331048478997, "train_mlm_acc_2": 0.09990749380853528, "train_loss_1": 5.175263437086171, "train_loss_2": 5.197230395824111, "train_loss": 10.372493830289145, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.215161226670157, "epoch": 90, "n_parameters": 106143056}
{"train_lr": 0.0006149193250472682, "train_min_lr": 0.0006149193250472682, "train_mlm_acc_1": 0.10138395556028384, "train_mlm_acc_2": 0.10006290779136967, "train_loss_1": 5.172947180197757, "train_loss_2": 5.194941993806062, "train_loss": 10.367889175838615, "train_loss_scale": 9632.985048372911, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 91, "n_parameters": 106143056}
{"train_lr": 0.0006118089402543174, "train_min_lr": 0.0006118089402543174, "train_mlm_acc_1": 0.10150115456507462, "train_mlm_acc_2": 0.10016701719416478, "train_loss_1": 5.170462544014712, "train_loss_2": 5.192360448386445, "train_loss": 10.362822996490129, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1849871429835062, "epoch": 92, "n_parameters": 106143056}
{"train_lr": 0.0006086713516544388, "train_min_lr": 0.0006086713516544388, "train_mlm_acc_1": 0.10148748094928611, "train_mlm_acc_2": 0.10014554486415868, "train_loss_1": 5.170972760298216, "train_loss_2": 5.192937366566117, "train_loss": 10.363910127336139, "train_loss_scale": 8292.868953386103, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 93, "n_parameters": 106143056}
{"train_lr": 0.000605506927457566, "train_min_lr": 0.000605506927457566, "train_mlm_acc_1": 0.10166547814074481, "train_mlm_acc_2": 0.10036078372785105, "train_loss_1": 5.167368794441643, "train_loss_2": 5.189415403857185, "train_loss": 10.356784195153464, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1865484297223121, "epoch": 94, "n_parameters": 106143056}
{"train_lr": 0.0006023160390229106, "train_min_lr": 0.0006023160390229106, "train_mlm_acc_1": 0.10170208986540609, "train_mlm_acc_2": 0.10037084992912744, "train_loss_1": 5.166842437776014, "train_loss_2": 5.188892510289567, "train_loss": 10.355734946021094, "train_loss_scale": 9618.575197889182, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 95, "n_parameters": 106143056}
{"train_lr": 0.0005990990608153761, "train_min_lr": 0.0005990990608153761, "train_mlm_acc_1": 0.10182921763709374, "train_mlm_acc_2": 0.10050095520707186, "train_loss_1": 5.165291925271352, "train_loss_2": 5.1872483794900965, "train_loss": 10.352540304289644, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2115142007301853, "epoch": 96, "n_parameters": 106143056}
{"train_lr": 0.000595856370361619, "train_min_lr": 0.000595856370361619, "train_mlm_acc_1": 0.10190192591185987, "train_mlm_acc_2": 0.10055338211436228, "train_loss_1": 5.164213969189553, "train_loss_2": 5.186355536353095, "train_loss": 10.350569502030325, "train_loss_scale": 8220.819700967459, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 97, "n_parameters": 106143056}
{"train_lr": 0.0005925883482057425, "train_min_lr": 0.0005925883482057425, "train_mlm_acc_1": 0.10200470691528778, "train_mlm_acc_2": 0.10063952347058917, "train_loss_1": 5.161736653421464, "train_loss_2": 5.183825531494439, "train_loss": 10.345562182923839, "train_loss_scale": 8804.418645558488, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.1889159887006855, "epoch": 98, "n_parameters": 106143056}
{"train_lr": 0.0005892953778646349, "train_min_lr": 0.0005892953778646349, "train_mlm_acc_1": 0.10208064462193399, "train_mlm_acc_2": 0.10074773261597152, "train_loss_1": 5.160645704470713, "train_loss_2": 5.182710601870387, "train_loss": 10.343356301203672, "train_loss_scale": 8883.672823218998, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 99, "n_parameters": 106143056}
{"train_lr": 0.0005859778457829658, "train_min_lr": 0.0005859778457829658, "train_mlm_acc_1": 0.10227145646881433, "train_mlm_acc_2": 0.1009097429976955, "train_loss_1": 5.158040814842167, "train_loss_2": 5.1800822274351495, "train_loss": 10.338123042749121, "train_loss_scale": 5439.71855760774, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 100, "n_parameters": 106143056}
{"train_lr": 0.0005826361412878357, "train_min_lr": 0.0005826361412878357, "train_mlm_acc_1": 0.10228115625240453, "train_mlm_acc_2": 0.10095350076292912, "train_loss_1": 5.156954347038856, "train_loss_2": 5.179021557014871, "train_loss": 10.335975902061664, "train_loss_scale": 3955.503957783641, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 101, "n_parameters": 106143056}
{"train_lr": 0.0005792706565430835, "train_min_lr": 0.0005792706565430835, "train_mlm_acc_1": 0.1023890906477981, "train_mlm_acc_2": 0.10100605361992551, "train_loss_1": 5.156431802239665, "train_loss_2": 5.178526313135052, "train_loss": 10.334958120302453, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2652213869120013, "epoch": 102, "n_parameters": 106143056}
{"train_lr": 0.0005758817865032646, "train_min_lr": 0.0005758817865032646, "train_mlm_acc_1": 0.10238272335753827, "train_mlm_acc_2": 0.10104789892203365, "train_loss_1": 5.155426696401578, "train_loss_2": 5.177365796127756, "train_loss": 10.332792497142533, "train_loss_scale": 2682.0334212840808, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.22531610743037, "epoch": 103, "n_parameters": 106143056}
{"train_lr": 0.0005724699288673034, "train_min_lr": 0.0005724699288673034, "train_mlm_acc_1": 0.10259222481956766, "train_mlm_acc_2": 0.10124371535322492, "train_loss_1": 5.152556255603948, "train_loss_2": 5.174658106205856, "train_loss": 10.32721435405124, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2270797037616987, "epoch": 104, "n_parameters": 106143056}
{"train_lr": 0.0005690354840318202, "train_min_lr": 0.0005690354840318202, "train_mlm_acc_1": 0.10269561272176768, "train_mlm_acc_2": 0.10132016834173034, "train_loss_1": 5.150890485487596, "train_loss_2": 5.1729332015193545, "train_loss": 10.323823690414429, "train_loss_scale": 5011.025505716799, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 105, "n_parameters": 106143056}
{"train_lr": 0.0005655788550441483, "train_min_lr": 0.0005655788550441483, "train_mlm_acc_1": 0.10273620975592887, "train_mlm_acc_2": 0.10139360952476922, "train_loss_1": 5.1492045338256585, "train_loss_2": 5.171300018787804, "train_loss": 10.32050455256104, "train_loss_scale": 3123.335092348285, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 106, "n_parameters": 106143056}
{"train_lr": 0.0005621004475550199, "train_min_lr": 0.0005621004475550199, "train_mlm_acc_1": 0.10282831760770465, "train_mlm_acc_2": 0.10147784982636741, "train_loss_1": 5.148594873037481, "train_loss_2": 5.17066764621852, "train_loss": 10.319262516844555, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2270979804749433, "epoch": 107, "n_parameters": 106143056}
{"train_lr": 0.0005586006697709787, "train_min_lr": 0.0005586006697709787, "train_mlm_acc_1": 0.10289252850758657, "train_mlm_acc_2": 0.10154302272349335, "train_loss_1": 5.146909903987207, "train_loss_2": 5.169135911693254, "train_loss": 10.316045819717012, "train_loss_scale": 3514.2022867194373, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2428066840587002, "epoch": 108, "n_parameters": 106143056}
{"train_lr": 0.0005550799324064666, "train_min_lr": 0.0005550799324064666, "train_mlm_acc_1": 0.10298030748930592, "train_mlm_acc_2": 0.1015984614862157, "train_loss_1": 5.146171569142723, "train_loss_2": 5.168401715728203, "train_loss": 10.314573282616749, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2498644717765044, "epoch": 109, "n_parameters": 106143056}
{"train_lr": 0.0005515386486356223, "train_min_lr": 0.0005515386486356223, "train_mlm_acc_1": 0.10318872101912922, "train_mlm_acc_2": 0.10182616000760776, "train_loss_1": 5.1434635983398325, "train_loss_2": 5.165713165817076, "train_loss": 10.30917676132608, "train_loss_scale": 7114.863676341249, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 110, "n_parameters": 106143056}
{"train_lr": 0.0005479772340437942, "train_min_lr": 0.0005479772340437942, "train_mlm_acc_1": 0.10321626281603292, "train_mlm_acc_2": 0.1018665624322106, "train_loss_1": 5.141008614497743, "train_loss_2": 5.163189064282121, "train_loss": 10.304197677836255, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2756093388182508, "epoch": 111, "n_parameters": 106143056}
{"train_lr": 0.0005443961065787804, "train_min_lr": 0.0005443961065787804, "train_mlm_acc_1": 0.10332815953847364, "train_mlm_acc_2": 0.10197637485554843, "train_loss_1": 5.140170569522609, "train_loss_2": 5.162336692908613, "train_loss": 10.30250726085854, "train_loss_scale": 5983.690413368514, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2715870400951321, "epoch": 112, "n_parameters": 106143056}
{"train_lr": 0.0005407956865017628, "train_min_lr": 0.0005407956865017628, "train_mlm_acc_1": 0.10341158677744389, "train_mlm_acc_2": 0.1020446970089025, "train_loss_1": 5.138095343018585, "train_loss_2": 5.160316685206448, "train_loss": 10.298412028487146, "train_loss_scale": 4420.221635883905, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 113, "n_parameters": 106143056}
{"train_lr": 0.0005371763963380031, "train_min_lr": 0.0005371763963380031, "train_mlm_acc_1": 0.10352248720015443, "train_mlm_acc_2": 0.10215669672480779, "train_loss_1": 5.136909825768299, "train_loss_2": 5.159084618196428, "train_loss": 10.295994441553281, "train_loss_scale": 4758.853122251539, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2700191806992, "epoch": 114, "n_parameters": 106143056}
{"train_lr": 0.0005335386608272497, "train_min_lr": 0.0005335386608272497, "train_mlm_acc_1": 0.10353128225751476, "train_mlm_acc_2": 0.10217994420806384, "train_loss_1": 5.135924845698012, "train_loss_2": 5.158157554496876, "train_loss": 10.294082401924838, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2929737016414484, "epoch": 115, "n_parameters": 106143056}
{"train_lr": 0.0005298829068738921, "train_min_lr": 0.0005298829068738921, "train_mlm_acc_1": 0.1036129802606325, "train_mlm_acc_2": 0.10225434731544637, "train_loss_1": 5.134278498046107, "train_loss_2": 5.156402233512965, "train_loss": 10.290680731296959, "train_loss_scale": 8422.557607739665, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 116, "n_parameters": 106143056}
{"train_lr": 0.0005262095634968652, "train_min_lr": 0.0005262095634968652, "train_mlm_acc_1": 0.10389190325439762, "train_mlm_acc_2": 0.10249102417061805, "train_loss_1": 5.132362332853604, "train_loss_2": 5.154602570972006, "train_loss": 10.286964898268801, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3036335472905436, "epoch": 117, "n_parameters": 106143056}
{"train_lr": 0.0005225190617793022, "train_min_lr": 0.0005225190617793022, "train_mlm_acc_1": 0.10403029971224442, "train_mlm_acc_2": 0.10267141483488215, "train_loss_1": 5.129676971607493, "train_loss_2": 5.1518497964008505, "train_loss": 10.281526773145771, "train_loss_scale": 9560.935795954265, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 118, "n_parameters": 106143056}
{"train_lr": 0.0005188118348179412, "train_min_lr": 0.0005188118348179412, "train_mlm_acc_1": 0.10402232918662258, "train_mlm_acc_2": 0.10267411741995718, "train_loss_1": 5.129155109142565, "train_loss_2": 5.151364389174637, "train_loss": 10.280519495119416, "train_loss_scale": 6156.608619173263, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 119, "n_parameters": 106143056}
{"train_lr": 0.0005150883176723058, "train_min_lr": 0.0005150883176723058, "train_mlm_acc_1": 0.10401980973626164, "train_mlm_acc_2": 0.1026529314376499, "train_loss_1": 5.12849549321407, "train_loss_2": 5.150728869983368, "train_loss": 10.279224359056041, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3353361551344343, "epoch": 120, "n_parameters": 106143056}
{"train_lr": 0.0005113489473136387, "train_min_lr": 0.0005113489473136387, "train_mlm_acc_1": 0.10416826099425999, "train_mlm_acc_2": 0.10279379004863211, "train_loss_1": 5.126326944813355, "train_loss_2": 5.148614597194742, "train_loss": 10.27494154127418, "train_loss_scale": 6488.035180299033, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 121, "n_parameters": 106143056}
{"train_lr": 0.0005075941625736347, "train_min_lr": 0.0005075941625736347, "train_mlm_acc_1": 0.10426161702797669, "train_mlm_acc_2": 0.10289588387852425, "train_loss_1": 5.1244451570846365, "train_loss_2": 5.146599203426794, "train_loss": 10.271044360406586, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3133111975648053, "epoch": 122, "n_parameters": 106143056}
{"train_lr": 0.0005038244040929274, "train_min_lr": 0.0005038244040929274, "train_mlm_acc_1": 0.1043369707134581, "train_mlm_acc_2": 0.10297521131593167, "train_loss_1": 5.123039073658912, "train_loss_2": 5.145293221677094, "train_loss": 10.268332297799875, "train_loss_scale": 5713.505716798592, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3296273833528987, "epoch": 123, "n_parameters": 106143056}
{"train_lr": 0.0005000401142693911, "train_min_lr": 0.0005000401142693911, "train_mlm_acc_1": 0.10447729112238033, "train_mlm_acc_2": 0.10305716129299991, "train_loss_1": 5.121923388203928, "train_loss_2": 5.144201069991633, "train_loss": 10.266124466163816, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.2995212005226886, "epoch": 124, "n_parameters": 106143056}
{"train_lr": 0.0004962417372062153, "train_min_lr": 0.0004962417372062153, "train_mlm_acc_1": 0.10456318047107341, "train_mlm_acc_2": 0.10316255335960613, "train_loss_1": 5.1205374622093345, "train_loss_2": 5.142819148779125, "train_loss": 10.263356610359386, "train_loss_scale": 8955.722075637643, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 125, "n_parameters": 106143056}
{"train_lr": 0.0004924297186597878, "train_min_lr": 0.0004924297186597878, "train_mlm_acc_1": 0.10478218700310826, "train_mlm_acc_2": 0.10337536435790537, "train_loss_1": 5.118189787854201, "train_loss_2": 5.140277369355778, "train_loss": 10.258467154326729, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3247383785751061, "epoch": 126, "n_parameters": 106143056}
{"train_lr": 0.0004886045059873886, "train_min_lr": 0.0004886045059873886, "train_mlm_acc_1": 0.10471372743912874, "train_mlm_acc_2": 0.10332656774846813, "train_loss_1": 5.117189771267229, "train_loss_2": 5.139365744045563, "train_loss": 10.256555516570938, "train_loss_scale": 9229.509234828496, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 127, "n_parameters": 106143056}
{"train_lr": 0.00048476654809468197, "train_min_lr": 0.00048476654809468197, "train_mlm_acc_1": 0.10485612060022831, "train_mlm_acc_2": 0.10348019525965736, "train_loss_1": 5.115463741484082, "train_loss_2": 5.13774390868587, "train_loss": 10.253207645923712, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3727471875116923, "epoch": 128, "n_parameters": 106143056}
{"train_lr": 0.0004809162953830467, "train_min_lr": 0.0004809162953830467, "train_mlm_acc_1": 0.10503733577083865, "train_mlm_acc_2": 0.1036503593860851, "train_loss_1": 5.112372802608141, "train_loss_2": 5.1347445806286895, "train_loss": 10.247117380877807, "train_loss_scale": 5479.345646437995, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3577061770459278, "epoch": 129, "n_parameters": 106143056}
{"train_lr": 0.0004770541996967091, "train_min_lr": 0.0004770541996967091, "train_mlm_acc_1": 0.1051260996413341, "train_mlm_acc_2": 0.10372654901180177, "train_loss_1": 5.111197641940104, "train_loss_2": 5.133473738516855, "train_loss": 10.244671375581646, "train_loss_scale": 4776.865435356201, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 130, "n_parameters": 106143056}
{"train_lr": 0.00047318071426971875, "train_min_lr": 0.00047318071426971875, "train_mlm_acc_1": 0.10512269842917576, "train_mlm_acc_2": 0.1037473227671473, "train_loss_1": 5.110366534536726, "train_loss_2": 5.132596936525749, "train_loss": 10.242963464929016, "train_loss_scale": 4402.209322779244, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3645589493195425, "epoch": 131, "n_parameters": 106143056}
{"train_lr": 0.00046929629367276803, "train_min_lr": 0.00046929629367276803, "train_mlm_acc_1": 0.10527223760381721, "train_mlm_acc_2": 0.10386872454484959, "train_loss_1": 5.10902366443171, "train_loss_2": 5.1313133328864735, "train_loss": 10.240337000149012, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3553517013657166, "epoch": 132, "n_parameters": 106143056}
{"train_lr": 0.00046540139375983523, "train_min_lr": 0.00046540139375983523, "train_mlm_acc_1": 0.10535453109229564, "train_mlm_acc_2": 0.10398611819851576, "train_loss_1": 5.107028663472953, "train_loss_2": 5.129338562069174, "train_loss": 10.236367227743882, "train_loss_scale": 8480.197009674583, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 133, "n_parameters": 106143056}
{"train_lr": 0.00046149647161469406, "train_min_lr": 0.00046149647161469406, "train_mlm_acc_1": 0.10543459149367498, "train_mlm_acc_2": 0.1040569140060609, "train_loss_1": 5.105271387488148, "train_loss_2": 5.1275379585401994, "train_loss": 10.232809346500153, "train_loss_scale": 5490.153034300792, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 134, "n_parameters": 106143056}
{"train_lr": 0.000457581985497272, "train_min_lr": 0.000457581985497272, "train_mlm_acc_1": 0.10557421325585536, "train_mlm_acc_2": 0.1042106216347456, "train_loss_1": 5.103386070084551, "train_loss_2": 5.125578331391646, "train_loss": 10.228964406875738, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3638587859291305, "epoch": 135, "n_parameters": 106143056}
{"train_lr": 0.00045365839478986964, "train_min_lr": 0.00045365839478986964, "train_mlm_acc_1": 0.10568668262700476, "train_mlm_acc_2": 0.10427839409727063, "train_loss_1": 5.102383615578489, "train_loss_2": 5.124714943957937, "train_loss": 10.227098559536426, "train_loss_scale": 7784.921723834653, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3544527952253766, "epoch": 136, "n_parameters": 106143056}
{"train_lr": 0.00044972615994325554, "train_min_lr": 0.00044972615994325554, "train_mlm_acc_1": 0.10575012620554855, "train_mlm_acc_2": 0.10433190895151101, "train_loss_1": 5.1007122086556, "train_loss_2": 5.122993056566545, "train_loss": 10.22370526207678, "train_loss_scale": 9351.992963940194, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.3778311711397733, "epoch": 137, "n_parameters": 106143056}
{"train_lr": 0.00044578574242262216, "train_min_lr": 0.00044578574242262216, "train_mlm_acc_1": 0.10593778884043244, "train_mlm_acc_2": 0.10453303905716699, "train_loss_1": 5.098482872324233, "train_loss_2": 5.120759295966401, "train_loss": 10.219242165774343, "train_loss_scale": 8372.123131046614, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 138, "n_parameters": 106143056}
{"train_lr": 0.0004418376046534354, "train_min_lr": 0.0004418376046534354, "train_mlm_acc_1": 0.10595434835211766, "train_mlm_acc_2": 0.10456671914955636, "train_loss_1": 5.096945537583495, "train_loss_2": 5.119347696516109, "train_loss": 10.216293233680222, "train_loss_scale": 5872.014072119613, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 139, "n_parameters": 106143056}
{"train_lr": 0.00043788220996717, "train_min_lr": 0.00043788220996717, "train_mlm_acc_1": 0.10612130586202063, "train_mlm_acc_2": 0.10468015038443561, "train_loss_1": 5.095254756529917, "train_loss_2": 5.117683274764813, "train_loss": 10.21293802668153, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.379033012985659, "epoch": 140, "n_parameters": 106143056}
{"train_lr": 0.0004339200225469267, "train_min_lr": 0.0004339200225469267, "train_mlm_acc_1": 0.10625879764524121, "train_mlm_acc_2": 0.10484635215760484, "train_loss_1": 5.093227808110632, "train_loss_2": 5.115451886555346, "train_loss": 10.208679696920155, "train_loss_scale": 7403.060686015831, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4165731419988548, "epoch": 141, "n_parameters": 106143056}
{"train_lr": 0.0004299515073729694, "train_min_lr": 0.0004299515073729694, "train_mlm_acc_1": 0.10633568581858799, "train_mlm_acc_2": 0.10494100223659893, "train_loss_1": 5.091422860047853, "train_loss_2": 5.113841783297932, "train_loss": 10.20526464843079, "train_loss_scale": 8350.50835532102, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 142, "n_parameters": 106143056}
{"train_lr": 0.0004259771301681481, "train_min_lr": 0.0004259771301681481, "train_mlm_acc_1": 0.10638244402010842, "train_mlm_acc_2": 0.10496249749417774, "train_loss_1": 5.091240915061092, "train_loss_2": 5.113720802329776, "train_loss": 10.204961717390868, "train_loss_scale": 5147.919085312225, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 143, "n_parameters": 106143056}
{"train_lr": 0.00042199735734324876, "train_min_lr": 0.00042199735734324876, "train_mlm_acc_1": 0.10656820564459528, "train_mlm_acc_2": 0.10516434902998577, "train_loss_1": 5.088891481451539, "train_loss_2": 5.111284158475166, "train_loss": 10.200175636676496, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4632711768045483, "epoch": 144, "n_parameters": 106143056}
{"train_lr": 0.0004180126559422584, "train_min_lr": 0.0004180126559422584, "train_mlm_acc_1": 0.10660528695405762, "train_mlm_acc_2": 0.10519254368483338, "train_loss_1": 5.08731860997075, "train_loss_2": 5.109716218348229, "train_loss": 10.19703482795202, "train_loss_scale": 4985.808267370273, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 145, "n_parameters": 106143056}
{"train_lr": 0.00041402349358755474, "train_min_lr": 0.00041402349358755474, "train_mlm_acc_1": 0.10677396227329602, "train_mlm_acc_2": 0.10535960429714192, "train_loss_1": 5.085602151162811, "train_loss_2": 5.107968858856848, "train_loss": 10.193571002418365, "train_loss_scale": 4128.4221635883905, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4578387987330594, "epoch": 146, "n_parameters": 106143056}
{"train_lr": 0.00041003033842502425, "train_min_lr": 0.00041003033842502425, "train_mlm_acc_1": 0.10695400934669672, "train_mlm_acc_2": 0.10551964486363485, "train_loss_1": 5.083133006840289, "train_loss_2": 5.1054919585389005, "train_loss": 10.1886249686294, "train_loss_scale": 4333.76253298153, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 147, "n_parameters": 106143056}
{"train_lr": 0.00040603365906913383, "train_min_lr": 0.00040603365906913383, "train_mlm_acc_1": 0.10698884610486403, "train_mlm_acc_2": 0.10557523252575174, "train_loss_1": 5.081331875204725, "train_loss_2": 5.103758698979699, "train_loss": 10.185090575285301, "train_loss_scale": 4312.147757255937, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 148, "n_parameters": 106143056}
{"train_lr": 0.000402033924547923, "train_min_lr": 0.000402033924547923, "train_mlm_acc_1": 0.10714901266611372, "train_mlm_acc_2": 0.10572940969746314, "train_loss_1": 5.0795424056870955, "train_loss_2": 5.101940106381003, "train_loss": 10.181482510495416, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.4568395808063899, "epoch": 149, "n_parameters": 106143056}
{"train_lr": 0.0003980316042479732, "train_min_lr": 0.0003980316042479732, "train_mlm_acc_1": 0.1072152047520446, "train_mlm_acc_2": 0.10578449344853874, "train_loss_1": 5.078676425058169, "train_loss_2": 5.101053789507011, "train_loss": 10.179730215403943, "train_loss_scale": 4441.836411609499, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 150, "n_parameters": 106143056}
{"train_lr": 0.000394027167859318, "train_min_lr": 0.000394027167859318, "train_mlm_acc_1": 0.10740592504835957, "train_mlm_acc_2": 0.10599494542887233, "train_loss_1": 5.076409983131691, "train_loss_2": 5.098867135133886, "train_loss": 10.175277122302127, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5257240546410191, "epoch": 151, "n_parameters": 106143056}
{"train_lr": 0.00039002108532032085, "train_min_lr": 0.00039002108532032085, "train_mlm_acc_1": 0.107391839172026, "train_mlm_acc_2": 0.10595195487030211, "train_loss_1": 5.076014955733676, "train_loss_2": 5.098331952787012, "train_loss": 10.17434690914976, "train_loss_scale": 4600.344766930519, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 152, "n_parameters": 106143056}
{"train_lr": 0.00038601382676252893, "train_min_lr": 0.00038601382676252893, "train_mlm_acc_1": 0.10754135550510076, "train_mlm_acc_2": 0.1060922523639382, "train_loss_1": 5.073445709892397, "train_loss_2": 5.0957904067496615, "train_loss": 10.169236112920045, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.457699169164807, "epoch": 153, "n_parameters": 106143056}
{"train_lr": 0.0003820058624555032, "train_min_lr": 0.0003820058624555032, "train_mlm_acc_1": 0.10765038918713624, "train_mlm_acc_2": 0.10621810898679516, "train_loss_1": 5.071505149939444, "train_loss_2": 5.0940544394515745, "train_loss": 10.165559595262366, "train_loss_scale": 6740.207563764292, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5154751714846495, "epoch": 154, "n_parameters": 106143056}
{"train_lr": 0.000377997662751625, "train_min_lr": 0.000377997662751625, "train_mlm_acc_1": 0.10777205443656827, "train_mlm_acc_2": 0.1063238445820128, "train_loss_1": 5.069577595122362, "train_loss_2": 5.0919674624448925, "train_loss": 10.161545054264622, "train_loss_scale": 4114.012313104661, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 155, "n_parameters": 106143056}
{"train_lr": 0.0003739896980309009, "train_min_lr": 0.0003739896980309009, "train_mlm_acc_1": 0.107817667438964, "train_mlm_acc_2": 0.10634956555645798, "train_loss_1": 5.068797552438818, "train_loss_2": 5.0912639337772845, "train_loss": 10.16006148710729, "train_loss_scale": 5065.062445030782, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5239100111296224, "epoch": 156, "n_parameters": 106143056}
{"train_lr": 0.0003699824386457607, "train_min_lr": 0.0003699824386457607, "train_mlm_acc_1": 0.10807826732454875, "train_mlm_acc_2": 0.1066194186314757, "train_loss_1": 5.065392586308398, "train_loss_2": 5.08768860803116, "train_loss": 10.153081189883626, "train_loss_scale": 5591.021987686895, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 157, "n_parameters": 106143056}
{"train_lr": 0.00036597635486586153, "train_min_lr": 0.00036597635486586153, "train_mlm_acc_1": 0.10812628525575474, "train_mlm_acc_2": 0.10672454729433792, "train_loss_1": 5.064330653706033, "train_loss_2": 5.086628933328227, "train_loss": 10.150959586405188, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.498032271075689, "epoch": 158, "n_parameters": 106143056}
{"train_lr": 0.0003619719168228958, "train_min_lr": 0.0003619719168228958, "train_mlm_acc_1": 0.10825342447116067, "train_mlm_acc_2": 0.10685598096755401, "train_loss_1": 5.062376588084977, "train_loss_2": 5.0847484412272985, "train_loss": 10.147125027005675, "train_loss_scale": 5147.919085312225, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 159, "n_parameters": 106143056}
{"train_lr": 0.00035796959445542426, "train_min_lr": 0.00035796959445542426, "train_mlm_acc_1": 0.10840823150689574, "train_mlm_acc_2": 0.10695994145539159, "train_loss_1": 5.060492702922804, "train_loss_2": 5.083052882837851, "train_loss": 10.143545578106936, "train_loss_scale": 2618.990325417766, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 160, "n_parameters": 106143056}
{"train_lr": 0.0003539698574537211, "train_min_lr": 0.0003539698574537211, "train_mlm_acc_1": 0.10842573005384983, "train_mlm_acc_2": 0.10701746448363351, "train_loss_1": 5.060030335801258, "train_loss_2": 5.082500914313234, "train_loss": 10.142531248384541, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5591324122201589, "epoch": 161, "n_parameters": 106143056}
{"train_lr": 0.0003499731752046559, "train_min_lr": 0.0003499731752046559, "train_mlm_acc_1": 0.10859808142124139, "train_mlm_acc_2": 0.1072146436207737, "train_loss_1": 5.056619280560979, "train_loss_2": 5.079093234310469, "train_loss": 10.135712513089075, "train_loss_scale": 4018.547053649956, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5327661947503672, "epoch": 162, "n_parameters": 106143056}
{"train_lr": 0.0003459800167366142, "train_min_lr": 0.0003459800167366142, "train_mlm_acc_1": 0.10867822201465475, "train_mlm_acc_2": 0.10724129224328771, "train_loss_1": 5.055424097555189, "train_loss_2": 5.077906049545543, "train_loss": 10.133330154859296, "train_loss_scale": 4928.168865435357, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6382075091570012, "epoch": 163, "n_parameters": 106143056}
{"train_lr": 0.0003419908506644451, "train_min_lr": 0.0003419908506644451, "train_mlm_acc_1": 0.10884103397105672, "train_mlm_acc_2": 0.10739964942088254, "train_loss_1": 5.0536667083372855, "train_loss_2": 5.0760980365878146, "train_loss": 10.129764739211023, "train_loss_scale": 4938.976253298153, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 164, "n_parameters": 106143056}
{"train_lr": 0.00033800614513447493, "train_min_lr": 0.00033800614513447493, "train_mlm_acc_1": 0.10894326523696658, "train_mlm_acc_2": 0.107476709424473, "train_loss_1": 5.051579589055312, "train_loss_2": 5.074092555171896, "train_loss": 10.12567214349329, "train_loss_scale": 4240.098504837291, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5543079913029465, "epoch": 165, "n_parameters": 106143056}
{"train_lr": 0.00033402636776956357, "train_min_lr": 0.00033402636776956357, "train_mlm_acc_1": 0.10910477170273465, "train_mlm_acc_2": 0.10764343789373193, "train_loss_1": 5.05020936225314, "train_loss_2": 5.072729806314987, "train_loss": 10.12293917113684, "train_loss_scale": 8192.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6123173201199468, "epoch": 166, "n_parameters": 106143056}
{"train_lr": 0.000330051985614231, "train_min_lr": 0.000330051985614231, "train_mlm_acc_1": 0.10925460860572211, "train_mlm_acc_2": 0.10779862285967631, "train_loss_1": 5.047550875048104, "train_loss_2": 5.070070250787123, "train_loss": 10.117621134956783, "train_loss_scale": 7024.802110817942, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 167, "n_parameters": 106143056}
{"train_lr": 0.0003260834650798454, "train_min_lr": 0.0003260834650798454, "train_mlm_acc_1": 0.10935683991340633, "train_mlm_acc_2": 0.10787139986146146, "train_loss_1": 5.04630116039761, "train_loss_2": 5.06885562214604, "train_loss": 10.115156782333958, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.5722615426322715, "epoch": 168, "n_parameters": 106143056}
{"train_lr": 0.00032212127188988656, "train_min_lr": 0.00032212127188988656, "train_mlm_acc_1": 0.10942482995156039, "train_mlm_acc_2": 0.10798977836049117, "train_loss_1": 5.0446302185691865, "train_loss_2": 5.067207020526406, "train_loss": 10.111837238518943, "train_loss_scale": 4993.013192612138, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 169, "n_parameters": 106143056}
{"train_lr": 0.0003181658710252925, "train_min_lr": 0.0003181658710252925, "train_mlm_acc_1": 0.10951102854685633, "train_mlm_acc_2": 0.10802707721691385, "train_loss_1": 5.043315186978645, "train_loss_2": 5.065863414825634, "train_loss": 10.109178599497678, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6039641608558628, "epoch": 170, "n_parameters": 106143056}
{"train_lr": 0.0003142177266698921, "train_min_lr": 0.0003142177266698921, "train_mlm_acc_1": 0.10968536113469927, "train_mlm_acc_2": 0.10826015819385058, "train_loss_1": 5.040993469633758, "train_loss_2": 5.063516752858275, "train_loss": 10.10451021819337, "train_loss_scale": 4510.283201407212, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 171, "n_parameters": 106143056}
{"train_lr": 0.00031027730215593045, "train_min_lr": 0.00031027730215593045, "train_mlm_acc_1": 0.10979610119300028, "train_mlm_acc_2": 0.10830769508834617, "train_loss_1": 5.039183408205407, "train_loss_2": 5.061858103950504, "train_loss": 10.101041511893797, "train_loss_scale": 3694.325417766051, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 172, "n_parameters": 106143056}
{"train_lr": 0.0003063450599096958, "train_min_lr": 0.0003063450599096958, "train_mlm_acc_1": 0.10993044369460044, "train_mlm_acc_2": 0.10845477213770177, "train_loss_1": 5.037544657812899, "train_loss_2": 5.060098370388085, "train_loss": 10.097643028672788, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6123316631887499, "epoch": 173, "n_parameters": 106143056}
{"train_lr": 0.0003024214613972495, "train_min_lr": 0.0003024214613972495, "train_mlm_acc_1": 0.11005655222260308, "train_mlm_acc_2": 0.1086107472886668, "train_loss_1": 5.034570455970529, "train_loss_2": 5.0571945749465685, "train_loss": 10.091765032804316, "train_loss_scale": 2943.211961301671, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.646197164803088, "epoch": 174, "n_parameters": 106143056}
{"train_lr": 0.0002985069670702745, "train_min_lr": 0.0002985069670702745, "train_mlm_acc_1": 0.1102000676642648, "train_mlm_acc_2": 0.10872031926777846, "train_loss_1": 5.032978838593056, "train_loss_2": 5.055568286538019, "train_loss": 10.088547125235921, "train_loss_scale": 2757.6851363236588, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 175, "n_parameters": 106143056}
{"train_lr": 0.0002946020363120353, "train_min_lr": 0.0002946020363120353, "train_mlm_acc_1": 0.1103079104320971, "train_mlm_acc_2": 0.1088293758503562, "train_loss_1": 5.031523334686444, "train_loss_2": 5.053978082477365, "train_loss": 10.085501419208295, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6400411650603972, "epoch": 176, "n_parameters": 106143056}
{"train_lr": 0.0002907071273834704, "train_min_lr": 0.0002907071273834704, "train_mlm_acc_1": 0.11033136400794684, "train_mlm_acc_2": 0.10889197211375128, "train_loss_1": 5.030377395968744, "train_loss_2": 5.052869595187531, "train_loss": 10.083246986385806, "train_loss_scale": 3879.8522427440635, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6354883649732948, "epoch": 177, "n_parameters": 106143056}
{"train_lr": 0.0002868226973694113, "train_min_lr": 0.0002868226973694113, "train_mlm_acc_1": 0.11056336846281246, "train_mlm_acc_2": 0.10913697445868345, "train_loss_1": 5.0273984279565465, "train_loss_2": 5.050013666207474, "train_loss": 10.07741209647062, "train_loss_scale": 4650.77924362357, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.706288829485156, "epoch": 178, "n_parameters": 106143056}
{"train_lr": 0.00028294920212494217, "train_min_lr": 0.00028294920212494217, "train_mlm_acc_1": 0.11071003316479786, "train_mlm_acc_2": 0.10920661359635511, "train_loss_1": 5.02552465319948, "train_loss_2": 5.0482033394152594, "train_loss": 10.073727991566285, "train_loss_scale": 4135.627088830255, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 179, "n_parameters": 106143056}
{"train_lr": 0.00027908709622190573, "train_min_lr": 0.00027908709622190573, "train_mlm_acc_1": 0.1108417073575978, "train_mlm_acc_2": 0.10932963015552587, "train_loss_1": 5.023680219339926, "train_loss_2": 5.046285761430165, "train_loss": 10.069965979459523, "train_loss_scale": 5043.447669305189, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.788654431189585, "epoch": 180, "n_parameters": 106143056}
{"train_lr": 0.00027523683289555303, "train_min_lr": 0.00027523683289555303, "train_mlm_acc_1": 0.11089683693351196, "train_mlm_acc_2": 0.10944648554406097, "train_loss_1": 5.022870117148078, "train_loss_2": 5.045442616562101, "train_loss": 10.068312734391675, "train_loss_scale": 2705.4494283201407, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 181, "n_parameters": 106143056}
{"train_lr": 0.0002713988639913556, "train_min_lr": 0.0002713988639913556, "train_mlm_acc_1": 0.1110605535874751, "train_mlm_acc_2": 0.10957234213743015, "train_loss_1": 5.020281434216411, "train_loss_2": 5.042962324231365, "train_loss": 10.063243754830609, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7054577351350373, "epoch": 182, "n_parameters": 106143056}
{"train_lr": 0.00026757363991198143, "train_min_lr": 0.00026757363991198143, "train_mlm_acc_1": 0.11123670701170135, "train_mlm_acc_2": 0.10972252259114487, "train_loss_1": 5.018343742206207, "train_loss_2": 5.040929310030338, "train_loss": 10.059273051922009, "train_loss_scale": 3960.9076517150397, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.6640882932940595, "epoch": 183, "n_parameters": 106143056}
{"train_lr": 0.00026376160956443706, "train_min_lr": 0.00026376160956443706, "train_mlm_acc_1": 0.1113741987302126, "train_mlm_acc_2": 0.10990892555204236, "train_loss_1": 5.0154568774719035, "train_loss_2": 5.038141576522468, "train_loss": 10.05359845530494, "train_loss_scale": 4376.992084432718, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 184, "n_parameters": 106143056}
{"train_lr": 0.00025996322030738496, "train_min_lr": 0.00025996322030738496, "train_mlm_acc_1": 0.11144226893992307, "train_mlm_acc_2": 0.10995701217750316, "train_loss_1": 5.014727374180011, "train_loss_2": 5.037409546297689, "train_loss": 10.052136919848627, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7400228978251824, "epoch": 185, "n_parameters": 106143056}
{"train_lr": 0.00025617891789864574, "train_min_lr": 0.00025617891789864574, "train_mlm_acc_1": 0.11161910949591072, "train_mlm_acc_2": 0.1100946069247005, "train_loss_1": 5.0127306649741525, "train_loss_2": 5.035267466133692, "train_loss": 10.047998126389798, "train_loss_scale": 4297.737906772208, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 186, "n_parameters": 106143056}
{"train_lr": 0.0002524091464428861, "train_min_lr": 0.0002524091464428861, "train_mlm_acc_1": 0.11172155842918939, "train_mlm_acc_2": 0.11024574939449865, "train_loss_1": 5.010755788367782, "train_loss_2": 5.033376316334348, "train_loss": 10.044132098463825, "train_loss_scale": 3672.7106420404575, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 187, "n_parameters": 106143056}
{"train_lr": 0.00024865434833949967, "train_min_lr": 0.00024865434833949967, "train_mlm_acc_1": 0.11197363806965457, "train_mlm_acc_2": 0.11044799031815905, "train_loss_1": 5.007615441749676, "train_loss_2": 5.030224314203573, "train_loss": 10.037839759937377, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.853791748103911, "epoch": 188, "n_parameters": 106143056}
{"train_lr": 0.0002449149642306928, "train_min_lr": 0.0002449149642306928, "train_mlm_acc_1": 0.11197606592521844, "train_mlm_acc_2": 0.11051958772495533, "train_loss_1": 5.00673255887908, "train_loss_2": 5.029332716473384, "train_loss": 10.036065274933083, "train_loss_scale": 1219.433597185576, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 189, "n_parameters": 106143056}
{"train_lr": 0.0002411914329497703, "train_min_lr": 0.0002411914329497703, "train_mlm_acc_1": 0.11214802795308482, "train_mlm_acc_2": 0.11065388442383278, "train_loss_1": 5.00449735544812, "train_loss_2": 5.027119323100138, "train_loss": 10.031616681693622, "train_loss_scale": 1075.335092348285, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7556296140872918, "epoch": 190, "n_parameters": 106143056}
{"train_lr": 0.000237484191469636, "train_min_lr": 0.000237484191469636, "train_mlm_acc_1": 0.11230093398251839, "train_mlm_acc_2": 0.11081596344984616, "train_loss_1": 5.002053593006067, "train_loss_2": 5.024650673071544, "train_loss": 10.026704264190393, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7837407317933223, "epoch": 191, "n_parameters": 106143056}
{"train_lr": 0.00023379367485151643, "train_min_lr": 0.00023379367485151643, "train_mlm_acc_1": 0.11242814187989254, "train_mlm_acc_2": 0.1109403312835341, "train_loss_1": 4.999904604784312, "train_loss_2": 5.022582015817168, "train_loss": 10.022486614048638, "train_loss_scale": 2644.207563764292, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.7969098446551601, "epoch": 192, "n_parameters": 106143056}
{"train_lr": 0.00023012031619389827, "train_min_lr": 0.00023012031619389827, "train_mlm_acc_1": 0.11257131380277212, "train_mlm_acc_2": 0.11110380744412476, "train_loss_1": 4.998567956628355, "train_loss_2": 5.021159534194329, "train_loss": 10.01972749669403, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.715275636029642, "epoch": 193, "n_parameters": 106143056}
{"train_lr": 0.00022646454658170753, "train_min_lr": 0.00022646454658170753, "train_mlm_acc_1": 0.11269209726255718, "train_mlm_acc_2": 0.11118047811064735, "train_loss_1": 4.9962682375912095, "train_loss_2": 5.018933891673411, "train_loss": 10.015202128478279, "train_loss_scale": 3114.3289357959543, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 194, "n_parameters": 106143056}
{"train_lr": 0.00022282679503571708, "train_min_lr": 0.00022282679503571708, "train_mlm_acc_1": 0.11283223433936099, "train_mlm_acc_2": 0.11131799270922323, "train_loss_1": 4.994691599694489, "train_loss_2": 5.017314241922206, "train_loss": 10.012005840987623, "train_loss_scale": 1868.7774846086193, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 195, "n_parameters": 106143056}
{"train_lr": 0.00021920748846219963, "train_min_lr": 0.00021920748846219963, "train_mlm_acc_1": 0.11298668643061592, "train_mlm_acc_2": 0.11146640957872937, "train_loss_1": 4.992300516015726, "train_loss_2": 5.015028070753462, "train_loss": 10.007328585039238, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.883127193285272, "epoch": 196, "n_parameters": 106143056}
{"train_lr": 0.00021560705160282874, "train_min_lr": 0.00021560705160282874, "train_mlm_acc_1": 0.11304603025674322, "train_mlm_acc_2": 0.11154555385193493, "train_loss_1": 4.990767807947929, "train_loss_2": 5.013445234026108, "train_loss": 10.004213045748473, "train_loss_scale": 1449.9912049252418, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8645988022327005, "epoch": 197, "n_parameters": 106143056}
{"train_lr": 0.0002120259069848334, "train_min_lr": 0.0002120259069848334, "train_mlm_acc_1": 0.11325582948971209, "train_mlm_acc_2": 0.11173641156215178, "train_loss_1": 4.987934527632009, "train_loss_2": 5.010603013380432, "train_loss": 9.998537531943308, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8626040415273177, "epoch": 198, "n_parameters": 106143056}
{"train_lr": 0.00020846447487141197, "train_min_lr": 0.00020846447487141197, "train_mlm_acc_1": 0.11345965075064958, "train_mlm_acc_2": 0.1118953985931219, "train_loss_1": 4.986286704856886, "train_loss_2": 5.008956457295749, "train_loss": 9.99524316341078, "train_loss_scale": 3393.519788918206, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8704411015242155, "epoch": 199, "n_parameters": 106143056}
{"train_lr": 0.0002049231732124145, "train_min_lr": 0.0002049231732124145, "train_mlm_acc_1": 0.11358406442637729, "train_mlm_acc_2": 0.11203836432593427, "train_loss_1": 4.983885645971239, "train_loss_2": 5.006625269679721, "train_loss": 9.99051091119503, "train_loss_scale": 2218.21635883905, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 200, "n_parameters": 106143056}
{"train_lr": 0.00020140241759529154, "train_min_lr": 0.00020140241759529154, "train_mlm_acc_1": 0.1136985950502866, "train_mlm_acc_2": 0.11214708886948875, "train_loss_1": 4.982684658406173, "train_loss_2": 5.005367284661967, "train_loss": 9.988051942281798, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.8648473981607347, "epoch": 201, "n_parameters": 106143056}
{"train_lr": 0.00019790262119632546, "train_min_lr": 0.00019790262119632546, "train_mlm_acc_1": 0.11382384470556663, "train_mlm_acc_2": 0.11232285290586262, "train_loss_1": 4.979874415416516, "train_loss_2": 5.00252835123604, "train_loss": 9.982402767438897, "train_loss_scale": 1725.5795954265611, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9329836936823193, "epoch": 202, "n_parameters": 106143056}
{"train_lr": 0.0001944241947321401, "train_min_lr": 0.0001944241947321401, "train_mlm_acc_1": 0.11395033117606515, "train_mlm_acc_2": 0.11242989405478525, "train_loss_1": 4.978077055491579, "train_loss_2": 5.0008007070949025, "train_loss": 9.97887775776359, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9134013502872504, "epoch": 203, "n_parameters": 106143056}
{"train_lr": 0.00019096754641150413, "train_min_lr": 0.00019096754641150413, "train_mlm_acc_1": 0.11409599959552157, "train_mlm_acc_2": 0.11256030853837729, "train_loss_1": 4.976356506452501, "train_loss_2": 4.999083625819459, "train_loss": 9.975440126190923, "train_loss_scale": 3944.6965699208445, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9845760392849132, "epoch": 204, "n_parameters": 106143056}
{"train_lr": 0.00018753308188742345, "train_min_lr": 0.00018753308188742345, "train_mlm_acc_1": 0.11423823246347374, "train_mlm_acc_2": 0.11269889965574785, "train_loss_1": 4.97460847731316, "train_loss_2": 4.997262945380668, "train_loss": 9.971871422588983, "train_loss_scale": 4391.401934916446, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 205, "n_parameters": 106143056}
{"train_lr": 0.00018412120420953888, "train_min_lr": 0.00018412120420953888, "train_mlm_acc_1": 0.11446823281208962, "train_mlm_acc_2": 0.11293715685229215, "train_loss_1": 4.9712394767407275, "train_loss_2": 4.994096431484742, "train_loss": 9.965335909483615, "train_loss_scale": 2402.842568161829, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 206, "n_parameters": 106143056}
{"train_lr": 0.00018073231377682198, "train_min_lr": 0.00018073231377682198, "train_mlm_acc_1": 0.11451086830003752, "train_mlm_acc_2": 0.11299455388577732, "train_loss_1": 4.970459593894089, "train_loss_2": 4.993266286038471, "train_loss": 9.963725875738742, "train_loss_scale": 2186.6948109058926, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9360321601860966, "epoch": 207, "n_parameters": 106143056}
{"train_lr": 0.0001773668082905917, "train_min_lr": 0.0001773668082905917, "train_mlm_acc_1": 0.1147405480295944, "train_mlm_acc_2": 0.11315839656152768, "train_loss_1": 4.967334775203346, "train_loss_2": 4.990175013963654, "train_loss": 9.957509785444985, "train_loss_scale": 4096.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 1.9314172537890881, "epoch": 208, "n_parameters": 106143056}
{"train_lr": 0.00017402508270783777, "train_min_lr": 0.00017402508270783777, "train_mlm_acc_1": 0.11492375584553498, "train_mlm_acc_2": 0.11334453601956944, "train_loss_1": 4.9650184174011756, "train_loss_2": 4.987750756237312, "train_loss": 9.952769174319982, "train_loss_scale": 4362.582233948989, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 209, "n_parameters": 106143056}
{"train_lr": 0.0001707075291948745, "train_min_lr": 0.0001707075291948745, "train_mlm_acc_1": 0.1150385956775492, "train_mlm_acc_2": 0.11348424946746757, "train_loss_1": 4.962594849243432, "train_loss_2": 4.985367793940408, "train_loss": 9.94796264433714, "train_loss_scale": 2032.6895338610377, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 210, "n_parameters": 106143056}
{"train_lr": 0.0001674145370813154, "train_min_lr": 0.0001674145370813154, "train_mlm_acc_1": 0.11517265186175743, "train_mlm_acc_2": 0.1136190500298782, "train_loss_1": 4.961315584423883, "train_loss_2": 4.984039281058332, "train_loss": 9.945354869099384, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.18951753665191, "epoch": 211, "n_parameters": 106143056}
{"train_lr": 0.0001641464928143861, "train_min_lr": 0.0001641464928143861, "train_mlm_acc_1": 0.11532318737790342, "train_mlm_acc_2": 0.11380389546148197, "train_loss_1": 4.958593070192514, "train_loss_2": 4.981395999642978, "train_loss": 9.939989075182611, "train_loss_scale": 1565.2700087950748, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1185511756907878, "epoch": 212, "n_parameters": 106143056}
{"train_lr": 0.0001609037799135703, "train_min_lr": 0.0001609037799135703, "train_mlm_acc_1": 0.11549593963502212, "train_mlm_acc_2": 0.11395570212400133, "train_loss_1": 4.956937247236884, "train_loss_2": 4.979706015624598, "train_loss": 9.936643262966328, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.060726753063336, "epoch": 213, "n_parameters": 106143056}
{"train_lr": 0.00015768677892560474, "train_min_lr": 0.00015768677892560474, "train_mlm_acc_1": 0.1156033357308822, "train_mlm_acc_2": 0.1140494016969778, "train_loss_1": 4.95496482632091, "train_loss_2": 4.9777520271698, "train_loss": 9.932716850135655, "train_loss_scale": 2620.791556728232, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 214, "n_parameters": 106143056}
{"train_lr": 0.0001544958673798188, "train_min_lr": 0.0001544958673798188, "train_mlm_acc_1": 0.1157263293567465, "train_mlm_acc_2": 0.11418412210011859, "train_loss_1": 4.953677978867906, "train_loss_2": 4.976495111261215, "train_loss": 9.930173086407107, "train_loss_scale": 1957.03781882146, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 215, "n_parameters": 106143056}
{"train_lr": 0.00015133141974383045, "train_min_lr": 0.00015133141974383045, "train_mlm_acc_1": 0.11598082535827275, "train_mlm_acc_2": 0.11441077851823866, "train_loss_1": 4.950086526317143, "train_loss_2": 4.972753177532105, "train_loss": 9.922839705317086, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1961048825225395, "epoch": 216, "n_parameters": 106143056}
{"train_lr": 0.00014819380737959978, "train_min_lr": 0.00014819380737959978, "train_mlm_acc_1": 0.11603769561949144, "train_mlm_acc_2": 0.11449779024169097, "train_loss_1": 4.94861495253698, "train_loss_2": 4.971266820174932, "train_loss": 9.919881773498254, "train_loss_scale": 1361.7308707124012, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.089949137250268, "epoch": 217, "n_parameters": 106143056}
{"train_lr": 0.0001450833984998489, "train_min_lr": 0.0001450833984998489, "train_mlm_acc_1": 0.11614281279358458, "train_mlm_acc_2": 0.11460455648417575, "train_loss_1": 4.94723614360957, "train_loss_2": 4.969959001585173, "train_loss": 9.917195149965211, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1357494131346595, "epoch": 218, "n_parameters": 106143056}
{"train_lr": 0.0001420005581248513, "train_min_lr": 0.0001420005581248513, "train_mlm_acc_1": 0.11638435666926907, "train_mlm_acc_2": 0.11480284647781831, "train_loss_1": 4.943728477994706, "train_loss_2": 4.966573139084151, "train_loss": 9.910301620538757, "train_loss_scale": 2532.531222515391, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 219, "n_parameters": 106143056}
{"train_lr": 0.00013894564803959363, "train_min_lr": 0.00013894564803959363, "train_mlm_acc_1": 0.11659406422634945, "train_mlm_acc_2": 0.11502254010885037, "train_loss_1": 4.941695247497491, "train_loss_2": 4.964458066534346, "train_loss": 9.906153313193073, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.172187353501534, "epoch": 220, "n_parameters": 106143056}
{"train_lr": 0.00013591902675131893, "train_min_lr": 0.00013591902675131893, "train_mlm_acc_1": 0.11669619248732728, "train_mlm_acc_2": 0.11512395837356516, "train_loss_1": 4.9399051512661165, "train_loss_2": 4.962738148822214, "train_loss": 9.902643298725339, "train_loss_scale": 3226.0052770448547, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.1507358402669063, "epoch": 221, "n_parameters": 106143056}
{"train_lr": 0.00013292104944745455, "train_min_lr": 0.00013292104944745455, "train_mlm_acc_1": 0.11686013815654221, "train_mlm_acc_2": 0.11530334122229954, "train_loss_1": 4.937794653018945, "train_loss_2": 4.960508000253058, "train_loss": 9.898302650283908, "train_loss_scale": 1250.0545294635003, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 222, "n_parameters": 106143056}
{"train_lr": 0.00012995206795392967, "train_min_lr": 0.00012995206795392967, "train_mlm_acc_1": 0.11704133041514282, "train_mlm_acc_2": 0.11551638128663509, "train_loss_1": 4.934879823431386, "train_loss_2": 4.9576341959081835, "train_loss": 9.89251402185586, "train_loss_scale": 1127.570800351803, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.262398905259219, "epoch": 223, "n_parameters": 106143056}
{"train_lr": 0.00012701243069388645, "train_min_lr": 0.00012701243069388645, "train_mlm_acc_1": 0.11702668345095091, "train_mlm_acc_2": 0.11550633791218148, "train_loss_1": 4.934808307031633, "train_loss_2": 4.957517312248234, "train_loss": 9.892325617078113, "train_loss_scale": 2048.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.3401250519978967, "epoch": 224, "n_parameters": 106143056}
{"train_lr": 0.0001241024826467912, "train_min_lr": 0.0001241024826467912, "train_mlm_acc_1": 0.1172080933097537, "train_mlm_acc_2": 0.11567755556921741, "train_loss_1": 4.93163826503351, "train_loss_2": 4.95447125168568, "train_loss": 9.886109514831972, "train_loss_scale": 1337.4142480211083, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 225, "n_parameters": 106143056}
{"train_lr": 0.00012122256530794866, "train_min_lr": 0.00012122256530794866, "train_mlm_acc_1": 0.11739146148109368, "train_mlm_acc_2": 0.11580322900002293, "train_loss_1": 4.930149287640681, "train_loss_2": 4.952954287789009, "train_loss": 9.883103578155671, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.379364745178659, "epoch": 226, "n_parameters": 106143056}
{"train_lr": 0.00011837301664842798, "train_min_lr": 0.00011837301664842798, "train_mlm_acc_1": 0.11753131230931038, "train_mlm_acc_2": 0.11597870678289506, "train_loss_1": 4.928402713441807, "train_loss_2": 4.951054008256582, "train_loss": 9.87945672348076, "train_loss_scale": 1981.3544415127528, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.312444888245357, "epoch": 227, "n_parameters": 106143056}
{"train_lr": 0.00011555417107539845, "train_min_lr": 0.00011555417107539845, "train_mlm_acc_1": 0.11767624779100626, "train_mlm_acc_2": 0.11614596206128021, "train_loss_1": 4.925678759629829, "train_loss_2": 4.94837488950924, "train_loss": 9.874053649034224, "train_loss_scale": 2408.246262093228, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.4581413730363, "epoch": 228, "n_parameters": 106143056}
{"train_lr": 0.00011276635939288607, "train_min_lr": 0.00011276635939288607, "train_mlm_acc_1": 0.11789055899598143, "train_mlm_acc_2": 0.11630630038396873, "train_loss_1": 4.92347118213917, "train_loss_2": 4.946198102771555, "train_loss": 9.869669283600155, "train_loss_scale": 1948.9322779243623, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 229, "n_parameters": 106143056}
{"train_lr": 0.00011000990876295262, "train_min_lr": 0.00011000990876295262, "train_mlm_acc_1": 0.11798753389775779, "train_mlm_acc_2": 0.116432111172977, "train_loss_1": 4.921692031773959, "train_loss_2": 4.944327685375851, "train_loss": 9.866019713532642, "train_loss_scale": 966.3605980650835, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 230, "n_parameters": 106143056}
{"train_lr": 0.00010728514266730062, "train_min_lr": 0.00010728514266730062, "train_mlm_acc_1": 0.11813640889196461, "train_mlm_acc_2": 0.11660787520115981, "train_loss_1": 4.919656811886538, "train_loss_2": 4.9424288370363945, "train_loss": 9.862085649499583, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.5360095843790704, "epoch": 231, "n_parameters": 106143056}
{"train_lr": 0.00010459238086931266, "train_min_lr": 0.00010459238086931266, "train_mlm_acc_1": 0.1183799339635273, "train_mlm_acc_2": 0.11676762954200058, "train_loss_1": 4.917807973469153, "train_loss_2": 4.94052055056093, "train_loss": 9.858328522667092, "train_loss_scale": 693.023746701847, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.585651989243171, "epoch": 232, "n_parameters": 106143056}
{"train_lr": 0.0001019319393765248, "train_min_lr": 0.0001019319393765248, "train_mlm_acc_1": 0.1184733472297602, "train_mlm_acc_2": 0.11689031394747337, "train_loss_1": 4.916004876348148, "train_loss_2": 4.938829925202862, "train_loss": 9.854834802861578, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.4667929574493366, "epoch": 233, "n_parameters": 106143056}
{"train_lr": 9.930413040354184e-05, "train_min_lr": 9.930413040354184e-05, "train_mlm_acc_1": 0.11868524213019258, "train_mlm_acc_2": 0.11707235372190347, "train_loss_1": 4.913251748709901, "train_loss_2": 4.9361006668920355, "train_loss": 9.84935241701735, "train_loss_scale": 1632.816182937555, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.502307061574495, "epoch": 234, "n_parameters": 106143056}
{"train_lr": 9.670926233539824e-05, "train_min_lr": 9.670926233539824e-05, "train_mlm_acc_1": 0.11879970410489785, "train_mlm_acc_2": 0.11721679677805072, "train_loss_1": 4.911354893902047, "train_loss_2": 4.93413697976026, "train_loss": 9.845491877331897, "train_loss_scale": 1254.5576077396659, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 235, "n_parameters": 106143056}
{"train_lr": 9.414763969136625e-05, "train_min_lr": 9.414763969136625e-05, "train_mlm_acc_1": 0.11895547311494198, "train_mlm_acc_2": 0.11733154506769061, "train_loss_1": 4.909452953932048, "train_loss_2": 4.932230231629827, "train_loss": 9.84168318488038, "train_loss_scale": 1040.2110817941953, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.6950457078276124, "epoch": 236, "n_parameters": 106143056}
{"train_lr": 9.16195630892216e-05, "train_min_lr": 9.16195630892216e-05, "train_mlm_acc_1": 0.11913548586292155, "train_mlm_acc_2": 0.11755181124012855, "train_loss_1": 4.907134275690128, "train_loss_2": 4.929787526344561, "train_loss": 9.836921797998139, "train_loss_scale": 1170.8003518029902, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 237, "n_parameters": 106143056}
{"train_lr": 8.91253292099618e-05, "train_min_lr": 8.91253292099618e-05, "train_mlm_acc_1": 0.11929190762524503, "train_mlm_acc_2": 0.11772787304088905, "train_loss_1": 4.9044202802573365, "train_loss_2": 4.927202900460443, "train_loss": 9.831623177519994, "train_loss_scale": 1123.9683377308706, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.532936833359845, "epoch": 238, "n_parameters": 106143056}
{"train_lr": 8.66652307629916e-05, "train_min_lr": 8.66652307629916e-05, "train_mlm_acc_1": 0.11931906012685523, "train_mlm_acc_2": 0.11776348849039331, "train_loss_1": 4.904035488659599, "train_loss_2": 4.926710161076582, "train_loss": 9.83074565298639, "train_loss_scale": 1603.9964819700967, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 239, "n_parameters": 106143056}
{"train_lr": 8.423955645177132e-05, "train_min_lr": 8.423955645177132e-05, "train_mlm_acc_1": 0.11956639873583064, "train_mlm_acc_2": 0.1180016999644872, "train_loss_1": 4.90173713450067, "train_loss_2": 4.924489519474479, "train_loss": 9.826226656019635, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.6113724302805195, "epoch": 240, "n_parameters": 106143056}
{"train_lr": 8.184859093993656e-05, "train_min_lr": 8.184859093993656e-05, "train_mlm_acc_1": 0.11963139985513561, "train_mlm_acc_2": 0.1180614102738291, "train_loss_1": 4.8994595722451795, "train_loss_2": 4.9221580463118375, "train_loss": 9.821617619448203, "train_loss_scale": 1594.089709762533, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 241, "n_parameters": 106143056}
{"train_lr": 7.949261481789082e-05, "train_min_lr": 7.949261481789082e-05, "train_mlm_acc_1": 0.11973402049333486, "train_mlm_acc_2": 0.1181612709338925, "train_loss_1": 4.898366342014457, "train_loss_2": 4.9210620628393, "train_loss": 9.81942840396257, "train_loss_scale": 1024.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.6008419014428306, "epoch": 242, "n_parameters": 106143056}
{"train_lr": 7.717190456987782e-05, "train_min_lr": 7.717190456987782e-05, "train_mlm_acc_1": 0.11991704506316307, "train_mlm_acc_2": 0.11835623992706928, "train_loss_1": 4.896023027186029, "train_loss_2": 4.9187078704515255, "train_loss": 9.814730897218173, "train_loss_scale": 1391.4511873350923, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 2.7878172510846624, "epoch": 243, "n_parameters": 106143056}
{"train_lr": 7.488673254153478e-05, "train_min_lr": 7.488673254153478e-05, "train_mlm_acc_1": 0.12012606553107552, "train_mlm_acc_2": 0.11852782402063082, "train_loss_1": 4.893942389555321, "train_loss_2": 4.916643701474081, "train_loss": 9.810586090452754, "train_loss_scale": 1055.5215479331575, "train_weight_decay": 0.04999999999999903, "train_grad_norm": NaN, "epoch": 244, "n_parameters": 106143056}
{"train_lr": 7.263736690793118e-05, "train_min_lr": 7.263736690793118e-05, "train_mlm_acc_1": 0.12023113686804354, "train_mlm_acc_2": 0.11860478095703725, "train_loss_1": 4.891694132497464, "train_loss_2": 4.91445229938393, "train_loss": 9.806146436651863, "train_loss_scale": 1032.5558487247142, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 245, "n_parameters": 106143056}
{"train_lr": 7.04240716420974e-05, "train_min_lr": 7.04240716420974e-05, "train_mlm_acc_1": 0.12044346690007543, "train_mlm_acc_2": 0.11884798535056537, "train_loss_1": 4.889609955126713, "train_loss_2": 4.912351634120774, "train_loss": 9.801961588880527, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.5325796401804754, "epoch": 246, "n_parameters": 106143056}
{"train_lr": 6.824710648404599e-05, "train_min_lr": 6.824710648404599e-05, "train_mlm_acc_1": 0.12052399684857698, "train_mlm_acc_2": 0.11891917045749953, "train_loss_1": 4.888318977339182, "train_loss_2": 4.9111031055345595, "train_loss": 9.7994220786275, "train_loss_scale": 640.3377308707124, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.482729493785345, "epoch": 247, "n_parameters": 106143056}
{"train_lr": 6.610672691029053e-05, "train_min_lr": 6.610672691029053e-05, "train_mlm_acc_1": 0.12066206119204285, "train_mlm_acc_2": 0.11907373710306936, "train_loss_1": 4.88641527591301, "train_loss_2": 4.909095979303043, "train_loss": 9.795511254534558, "train_loss_scale": 537.217238346526, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 248, "n_parameters": 106143056}
{"train_lr": 6.400318410386393e-05, "train_min_lr": 6.400318410386393e-05, "train_mlm_acc_1": 0.12070997601019492, "train_mlm_acc_2": 0.11912843147202631, "train_loss_1": 4.885912616680669, "train_loss_2": 4.908433729079908, "train_loss": 9.794346348381714, "train_loss_scale": 532.2638522427441, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 249, "n_parameters": 106143056}
{"train_lr": 6.19367249248409e-05, "train_min_lr": 6.19367249248409e-05, "train_mlm_acc_1": 0.12086245830096272, "train_mlm_acc_2": 0.11927155758644943, "train_loss_1": 4.883560326975903, "train_loss_2": 4.906325604429136, "train_loss": 9.789885930985658, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.9781247335457444, "epoch": 250, "n_parameters": 106143056}
{"train_lr": 5.990759188136876e-05, "train_min_lr": 5.990759188136876e-05, "train_mlm_acc_1": 0.12094392726753192, "train_mlm_acc_2": 0.11934297174467601, "train_loss_1": 4.8820746881771, "train_loss_2": 4.904864320811622, "train_loss": 9.786939005948204, "train_loss_scale": 273.3368513632366, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 251, "n_parameters": 106143056}
{"train_lr": 5.791602310120655e-05, "train_min_lr": 5.791602310120655e-05, "train_mlm_acc_1": 0.12106264932629904, "train_mlm_acc_2": 0.11942638755221453, "train_loss_1": 4.88021866202669, "train_loss_2": 4.902868299549257, "train_loss": 9.783086956962746, "train_loss_scale": 300.35532102022864, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 3.7664688456551274, "epoch": 252, "n_parameters": 106143056}
{"train_lr": 5.59622523037808e-05, "train_min_lr": 5.59622523037808e-05, "train_mlm_acc_1": 0.12129504314116747, "train_mlm_acc_2": 0.1196863575393732, "train_loss_1": 4.8771615097579355, "train_loss_2": 4.899824885390994, "train_loss": 9.776986399133056, "train_loss_scale": 344.9357959542656, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 253, "n_parameters": 106143056}
{"train_lr": 5.4046508772757435e-05, "train_min_lr": 5.4046508772757435e-05, "train_mlm_acc_1": 0.12140495864725233, "train_mlm_acc_2": 0.11976488340046444, "train_loss_1": 4.876621289639067, "train_loss_2": 4.899380401445253, "train_loss": 9.776001687205037, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.403890885065392, "epoch": 254, "n_parameters": 106143056}
{"train_lr": 5.2169017329133505e-05, "train_min_lr": 5.2169017329133505e-05, "train_mlm_acc_1": 0.12146448577601027, "train_mlm_acc_2": 0.11987017235319763, "train_loss_1": 4.875210386467483, "train_loss_2": 4.89796051123526, "train_loss": 9.773170896444597, "train_loss_scale": 484.75637642919963, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.714370895501491, "epoch": 255, "n_parameters": 106143056}
{"train_lr": 5.03299983048543e-05, "train_min_lr": 5.03299983048543e-05, "train_mlm_acc_1": 0.12161091006161906, "train_mlm_acc_2": 0.12000194956321619, "train_loss_1": 4.873817827057818, "train_loss_2": 4.896542042100649, "train_loss": 9.77035987576373, "train_loss_scale": 346.06156552330697, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 256, "n_parameters": 106143056}
{"train_lr": 4.8529667516956426e-05, "train_min_lr": 4.8529667516956426e-05, "train_mlm_acc_1": 0.12168548490586728, "train_mlm_acc_2": 0.1200896941990368, "train_loss_1": 4.872675167277075, "train_loss_2": 4.895262235387334, "train_loss": 9.76793739558734, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.548121232575456, "epoch": 257, "n_parameters": 106143056}
{"train_lr": 4.676823624223976e-05, "train_min_lr": 4.676823624223976e-05, "train_mlm_acc_1": 0.12175847947017578, "train_mlm_acc_2": 0.12013804419056276, "train_loss_1": 4.871572543889048, "train_loss_2": 4.894169858441399, "train_loss": 9.765742400705342, "train_loss_scale": 483.6306068601583, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.107809594669359, "epoch": 258, "n_parameters": 106143056}
{"train_lr": 4.5045911192474324e-05, "train_min_lr": 4.5045911192474324e-05, "train_mlm_acc_1": 0.12194456174484763, "train_mlm_acc_2": 0.12033647162186124, "train_loss_1": 4.869214152545392, "train_loss_2": 4.891772054378254, "train_loss": 9.760986205350966, "train_loss_scale": 521.4564643799472, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 259, "n_parameters": 106143056}
{"train_lr": 4.336289449014104e-05, "train_min_lr": 4.336289449014104e-05, "train_mlm_acc_1": 0.12217341690498716, "train_mlm_acc_2": 0.12054700372542403, "train_loss_1": 4.866794693176434, "train_loss_2": 4.88937769323037, "train_loss": 9.756172388189176, "train_loss_scale": 512.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.73761499253091, "epoch": 260, "n_parameters": 106143056}
{"train_lr": 4.171938364471223e-05, "train_min_lr": 4.171938364471223e-05, "train_mlm_acc_1": 0.12215939974174782, "train_mlm_acc_2": 0.12057880572270252, "train_loss_1": 4.866223454685094, "train_loss_2": 4.888838091752145, "train_loss": 9.755061546856622, "train_loss_scale": 335.2541776605101, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 261, "n_parameters": 106143056}
{"train_lr": 4.011557152947225e-05, "train_min_lr": 4.011557152947225e-05, "train_mlm_acc_1": 0.1223394467979473, "train_mlm_acc_2": 0.12072318000514175, "train_loss_1": 4.864142885728163, "train_loss_2": 4.886696173155004, "train_loss": 9.750839061451881, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.39502487396502, "epoch": 262, "n_parameters": 106143056}
{"train_lr": 3.8551646358884036e-05, "train_min_lr": 3.8551646358884036e-05, "train_mlm_acc_1": 0.12258960258235324, "train_mlm_acc_2": 0.12097476732408466, "train_loss_1": 4.861300986276558, "train_loss_2": 4.883774272422572, "train_loss": 9.745075258017636, "train_loss_scale": 494.4379947229551, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.831292271404384, "epoch": 263, "n_parameters": 106143056}
{"train_lr": 3.702779166650029e-05, "train_min_lr": 3.702779166650029e-05, "train_mlm_acc_1": 0.12267917950237096, "train_mlm_acc_2": 0.1210703335754842, "train_loss_1": 4.8597731626966905, "train_loss_2": 4.882360341890716, "train_loss": 9.742133506684317, "train_loss_scale": 290.22339489885667, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 264, "n_parameters": 106143056}
{"train_lr": 3.55441862834257e-05, "train_min_lr": 3.55441862834257e-05, "train_mlm_acc_1": 0.12272312054811939, "train_mlm_acc_2": 0.12110320062818057, "train_loss_1": 4.859404657740496, "train_loss_2": 4.881968535921924, "train_loss": 9.741373191617933, "train_loss_scale": 281.89270008795074, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 265, "n_parameters": 106143056}
{"train_lr": 3.4101004317329864e-05, "train_min_lr": 3.4101004317329864e-05, "train_mlm_acc_1": 0.1227687220396302, "train_mlm_acc_2": 0.12111680551039722, "train_loss_1": 4.858409552744007, "train_loss_2": 4.881110427614462, "train_loss": 9.73951998056816, "train_loss_scale": 210.63148636763412, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 266, "n_parameters": 106143056}
{"train_lr": 3.269841513201525e-05, "train_min_lr": 3.269841513201525e-05, "train_mlm_acc_1": 0.12294684515785993, "train_mlm_acc_2": 0.1213113278209534, "train_loss_1": 4.856304915567816, "train_loss_2": 4.878789766640021, "train_loss": 9.735094682312683, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 5.175748908320538, "epoch": 267, "n_parameters": 106143056}
{"train_lr": 3.1336583327541557e-05, "train_min_lr": 3.1336583327541557e-05, "train_mlm_acc_1": 0.1229543577807586, "train_mlm_acc_2": 0.12137287043087452, "train_loss_1": 4.856069635904559, "train_loss_2": 4.878542599126552, "train_loss": 9.734612238333742, "train_loss_scale": 204.2145998240985, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 5.209391595191251, "epoch": 268, "n_parameters": 106143056}
{"train_lr": 3.0015668720909095e-05, "train_min_lr": 3.0015668720909095e-05, "train_mlm_acc_1": 0.12306697589485344, "train_mlm_acc_2": 0.12147023464924113, "train_loss_1": 4.854813871880634, "train_loss_2": 4.877372620602711, "train_loss": 9.732186489809786, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 4.780582418018197, "epoch": 269, "n_parameters": 106143056}
{"train_lr": 2.8735826327303497e-05, "train_min_lr": 2.8735826327303497e-05, "train_mlm_acc_1": 0.12316423705422705, "train_mlm_acc_2": 0.12156762174931056, "train_loss_1": 4.853107316460438, "train_loss_2": 4.875566966825131, "train_loss": 9.728674283652527, "train_loss_scale": 236.86191732629726, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 270, "n_parameters": 106143056}
{"train_lr": 2.7497206341904298e-05, "train_min_lr": 2.7497206341904298e-05, "train_mlm_acc_1": 0.12340515107653623, "train_mlm_acc_2": 0.12181723927513827, "train_loss_1": 4.850829526899987, "train_loss_2": 4.873361088355173, "train_loss": 9.724190614783355, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 6.267744534877485, "epoch": 271, "n_parameters": 106143056}
{"train_lr": 2.629995412225849e-05, "train_min_lr": 2.629995412225849e-05, "train_mlm_acc_1": 0.12340026114483281, "train_mlm_acc_2": 0.1217951141420683, "train_loss_1": 4.850086698483875, "train_loss_2": 4.872598027386158, "train_loss": 9.722684722986783, "train_loss_scale": 209.73087071240104, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 7.15157553241666, "epoch": 272, "n_parameters": 106143056}
{"train_lr": 2.514421017122239e-05, "train_min_lr": 2.514421017122239e-05, "train_mlm_acc_1": 0.12337853685889652, "train_mlm_acc_2": 0.1217979885721309, "train_loss_1": 4.850244391666973, "train_loss_2": 4.8728188487030275, "train_loss": 9.723063241628145, "train_loss_scale": 163.23658751099384, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 273, "n_parameters": 106143056}
{"train_lr": 2.4030110120472967e-05, "train_min_lr": 2.4030110120472967e-05, "train_mlm_acc_1": 0.12354681133182036, "train_mlm_acc_2": 0.12190307142407934, "train_loss_1": 4.848804316294225, "train_loss_2": 4.871335478183357, "train_loss": 9.720139794320314, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 6.943561245499731, "epoch": 274, "n_parameters": 106143056}
{"train_lr": 2.29577847145909e-05, "train_min_lr": 2.29577847145909e-05, "train_mlm_acc_1": 0.12353621830421654, "train_mlm_acc_2": 0.1219475048151041, "train_loss_1": 4.848496549204975, "train_loss_2": 4.870893661453731, "train_loss": 9.719390212283809, "train_loss_scale": 251.6094986807388, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 7.16091224784482, "epoch": 275, "n_parameters": 106143056}
{"train_lr": 2.1927359795716904e-05, "train_min_lr": 2.1927359795716904e-05, "train_mlm_acc_1": 0.12369567488148979, "train_mlm_acc_2": 0.12204884282880928, "train_loss_1": 4.847076048951664, "train_loss_2": 4.869545726631436, "train_loss": 9.716621767667268, "train_loss_scale": 162.56112576956903, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 276, "n_parameters": 106143056}
{"train_lr": 2.093895628878402e-05, "train_min_lr": 2.093895628878402e-05, "train_mlm_acc_1": 0.1237514571793764, "train_mlm_acc_2": 0.12214017203347978, "train_loss_1": 4.8454395371670245, "train_loss_2": 4.867789303669305, "train_loss": 9.713228840416948, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 7.494159404919037, "epoch": 277, "n_parameters": 106143056}
{"train_lr": 1.9992690187326e-05, "train_min_lr": 1.9992690187326e-05, "train_mlm_acc_1": 0.12387328267526684, "train_mlm_acc_2": 0.12222053015992872, "train_loss_1": 4.844993657728193, "train_loss_2": 4.867355814342868, "train_loss": 9.712349472280753, "train_loss_scale": 217.72383465259455, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 278, "n_parameters": 106143056}
{"train_lr": 1.9088672539865457e-05, "train_min_lr": 1.9088672539865457e-05, "train_mlm_acc_1": 0.12394061996523707, "train_mlm_acc_2": 0.12231385180187676, "train_loss_1": 4.843454543445439, "train_loss_2": 4.865955212604821, "train_loss": 9.709409757255983, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 7.687214133187984, "epoch": 279, "n_parameters": 106143056}
{"train_lr": 1.8227009436881574e-05, "train_min_lr": 1.8227009436881574e-05, "train_mlm_acc_1": 0.1240513028303389, "train_mlm_acc_2": 0.12239986715433675, "train_loss_1": 4.842216592560552, "train_loss_2": 4.864598836255053, "train_loss": 9.706815430021328, "train_loss_scale": 193.40721196130167, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 7.9946781426222575, "epoch": 280, "n_parameters": 106143056}
{"train_lr": 1.7407801998359794e-05, "train_min_lr": 1.7407801998359794e-05, "train_mlm_acc_1": 0.12407864995133672, "train_mlm_acc_2": 0.12248119869471749, "train_loss_1": 4.841965653913107, "train_loss_2": 4.864295014028708, "train_loss": 9.706260667103052, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 7.912552993970685, "epoch": 281, "n_parameters": 106143056}
{"train_lr": 1.6631146361925272e-05, "train_min_lr": 1.6631146361925272e-05, "train_mlm_acc_1": 0.12410947856580938, "train_mlm_acc_2": 0.12251414590996011, "train_loss_1": 4.840963845307511, "train_loss_2": 4.8632977149312495, "train_loss": 9.704261563908352, "train_loss_scale": 152.65435356200527, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 282, "n_parameters": 106143056}
{"train_lr": 1.5897133671560495e-05, "train_min_lr": 1.5897133671560495e-05, "train_mlm_acc_1": 0.12414534596551009, "train_mlm_acc_2": 0.12256164841678259, "train_loss_1": 4.841172949148042, "train_loss_2": 4.863360531778847, "train_loss": 9.704533482918952, "train_loss_scale": 134.19173262972734, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 7.816997924601707, "epoch": 283, "n_parameters": 106143056}
{"train_lr": 1.5205850066909038e-05, "train_min_lr": 1.5205850066909038e-05, "train_mlm_acc_1": 0.12422468490479227, "train_mlm_acc_2": 0.12259719522199745, "train_loss_1": 4.839438166393978, "train_loss_2": 4.86178568700163, "train_loss": 9.701223856750662, "train_loss_scale": 256.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 8.0007647903949, "epoch": 284, "n_parameters": 106143056}
{"train_lr": 1.4557376673166934e-05, "train_min_lr": 1.4557376673166934e-05, "train_mlm_acc_1": 0.1242739510392359, "train_mlm_acc_2": 0.12263711651815011, "train_loss_1": 4.83891264099559, "train_loss_2": 4.861325920362061, "train_loss": 9.700238564922396, "train_loss_scale": 187.4406332453826, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 285, "n_parameters": 106143056}
{"train_lr": 1.3951789591562158e-05, "train_min_lr": 1.3951789591562158e-05, "train_mlm_acc_1": 0.12440894620219474, "train_mlm_acc_2": 0.12278677032246413, "train_loss_1": 4.837576926698156, "train_loss_2": 4.859888580459823, "train_loss": 9.697465503750502, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 7.991171933415697, "epoch": 286, "n_parameters": 106143056}
{"train_lr": 1.3389159890423752e-05, "train_min_lr": 1.3389159890423752e-05, "train_mlm_acc_1": 0.12436981504765014, "train_mlm_acc_2": 0.12278853385588817, "train_loss_1": 4.837861464384258, "train_loss_2": 4.860035826264501, "train_loss": 9.697897291854483, "train_loss_scale": 186.65259454705364, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 287, "n_parameters": 106143056}
{"train_lr": 1.2869553596841708e-05, "train_min_lr": 1.2869553596841708e-05, "train_mlm_acc_1": 0.12449219025648547, "train_mlm_acc_2": 0.12291629151781086, "train_loss_1": 4.836039442133253, "train_loss_2": 4.858348891361827, "train_loss": 9.694388335172608, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 8.577723326553036, "epoch": 288, "n_parameters": 106143056}
{"train_lr": 1.2393031688918403e-05, "train_min_lr": 1.2393031688918403e-05, "train_mlm_acc_1": 0.12454583108009035, "train_mlm_acc_2": 0.12294612376948223, "train_loss_1": 4.835197562802331, "train_loss_2": 4.85749989092717, "train_loss": 9.692697449011455, "train_loss_scale": 129.91380826737029, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 289, "n_parameters": 106143056}
{"train_lr": 1.1959650088612536e-05, "train_min_lr": 1.1959650088612536e-05, "train_mlm_acc_1": 0.12457775900495896, "train_mlm_acc_2": 0.12298195687488783, "train_loss_1": 4.835372472868326, "train_loss_2": 4.857852314162275, "train_loss": 9.69322478970416, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 8.563326445502362, "epoch": 290, "n_parameters": 106143056}
{"train_lr": 1.1569459655176374e-05, "train_min_lr": 1.1569459655176374e-05, "train_mlm_acc_1": 0.12458424075451748, "train_mlm_acc_2": 0.12296433229631726, "train_loss_1": 4.834883951050415, "train_loss_2": 4.857220399295854, "train_loss": 9.692104352390755, "train_loss_scale": 165.7132805628848, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 291, "n_parameters": 106143056}
{"train_lr": 1.1222506179187317e-05, "train_min_lr": 1.1222506179187317e-05, "train_mlm_acc_1": 0.1246853040362542, "train_mlm_acc_2": 0.12306853331029154, "train_loss_1": 4.834126427599287, "train_loss_2": 4.856435000005267, "train_loss": 9.69056142907239, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 8.785972129491304, "epoch": 292, "n_parameters": 106143056}
{"train_lr": 1.0918830377174124e-05, "train_min_lr": 1.0918830377174124e-05, "train_mlm_acc_1": 0.12467394369140779, "train_mlm_acc_2": 0.12305451627155617, "train_loss_1": 4.834053182507568, "train_loss_2": 4.856403401103477, "train_loss": 9.690456579941454, "train_loss_scale": 132.72823218997362, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 293, "n_parameters": 106143056}
{"train_lr": 1.0658467886838543e-05, "train_min_lr": 1.0658467886838543e-05, "train_mlm_acc_1": 0.12468374661262505, "train_mlm_acc_2": 0.1230598871343054, "train_loss_1": 4.83423562724022, "train_loss_2": 4.85649757256294, "train_loss": 9.690733202948524, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 9.104587608927053, "epoch": 294, "n_parameters": 106143056}
{"train_lr": 1.0441449262873223e-05, "train_min_lr": 1.0441449262873223e-05, "train_mlm_acc_1": 0.12475564174203362, "train_mlm_acc_2": 0.12316690539087684, "train_loss_1": 4.833086303796492, "train_loss_2": 4.855454733000582, "train_loss": 9.6885410350147, "train_loss_scale": 247.78188214599825, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 8.862277597739388, "epoch": 295, "n_parameters": 106143056}
{"train_lr": 1.0267799973375903e-05, "train_min_lr": 1.0267799973375903e-05, "train_mlm_acc_1": 0.12469043449573251, "train_mlm_acc_2": 0.12312995005405541, "train_loss_1": 4.833262831680378, "train_loss_2": 4.855525481879135, "train_loss": 9.688788312825595, "train_loss_scale": 221.0448548812665, "train_weight_decay": 0.04999999999999903, "train_grad_norm": Infinity, "epoch": 296, "n_parameters": 106143056}
{"train_lr": 1.0137540396860598e-05, "train_min_lr": 1.0137540396860598e-05, "train_mlm_acc_1": 0.12480514837312615, "train_mlm_acc_2": 0.12320226892049153, "train_loss_1": 4.832758082720724, "train_loss_2": 4.855040107836509, "train_loss": 9.687798186153724, "train_loss_scale": 64.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 8.556524714043817, "epoch": 297, "n_parameters": 106143056}
{"train_lr": 1.0050685819866211e-05, "train_min_lr": 1.0050685819866211e-05, "train_mlm_acc_1": 0.1248262313849038, "train_mlm_acc_2": 0.1232093919630481, "train_loss_1": 4.8325231572778575, "train_loss_2": 4.854781520555391, "train_loss": 9.687304672171594, "train_loss_scale": 82.63148636763412, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 9.214848215473044, "epoch": 298, "n_parameters": 106143056}
{"train_lr": 1.0007246435162376e-05, "train_min_lr": 1.0007246435162376e-05, "train_mlm_acc_1": 0.12486111389828572, "train_mlm_acc_2": 0.12323581154164166, "train_loss_1": 4.831774580132678, "train_loss_2": 4.854056447141508, "train_loss": 9.68583102234645, "train_loss_scale": 128.0, "train_weight_decay": 0.04999999999999903, "train_grad_norm": 9.664224519683483, "epoch": 299, "n_parameters": 106143056}
